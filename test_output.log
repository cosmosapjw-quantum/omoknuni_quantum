============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.1, pluggy-1.6.0 -- /home/cosmosapjw/venv/bin/python
cachedir: .pytest_cache
hypothesis profile 'default'
rootdir: /home/cosmosapjw/omoknuni_quantum
configfile: pytest.ini
plugins: timeout-2.4.0, cov-6.2.1, hypothesis-6.135.24
timeout: 300.0s
timeout method: thread
timeout func_only: False
collecting ... collected 939 items

python/tests/test_core/test_bound_checking.py::TestBoundChecking::test_get_best_child_invalid_node_index PASSED [  0%]
python/tests/test_core/test_bound_checking.py::TestBoundChecking::test_get_best_child_edge_case_node_indices PASSED [  0%]
python/tests/test_core/test_bound_checking.py::TestBoundChecking::test_other_tree_operations_bound_checking PASSED [  0%]
python/tests/test_core/test_dirichlet_noise_fix.py::TestDirichletNoiseFix::test_dirichlet_noise_produces_different_results PASSED [  0%]
python/tests/test_core/test_dirichlet_noise_fix.py::TestDirichletNoiseFix::test_dirichlet_distribution_sampling_variation PASSED [  0%]
python/tests/test_core/test_evaluator.py::TestEvaluatorConfig::test_default_config PASSED [  0%]
python/tests/test_core/test_evaluator.py::TestEvaluatorConfig::test_custom_config PASSED [  0%]
python/tests/test_core/test_evaluator.py::TestAbstractEvaluator::test_initialization PASSED [  0%]
python/tests/test_core/test_evaluator.py::TestAbstractEvaluator::test_stats_tracking PASSED [  0%]
python/tests/test_core/test_evaluator.py::TestAbstractEvaluator::test_stats_reset PASSED [  1%]
python/tests/test_core/test_evaluator.py::TestAbstractEvaluator::test_cache_operations PASSED [  1%]
python/tests/test_core/test_evaluator.py::TestAbstractEvaluator::test_cache_size_limit PASSED [  1%]
python/tests/test_core/test_evaluator.py::TestAbstractEvaluator::test_cache_disabled PASSED [  1%]
python/tests/test_core/test_evaluator.py::TestAbstractEvaluator::test_warmup PASSED [  1%]
python/tests/test_core/test_evaluator.py::TestAlphaZeroEvaluator::test_initialization PASSED [  1%]
python/tests/test_core/test_evaluator.py::TestAlphaZeroEvaluator::test_action_size_inference PASSED [  1%]
python/tests/test_core/test_evaluator.py::TestAlphaZeroEvaluator::test_single_evaluation PASSED [  1%]
python/tests/test_core/test_evaluator.py::TestAlphaZeroEvaluator::test_batch_evaluation PASSED [  1%]
python/tests/test_core/test_evaluator.py::TestAlphaZeroEvaluator::test_temperature_scaling PASSED [  2%]
python/tests/test_core/test_evaluator.py::TestAlphaZeroEvaluator::test_no_legal_moves PASSED [  2%]
python/tests/test_core/test_evaluator.py::TestAlphaZeroEvaluator::test_device_handling PASSED [  2%]
python/tests/test_core/test_evaluator.py::TestAlphaZeroEvaluator::test_cuda_device PASSED [  2%]
python/tests/test_core/test_evaluator.py::TestAlphaZeroEvaluator::test_tensor_input_handling PASSED [  2%]
python/tests/test_core/test_evaluator.py::TestAlphaZeroEvaluator::test_single_batch_value_handling PASSED [  2%]
python/tests/test_core/test_evaluator.py::TestRandomEvaluator::test_initialization PASSED [  2%]
python/tests/test_core/test_evaluator.py::TestRandomEvaluator::test_single_evaluation PASSED [  2%]
python/tests/test_core/test_evaluator.py::TestRandomEvaluator::test_batch_evaluation PASSED [  2%]
python/tests/test_core/test_evaluator.py::TestRandomEvaluator::test_reproducibility PASSED [  2%]
python/tests/test_core/test_evaluator.py::TestRandomEvaluator::test_no_legal_moves PASSED [  3%]
python/tests/test_core/test_evaluator.py::TestRandomEvaluator::test_all_legal_moves PASSED [  3%]
python/tests/test_core/test_evaluator.py::TestEvaluatorIntegration::test_evaluator_comparison PASSED [  3%]
python/tests/test_core/test_evaluator.py::TestEvaluatorIntegration::test_large_batch_evaluation PASSED [  3%]
python/tests/test_core/test_evaluator.py::TestEvaluatorIntegration::test_mixed_legal_masks PASSED [  3%]
python/tests/test_core/test_evaluator.py::TestEvaluatorIntegration::test_performance_tracking PASSED [  3%]
python/tests/test_core/test_evaluator.py::TestErrorHandling::test_import_error_without_torch PASSED [  3%]
python/tests/test_core/test_evaluator.py::TestErrorHandling::test_invalid_action_size PASSED [  3%]
python/tests/test_core/test_evaluator.py::TestErrorHandling::test_model_forward_error PASSED [  3%]
python/tests/test_core/test_game_interface.py::TestGameInterfaceInitialization::test_gomoku_initialization PASSED [  4%]
python/tests/test_core/test_game_interface.py::TestGameInterfaceInitialization::test_go_initialization PASSED [  4%]
python/tests/test_core/test_game_interface.py::TestGameInterfaceInitialization::test_chess_initialization PASSED [  4%]
python/tests/test_core/test_game_interface.py::TestGameInterfaceInitialization::test_game_options PASSED [  4%]
python/tests/test_core/test_game_interface.py::TestStateCreation::test_create_initial_state PASSED [  4%]
python/tests/test_core/test_game_interface.py::TestStateCreation::test_create_state_with_options PASSED [  4%]
python/tests/test_core/test_game_interface.py::TestStateConversions::test_state_to_numpy_basic PASSED [  4%]
python/tests/test_core/test_game_interface.py::TestStateConversions::test_state_to_numpy_enhanced PASSED [  4%]
python/tests/test_core/test_game_interface.py::TestStateConversions::test_state_to_numpy_standard PASSED [  4%]
python/tests/test_core/test_game_interface.py::TestStateConversions::test_state_to_tensor PASSED [  5%]
python/tests/test_core/test_game_interface.py::TestStateConversions::test_batch_state_conversion PASSED [  5%]
python/tests/test_core/test_game_interface.py::TestTensorToState::test_tensor_to_state_basic PASSED [  5%]
python/tests/test_core/test_game_interface.py::TestTensorToState::test_tensor_to_state_empty PASSED [  5%]
python/tests/test_core/test_game_interface.py::TestTensorToState::test_tensor_to_state_validation PASSED [  5%]
python/tests/test_core/test_game_interface.py::TestMoveHandling::test_legal_moves_generation PASSED [  5%]
python/tests/test_core/test_game_interface.py::TestMoveHandling::test_legal_moves_shuffling PASSED [  5%]
python/tests/test_core/test_game_interface.py::TestMoveHandling::test_apply_move PASSED [  5%]
python/tests/test_core/test_game_interface.py::TestMoveHandling::test_invalid_move_handling PASSED [  5%]
python/tests/test_core/test_game_interface.py::TestMoveHandling::test_go_pass_move PASSED [  5%]
python/tests/test_core/test_game_interface.py::TestGameLogic::test_terminal_detection PASSED [  6%]
python/tests/test_core/test_game_interface.py::TestGameLogic::test_winner_detection PASSED [  6%]
python/tests/test_core/test_game_interface.py::TestGameLogic::test_draw_detection PASSED [  6%]
python/tests/test_core/test_game_interface.py::TestGameLogic::test_current_player_tracking PASSED [  6%]
python/tests/test_core/test_game_interface.py::TestSymmetries::test_symmetries_interface PASSED [  6%]
python/tests/test_core/test_game_interface.py::TestSymmetries::test_go_symmetries_with_pass PASSED [  6%]
python/tests/test_core/test_game_interface.py::TestSymmetries::test_chess_no_symmetries PASSED [  6%]
python/tests/test_core/test_game_interface.py::TestUtilityMethods::test_get_hash PASSED [  6%]
python/tests/test_core/test_game_interface.py::TestUtilityMethods::test_action_to_string PASSED [  6%]
python/tests/test_core/test_game_interface.py::TestUtilityMethods::test_clone_state PASSED [  7%]
python/tests/test_core/test_game_interface.py::TestUtilityMethods::test_get_state_hash PASSED [  7%]
python/tests/test_core/test_game_interface.py::TestUtilityMethods::test_get_canonical_form PASSED [  7%]
python/tests/test_core/test_game_interface.py::TestUtilityMethods::test_encode_for_nn PASSED [  7%]
python/tests/test_core/test_game_interface.py::TestActionProbabilityMask::test_action_probability_mask PASSED [  7%]
python/tests/test_core/test_game_interface.py::TestActionProbabilityMask::test_get_legal_mask PASSED [  7%]
python/tests/test_core/test_game_interface.py::TestGameSpecificFeatures::test_go_specific_features PASSED [  7%]
python/tests/test_core/test_game_interface.py::TestGameSpecificFeatures::test_chess_specific_features PASSED [  7%]
python/tests/test_core/test_game_interface.py::TestGameSpecificFeatures::test_gomoku_specific_features PASSED [  7%]
python/tests/test_core/test_game_interface.py::TestEdgeCases::test_legal_moves_behavior PASSED [  7%]
python/tests/test_core/test_game_interface.py::TestEdgeCases::test_invalid_action_space PASSED [  8%]
python/tests/test_core/test_game_interface.py::TestErrorHandling::test_invalid_game_type PASSED [  8%]
python/tests/test_core/test_game_interface.py::TestErrorHandling::test_missing_cpp_module PASSED [  8%]
python/tests/test_core/test_game_interface.py::TestErrorHandling::test_state_validation PASSED [  8%]
python/tests/test_core/test_game_interface.py::TestErrorHandling::test_state_hashing PASSED [  8%]
python/tests/test_core/test_game_interface.py::TestIntegration::test_mcts_compatibility PASSED [  8%]
python/tests/test_core/test_game_interface.py::TestIntegration::test_neural_network_compatibility PASSED [  8%]
python/tests/test_core/test_go_policy_fix.py::TestGoPolicyFix::test_go_policy_shape_consistency PASSED [  8%]
python/tests/test_core/test_go_policy_fix.py::TestGoPolicyFix::test_go_vs_gomoku_policy_shapes PASSED [  8%]
python/tests/test_core/test_mcts.py::TestMCTSInitialization::test_basic_initialization PASSED [  9%]
python/tests/test_core/test_mcts.py::TestMCTSInitialization::test_device_configuration PASSED [  9%]
python/tests/test_core/test_mcts.py::TestMCTSInitialization::test_game_type_configuration PASSED [  9%]
python/tests/test_core/test_mcts.py::TestMCTSInitialization::test_evaluator_configuration PASSED [  9%]
python/tests/test_core/test_mcts.py::TestMCTSSearch::test_basic_search PASSED [  9%]
python/tests/test_core/test_mcts.py::TestMCTSSearch::test_search_respects_num_simulations PASSED [  9%]
python/tests/test_core/test_mcts.py::TestMCTSSearch::test_search_with_dirichlet_noise PASSED [  9%]
python/tests/test_core/test_mcts.py::TestMCTSSearch::test_search_without_tree_reuse PASSED [  9%]
python/tests/test_core/test_mcts.py::TestMCTSSearch::test_search_terminal_position PASSED [  9%]
python/tests/test_core/test_mcts.py::TestMCTSSelection::test_ucb_selection PASSED [ 10%]
python/tests/test_core/test_mcts.py::TestMCTSSelection::test_virtual_loss_during_selection PASSED [ 10%]
python/tests/test_core/test_mcts.py::TestMCTSExpansion::test_basic_expansion PASSED [ 10%]
python/tests/test_core/test_mcts.py::TestMCTSExpansion::test_progressive_widening PASSED [ 10%]
python/tests/test_core/test_mcts.py::TestMCTSExpansion::test_expansion_respects_legal_moves PASSED [ 10%]
python/tests/test_core/test_mcts.py::TestMCTSBackpropagation::test_value_backpropagation PASSED [ 10%]
python/tests/test_core/test_mcts.py::TestMCTSBackpropagation::test_visit_count_updates PASSED [ 10%]
python/tests/test_core/test_mcts.py::TestMCTSBackpropagation::test_q_value_computation PASSED [ 10%]
python/tests/test_core/test_mcts.py::TestMCTSPolicyExtraction::test_policy_extraction_basic PASSED [ 10%]
python/tests/test_core/test_mcts.py::TestMCTSPolicyExtraction::test_policy_temperature PASSED [ 10%]
python/tests/test_core/test_mcts.py::TestMCTSPolicyExtraction::test_policy_masking_illegal_moves PASSED [ 11%]
python/tests/test_core/test_mcts.py::TestMCTSPolicyExtraction::test_empty_tree_policy PASSED [ 11%]
python/tests/test_core/test_mcts.py::TestMCTSTreeReuse::test_subtree_reuse_basic PASSED [ 11%]
python/tests/test_core/test_mcts.py::TestMCTSTreeReuse::test_subtree_reuse_preserves_values PASSED [ 11%]
python/tests/test_core/test_mcts.py::TestMCTSTreeReuse::test_subtree_reuse_disabled FAILED [ 11%]
python/tests/test_core/test_mcts.py::TestMCTSStateManagement::test_state_allocation PASSED [ 11%]
python/tests/test_core/test_mcts.py::TestMCTSStateManagement::test_state_cleanup_without_reuse PASSED [ 11%]
python/tests/test_core/test_mcts.py::TestMCTSStateManagement::test_node_to_state_mapping PASSED [ 11%]
python/tests/test_core/test_mcts.py::TestMCTSStatistics::test_statistics_tracking PASSED [ 11%]
python/tests/test_core/test_mcts.py::TestMCTSStatistics::test_performance_metrics PASSED [ 12%]
python/tests/test_core/test_mcts.py::TestMCTSStatistics::test_memory_usage_tracking SKIPPED [ 12%]
python/tests/test_core/test_mcts.py::TestMCTSEdgeCases::test_terminal_root_position PASSED [ 12%]
python/tests/test_core/test_mcts.py::TestMCTSEdgeCases::test_single_legal_move PASSED [ 12%]
python/tests/test_core/test_mcts.py::TestMCTSEdgeCases::test_max_tree_nodes_limit PASSED [ 12%]
python/tests/test_core/test_mcts.py::TestMCTSEdgeCases::test_invalid_action_handling PASSED [ 12%]
python/tests/test_core/test_mcts.py::TestMCTSIntegration::test_with_neural_evaluator PASSED [ 12%]
python/tests/test_core/test_mcts.py::TestMCTSIntegration::test_full_game_simulation SKIPPED [ 12%]
python/tests/test_core/test_mcts.py::TestMCTSIntegration::test_parallel_mcts_instances PASSED [ 12%]
python/tests/test_core/test_policy_determinism.py::TestPolicyDeterminism::test_temperature_zero_determinism PASSED [ 12%]
python/tests/test_core/test_policy_determinism.py::TestPolicyDeterminism::test_select_action_with_same_state PASSED [ 13%]
python/tests/test_core/test_policy_determinism.py::TestPolicyDeterminism::test_policy_extraction_consistency PASSED [ 13%]
python/tests/test_core/test_policy_determinism.py::TestPolicyDeterminism::test_argmax_determinism_direct PASSED [ 13%]
python/tests/test_core/test_state_synchronization.py::TestStateSynchronization::test_position_128_legal_move_consistency PASSED [ 13%]
python/tests/test_core/test_state_synchronization.py::TestStateSynchronization::test_multiple_moves_synchronization PASSED [ 13%]
python/tests/test_core/test_terminal_detection.py::TestTerminalDetection::test_terminal_position_creates_minimal_tree PASSED [ 13%]
python/tests/test_core/test_terminal_detection.py::TestTerminalDetection::test_non_terminal_position_expands_normally PASSED [ 13%]
python/tests/test_core/test_terminal_detection.py::TestTerminalDetection::test_terminal_state_detection_methods PASSED [ 13%]
python/tests/test_core/test_terminal_detection_debug.py::TestTerminalDetectionDebug::test_terminal_position_step_by_step FAILED [ 13%]
python/tests/test_core/test_tree_operations.py::TestTreeOperationsBasics::test_initialization PASSED [ 14%]
python/tests/test_core/test_tree_operations.py::TestTreeOperationsBasics::test_clear_tree PASSED [ 14%]
python/tests/test_core/test_tree_operations.py::TestTreeOperationsBasics::test_reset_tree PASSED [ 14%]
python/tests/test_core/test_tree_operations.py::TestSubtreeReuse::test_subtree_reuse_basic PASSED [ 14%]
python/tests/test_core/test_tree_operations.py::TestSubtreeReuse::test_subtree_reuse_insufficient_visits PASSED [ 14%]
python/tests/test_core/test_tree_operations.py::TestSubtreeReuse::test_subtree_reuse_nonexistent_action PASSED [ 14%]
python/tests/test_core/test_tree_operations.py::TestSubtreeReuse::test_subtree_reuse_disabled PASSED [ 14%]
python/tests/test_core/test_tree_operations.py::TestSubtreeReuse::test_subtree_extraction PASSED [ 14%]
python/tests/test_core/test_tree_operations.py::TestNodeInformation::test_get_root_children_info FAILED [ 14%]
python/tests/test_core/test_tree_operations.py::TestNodeInformation::test_get_root_children_info_empty PASSED [ 15%]
python/tests/test_core/test_tree_operations.py::TestNodeInformation::test_get_best_child PASSED [ 15%]
python/tests/test_core/test_tree_operations.py::TestNodeInformation::test_get_best_child_no_children PASSED [ 15%]
python/tests/test_core/test_tree_operations.py::TestDirichletNoise::test_add_dirichlet_noise_to_root PASSED [ 15%]
python/tests/test_core/test_tree_operations.py::TestDirichletNoise::test_dirichlet_noise_empty_root PASSED [ 15%]
python/tests/test_core/test_tree_operations.py::TestDirichletNoise::test_dirichlet_noise_determinism PASSED [ 15%]
python/tests/test_core/test_tree_operations.py::TestTreeStatistics::test_get_tree_statistics_basic PASSED [ 15%]
python/tests/test_core/test_tree_operations.py::TestTreeStatistics::test_calculate_max_depth PASSED [ 15%]
python/tests/test_core/test_tree_operations.py::TestTreeStatistics::test_calculate_max_depth_single_node PASSED [ 15%]
python/tests/test_core/test_tree_operations.py::TestTreeStatistics::test_count_root_children PASSED [ 15%]
python/tests/test_core/test_tree_operations.py::TestTreeStatistics::test_estimate_memory_usage PASSED [ 16%]
python/tests/test_core/test_tree_operations.py::TestEdgeCases::test_operations_on_empty_tree PASSED [ 16%]
python/tests/test_core/test_tree_operations.py::TestEdgeCases::test_operations_on_invalid_nodes PASSED [ 16%]
python/tests/test_core/test_tree_operations.py::TestEdgeCases::test_large_tree_operations PASSED [ 16%]
python/tests/test_core/test_wave_search.py::TestWaveSearchInitialization::test_basic_initialization PASSED [ 16%]
python/tests/test_core/test_wave_search.py::TestWaveSearchInitialization::test_buffer_allocation PASSED [ 16%]
python/tests/test_core/test_wave_search.py::TestWaveSearchInitialization::test_progressive_widening_calculation PASSED [ 16%]
python/tests/test_core/test_wave_search.py::TestWaveSelection::test_basic_selection PASSED [ 16%]
python/tests/test_core/test_wave_search.py::TestWaveSelection::test_selection_with_terminal_nodes PASSED [ 16%]
python/tests/test_core/test_wave_search.py::TestWaveSelection::test_selection_with_ucb_scores PASSED [ 17%]
python/tests/test_core/test_wave_search.py::TestWaveExpansion::test_basic_expansion PASSED [ 17%]
python/tests/test_core/test_wave_search.py::TestWaveExpansion::test_expansion_with_progressive_widening PASSED [ 17%]
python/tests/test_core/test_wave_search.py::TestWaveExpansion::test_expansion_multiple_nodes PASSED [ 17%]
python/tests/test_core/test_wave_search.py::TestWaveExpansion::test_expansion_avoids_duplicates PASSED [ 17%]
python/tests/test_core/test_wave_search.py::TestWaveEvaluation::test_basic_evaluation PASSED [ 17%]
python/tests/test_core/test_wave_search.py::TestWaveEvaluation::test_evaluation_with_invalid_nodes PASSED [ 17%]
python/tests/test_core/test_wave_search.py::TestWaveEvaluation::test_evaluation_caching PASSED [ 17%]
python/tests/test_core/test_wave_search.py::TestWaveBackpropagation::test_basic_backpropagation PASSED [ 17%]
python/tests/test_core/test_wave_search.py::TestWaveBackpropagation::test_parallel_backpropagation FAILED [ 17%]
python/tests/test_core/test_wave_search.py::TestWaveBackpropagation::test_scatter_backup_method PASSED [ 18%]
python/tests/test_core/test_wave_search.py::TestDirichletNoise::test_per_simulation_dirichlet_basic PASSED [ 18%]
python/tests/test_core/test_wave_search.py::TestDirichletNoise::test_dirichlet_noise_non_root PASSED [ 18%]
python/tests/test_core/test_wave_search.py::TestDirichletNoise::test_dirichlet_noise_mixing PASSED [ 18%]
python/tests/test_core/test_wave_search.py::TestWaveIntegration::test_full_wave_execution PASSED [ 18%]
python/tests/test_core/test_wave_search.py::TestWaveIntegration::test_wave_with_terminal_positions PASSED [ 18%]
python/tests/test_core/test_wave_search.py::TestWaveIntegration::test_large_wave_performance SKIPPED [ 18%]
python/tests/test_core/test_wave_search.py::TestEdgeCases::test_empty_tree_selection PASSED [ 18%]
python/tests/test_core/test_wave_search.py::TestEdgeCases::test_buffer_reallocation PASSED [ 18%]
python/tests/test_core/test_wave_search.py::TestEdgeCases::test_state_pool_exhaustion PASSED [ 19%]
python/tests/test_core/test_wave_search_init.py::TestWaveSearchInitialization::test_expand_batch_vectorized_without_run_wave FAILED [ 19%]
python/tests/test_core/test_wave_search_init.py::TestWaveSearchInitialization::test_expand_batch_vectorized_with_manual_initialization FAILED [ 19%]
python/tests/test_core/test_wave_search_init.py::TestWaveSearchInitialization::test_proper_wave_search_flow PASSED [ 19%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_standard_chess_initialization PASSED [ 19%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_initial_position PASSED [ 19%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_pawn_movement PASSED [ 19%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_knight_movement PASSED [ 19%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_bishop_movement PASSED [ 19%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_rook_movement PASSED [ 20%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_queen_movement PASSED [ 20%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_king_movement PASSED [ 20%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_castling_kingside PASSED [ 20%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_castling_queenside PASSED [ 20%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_en_passant PASSED [ 20%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_pawn_promotion PASSED [ 20%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_check_detection PASSED [ 20%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_checkmate_detection PASSED [ 20%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_stalemate_detection PASSED [ 20%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_threefold_repetition PASSED [ 21%]
python/tests/test_games/test_chess_gameplay.py::TestChessRules::test_fifty_move_rule PASSED [ 21%]
python/tests/test_games/test_chess_gameplay.py::TestChessMoveValidation::test_legal_moves_initial_position PASSED [ 21%]
python/tests/test_games/test_chess_gameplay.py::TestChessMoveValidation::test_pinned_piece_movement PASSED [ 21%]
python/tests/test_games/test_chess_gameplay.py::TestChessMoveValidation::test_check_evasion_only PASSED [ 21%]
python/tests/test_games/test_chess_gameplay.py::TestChessMoveValidation::test_capture_validation PASSED [ 21%]
python/tests/test_games/test_chess_gameplay.py::TestChessStateRepresentation::test_state_to_tensor_planes PASSED [ 21%]
python/tests/test_games/test_chess_gameplay.py::TestChessStateRepresentation::test_fen_conversion PASSED [ 21%]
python/tests/test_games/test_chess_gameplay.py::TestChessStateRepresentation::test_pgn_move_parsing PASSED [ 21%]
python/tests/test_games/test_chess_gameplay.py::TestChessStateRepresentation::test_move_history_tracking PASSED [ 22%]
python/tests/test_games/test_chess_gameplay.py::TestChessStateRepresentation::test_symmetries_not_applicable PASSED [ 22%]
python/tests/test_games/test_chess_gameplay.py::TestChessWithMCTS::test_mcts_finds_checkmate_in_one PASSED [ 22%]
python/tests/test_games/test_chess_gameplay.py::TestChessWithMCTS::test_mcts_avoids_blunders PASSED [ 22%]
python/tests/test_games/test_chess_gameplay.py::TestChessWithMCTS::test_mcts_opening_play PASSED [ 22%]
python/tests/test_games/test_chess_gameplay.py::TestChessWithMCTS::test_mcts_endgame_technique PASSED [ 22%]
python/tests/test_games/test_chess_gameplay.py::TestChessSpecialScenarios::test_discovered_check PASSED [ 22%]
python/tests/test_games/test_chess_gameplay.py::TestChessSpecialScenarios::test_double_check PASSED [ 22%]
python/tests/test_games/test_chess_gameplay.py::TestChessSpecialScenarios::test_zwischenzug PASSED [ 22%]
python/tests/test_games/test_chess_gameplay.py::TestChessSpecialScenarios::test_fortress_position PASSED [ 23%]
python/tests/test_games/test_chess_gameplay.py::TestChessPerformance::test_move_generation_performance SKIPPED [ 23%]
python/tests/test_games/test_chess_gameplay.py::TestChessPerformance::test_complex_position_performance SKIPPED [ 23%]
python/tests/test_games/test_chess_gameplay.py::TestChessVariants::test_chess960_initialization PASSED [ 23%]
python/tests/test_games/test_chess_gameplay.py::TestChessVariants::test_time_control_integration PASSED [ 23%]
python/tests/test_games/test_chess_gameplay.py::TestChessVariants::test_opening_book_integration PASSED [ 23%]
python/tests/test_games/test_chess_gameplay.py::TestChessVariants::test_endgame_tablebase PASSED [ 23%]
python/tests/test_games/test_go_gameplay.py::TestGoRules::test_standard_go_initialization PASSED [ 23%]
python/tests/test_games/test_go_gameplay.py::TestGoRules::test_custom_board_sizes PASSED [ 23%]
python/tests/test_games/test_go_gameplay.py::TestGoRules::test_stone_placement PASSED [ 23%]
python/tests/test_games/test_go_gameplay.py::TestGoRules::test_capture_single_stone PASSED [ 24%]
python/tests/test_games/test_go_gameplay.py::TestGoRules::test_ko_rule_basic PASSED [ 24%]
python/tests/test_games/test_go_gameplay.py::TestGoRules::test_suicide_prevention PASSED [ 24%]
python/tests/test_games/test_go_gameplay.py::TestGoRules::test_pass_move PASSED [ 24%]
python/tests/test_games/test_go_gameplay.py::TestGoRules::test_territory_scoring PASSED [ 24%]
python/tests/test_games/test_go_gameplay.py::TestGoMoveValidation::test_valid_moves_empty_board PASSED [ 24%]
python/tests/test_games/test_go_gameplay.py::TestGoMoveValidation::test_occupied_position_illegal PASSED [ 24%]
python/tests/test_games/test_go_gameplay.py::TestGoMoveValidation::test_ko_position_illegal PASSED [ 24%]
python/tests/test_games/test_go_gameplay.py::TestGoMoveValidation::test_suicide_illegal_unless_capture PASSED [ 24%]
python/tests/test_games/test_go_gameplay.py::TestGoStateRepresentation::test_state_to_tensor_planes PASSED [ 25%]
python/tests/test_games/test_go_gameplay.py::TestGoStateRepresentation::test_state_history_tracking PASSED [ 25%]
python/tests/test_games/test_go_gameplay.py::TestGoStateRepresentation::test_symmetries_go PASSED [ 25%]
python/tests/test_games/test_go_gameplay.py::TestGoWithMCTS::test_mcts_finds_capture PASSED [ 25%]
python/tests/test_games/test_go_gameplay.py::TestGoWithMCTS::test_mcts_avoids_suicide PASSED [ 25%]
python/tests/test_games/test_go_gameplay.py::TestGoWithMCTS::test_mcts_territory_awareness PASSED [ 25%]
python/tests/test_games/test_go_gameplay.py::TestGoEndgame::test_pass_decision PASSED [ 25%]
python/tests/test_games/test_go_gameplay.py::TestGoPerformance::test_move_generation_performance SKIPPED [ 25%]
python/tests/test_games/test_go_gameplay.py::TestGoPerformance::test_capture_detection_performance SKIPPED [ 25%]
python/tests/test_games/test_go_gameplay.py::TestGoSpecialRules::test_chinese_rules PASSED [ 25%]
python/tests/test_games/test_go_gameplay.py::TestGoSpecialRules::test_japanese_rules PASSED [ 26%]
python/tests/test_games/test_go_gameplay.py::TestGoSpecialRules::test_different_komi PASSED [ 26%]
python/tests/test_games/test_go_gameplay.py::TestGoSpecialRules::test_handicap_stones PASSED [ 26%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuRules::test_standard_gomoku_initialization PASSED [ 26%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuRules::test_custom_board_sizes PASSED [ 26%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuRules::test_win_detection_horizontal PASSED [ 26%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuRules::test_win_detection_vertical PASSED [ 26%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuRules::test_win_detection_diagonal_main PASSED [ 26%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuRules::test_win_detection_diagonal_anti PASSED [ 26%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuRules::test_no_win_with_four PASSED [ 27%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuRules::test_draw_detection PASSED [ 27%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuRules::test_edge_win_detection PASSED [ 27%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuMoveValidation::test_valid_moves_empty_board PASSED [ 27%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuMoveValidation::test_invalid_move_occupied_square PASSED [ 27%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuMoveValidation::test_invalid_move_out_of_bounds PASSED [ 27%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuMoveValidation::test_legal_moves_decrease PASSED [ 27%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuStateRepresentation::test_gomoku_piece_representation PASSED [ 27%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuStateRepresentation::test_gomoku_symmetries PASSED [ 27%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuWithMCTS::test_mcts_finds_obvious_win PASSED [ 28%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuWithMCTS::test_mcts_blocks_opponent_win PASSED [ 28%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuWithMCTS::test_mcts_opening_moves FAILED [ 28%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuWithMCTS::test_full_game_playout SKIPPED [ 28%]
python/tests/test_games/test_gomoku_gameplay.py::TestRenjuRules::test_renju_initialization PASSED [ 28%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuPerformance::test_move_generation_performance SKIPPED [ 28%]
python/tests/test_games/test_gomoku_gameplay.py::TestGomokuPerformance::test_win_detection_performance SKIPPED [ 28%]
python/tests/test_gpu/test_csr_storage.py::TestCSRStorageConfig::test_default_config PASSED [ 28%]
python/tests/test_gpu/test_csr_storage.py::TestCSRStorageConfig::test_custom_config PASSED [ 28%]
python/tests/test_gpu/test_csr_storage.py::TestCSRStorageInitialization::test_initialization PASSED [ 28%]
python/tests/test_gpu/test_csr_storage.py::TestCSRStorageInitialization::test_unlimited_edges PASSED [ 29%]
python/tests/test_gpu/test_csr_storage.py::TestCSRStorageInitialization::test_cuda_device_fallback PASSED [ 29%]
python/tests/test_gpu/test_csr_storage.py::TestCSRStorageInitialization::test_initial_tensor_values PASSED [ 29%]
python/tests/test_gpu/test_csr_storage.py::TestEdgeAddition::test_single_edge_addition PASSED [ 29%]
python/tests/test_gpu/test_csr_storage.py::TestEdgeAddition::test_multiple_edge_addition PASSED [ 29%]
python/tests/test_gpu/test_csr_storage.py::TestEdgeAddition::test_batch_edge_addition PASSED [ 29%]
python/tests/test_gpu/test_csr_storage.py::TestEdgeAddition::test_edge_addition_triggers_growth PASSED [ 29%]
python/tests/test_gpu/test_csr_storage.py::TestEdgeAddition::test_batch_addition_triggers_growth PASSED [ 29%]
python/tests/test_gpu/test_csr_storage.py::TestMemoryGrowth::test_edge_storage_growth PASSED [ 29%]
python/tests/test_gpu/test_csr_storage.py::TestMemoryGrowth::test_growth_preserves_data PASSED [ 30%]
python/tests/test_gpu/test_csr_storage.py::TestMemoryGrowth::test_max_edges_limit PASSED [ 30%]
python/tests/test_gpu/test_csr_storage.py::TestMemoryGrowth::test_reallocation_tracking PASSED [ 30%]
python/tests/test_gpu/test_csr_storage.py::TestMemoryGrowth::test_row_ptr_growth PASSED [ 30%]
python/tests/test_gpu/test_csr_storage.py::TestRowPointerManagement::test_row_pointer_update_needed PASSED [ 30%]
python/tests/test_gpu/test_csr_storage.py::TestRowPointerManagement::test_children_query_requires_update PASSED [ 30%]
python/tests/test_gpu/test_csr_storage.py::TestRowPointerManagement::test_rebuild_row_pointers PASSED [ 30%]
python/tests/test_gpu/test_csr_storage.py::TestRowPointerManagement::test_rebuild_with_large_table PASSED [ 30%]
python/tests/test_gpu/test_csr_storage.py::TestChildrenRetrieval::test_get_node_children PASSED [ 30%]
python/tests/test_gpu/test_csr_storage.py::TestChildrenRetrieval::test_get_empty_children PASSED [ 30%]
python/tests/test_gpu/test_csr_storage.py::TestChildrenRetrieval::test_get_children_edges PASSED [ 31%]
python/tests/test_gpu/test_csr_storage.py::TestResetFunctionality::test_reset_empty PASSED [ 31%]
python/tests/test_gpu/test_csr_storage.py::TestResetFunctionality::test_reset_with_data PASSED [ 31%]
python/tests/test_gpu/test_csr_storage.py::TestResetFunctionality::test_reset_preserves_capacity PASSED [ 31%]
python/tests/test_gpu/test_csr_storage.py::TestMemoryUsageAndStats::test_memory_usage_calculation PASSED [ 31%]
python/tests/test_gpu/test_csr_storage.py::TestMemoryUsageAndStats::test_edge_utilization PASSED [ 31%]
python/tests/test_gpu/test_csr_storage.py::TestMemoryUsageAndStats::test_edge_utilization_full PASSED [ 31%]
python/tests/test_gpu/test_csr_storage.py::TestEdgeCases::test_zero_max_edges PASSED [ 31%]
python/tests/test_gpu/test_csr_storage.py::TestEdgeCases::test_large_batch_addition PASSED [ 31%]
python/tests/test_gpu/test_csr_storage.py::TestEdgeCases::test_mixed_single_and_batch_addition PASSED [ 32%]
python/tests/test_gpu/test_csr_tree.py::TestCSRTreeConfig::test_default_config PASSED [ 32%]
python/tests/test_gpu/test_csr_tree.py::TestCSRTreeConfig::test_custom_config PASSED [ 32%]
python/tests/test_gpu/test_csr_tree.py::TestCSRTreeConfig::test_dtype_defaults PASSED [ 32%]
python/tests/test_gpu/test_csr_tree.py::TestCSRTreeConfig::test_custom_dtypes PASSED [ 32%]
python/tests/test_gpu/test_csr_tree.py::TestCSRTreeInitialization::test_basic_initialization PASSED [ 32%]
python/tests/test_gpu/test_csr_tree.py::TestCSRTreeInitialization::test_initialization_with_limits PASSED [ 32%]
python/tests/test_gpu/test_csr_tree.py::TestCSRTreeInitialization::test_device_fallback PASSED [ 32%]
python/tests/test_gpu/test_csr_tree.py::TestCSRTreeInitialization::test_batch_buffer_initialization PASSED [ 32%]
python/tests/test_gpu/test_csr_tree.py::TestNodeOperations::test_add_single_child PASSED [ 33%]
python/tests/test_gpu/test_csr_tree.py::TestNodeOperations::test_add_children_batch PASSED [ 33%]
python/tests/test_gpu/test_csr_tree.py::TestNodeOperations::test_add_children_with_states PASSED [ 33%]
python/tests/test_gpu/test_csr_tree.py::TestNodeOperations::test_duplicate_action_filtering PASSED [ 33%]
python/tests/test_gpu/test_csr_tree.py::TestNodeOperations::test_tree_capacity_limit PASSED [ 33%]
python/tests/test_gpu/test_csr_tree.py::TestChildrenRetrieval::test_get_children_basic PASSED [ 33%]
python/tests/test_gpu/test_csr_tree.py::TestChildrenRetrieval::test_get_children_empty PASSED [ 33%]
python/tests/test_gpu/test_csr_tree.py::TestChildrenRetrieval::test_get_children_invalid_node PASSED [ 33%]
python/tests/test_gpu/test_csr_tree.py::TestChildrenRetrieval::test_batch_get_children PASSED [ 33%]
python/tests/test_gpu/test_csr_tree.py::TestNodeData::test_visit_count_updates PASSED [ 33%]
python/tests/test_gpu/test_csr_tree.py::TestNodeData::test_value_updates PASSED [ 34%]
python/tests/test_gpu/test_csr_tree.py::TestNodeData::test_q_value_computation PASSED [ 34%]
python/tests/test_gpu/test_csr_tree.py::TestNodeData::test_terminal_and_expanded_flags PASSED [ 34%]
python/tests/test_gpu/test_csr_tree.py::TestVirtualLoss::test_virtual_loss_application PASSED [ 34%]
python/tests/test_gpu/test_csr_tree.py::TestVirtualLoss::test_virtual_loss_removal PASSED [ 34%]
python/tests/test_gpu/test_csr_tree.py::TestVirtualLoss::test_effective_visits_with_virtual_loss PASSED [ 34%]
python/tests/test_gpu/test_csr_tree.py::TestUCBSelection::test_single_node_selection PASSED [ 34%]
python/tests/test_gpu/test_csr_tree.py::TestUCBSelection::test_batch_ucb_selection PASSED [ 34%]
python/tests/test_gpu/test_csr_tree.py::TestUCBSelection::test_selection_no_children PASSED [ 34%]
python/tests/test_gpu/test_csr_tree.py::TestTreeManipulation::test_tree_reset PASSED [ 35%]
python/tests/test_gpu/test_csr_tree.py::TestTreeManipulation::test_shift_root_basic PASSED [ 35%]
python/tests/test_gpu/test_csr_tree.py::TestTreeManipulation::test_shift_root_preserves_subtree PASSED [ 35%]
python/tests/test_gpu/test_csr_tree.py::TestTreeManipulation::test_shift_root_to_self PASSED [ 35%]
python/tests/test_gpu/test_csr_tree.py::TestMemoryManagement::test_children_array_growth PASSED [ 35%]
python/tests/test_gpu/test_csr_tree.py::TestMemoryManagement::test_memory_usage_tracking PASSED [ 35%]
python/tests/test_gpu/test_csr_tree.py::TestMemoryManagement::test_performance_stats PASSED [ 35%]
python/tests/test_gpu/test_csr_tree.py::TestEdgeCases::test_empty_children_batch PASSED [ 35%]
python/tests/test_gpu/test_csr_tree.py::TestEdgeCases::test_invalid_node_operations PASSED [ 35%]
python/tests/test_gpu/test_csr_tree.py::TestEdgeCases::test_large_action_values PASSED [ 35%]
python/tests/test_gpu/test_csr_tree.py::TestEdgeCases::test_batch_operations_with_invalid_indices PASSED [ 36%]
python/tests/test_gpu/test_csr_tree.py::TestIntegration::test_with_mock_gpu_kernels PASSED [ 36%]
python/tests/test_gpu/test_csr_tree.py::TestIntegration::test_large_tree_performance SKIPPED [ 36%]
python/tests/test_gpu/test_csr_tree.py::TestIntegration::test_consistency_after_operations PASSED [ 36%]
python/tests/test_gpu/test_gpu_game_states.py::TestGPUGameStatesConfig::test_default_config PASSED [ 36%]
python/tests/test_gpu/test_gpu_game_states.py::TestGPUGameStatesConfig::test_custom_config PASSED [ 36%]
python/tests/test_gpu/test_gpu_game_states.py::TestGPUGameStatesConfig::test_board_size_defaults PASSED [ 36%]
python/tests/test_gpu/test_gpu_game_states.py::TestGPUGameStatesConfig::test_game_type_enum PASSED [ 36%]
python/tests/test_gpu/test_gpu_game_states.py::TestGPUGameStatesInitialization::test_gomoku_initialization PASSED [ 36%]
python/tests/test_gpu/test_gpu_game_states.py::TestGPUGameStatesInitialization::test_go_initialization PASSED [ 37%]
python/tests/test_gpu/test_gpu_game_states.py::TestGPUGameStatesInitialization::test_chess_initialization PASSED [ 37%]
python/tests/test_gpu/test_gpu_game_states.py::TestGPUGameStatesInitialization::test_move_history_initialization PASSED [ 37%]
python/tests/test_gpu/test_gpu_game_states.py::TestGPUGameStatesInitialization::test_allocation_tracking_initialization PASSED [ 37%]
python/tests/test_gpu/test_gpu_game_states.py::TestGPUGameStatesInitialization::test_board_initialization_failure PASSED [ 37%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateAllocation::test_allocate_single_state PASSED [ 37%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateAllocation::test_allocate_multiple_states PASSED [ 37%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateAllocation::test_allocate_beyond_capacity PASSED [ 37%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateAllocation::test_free_states PASSED [ 37%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateAllocation::test_free_unallocated_states PASSED [ 38%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateAllocation::test_mixed_free_states PASSED [ 38%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateAllocation::test_state_reset_on_allocation PASSED [ 38%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateAllocation::test_chess_initial_position PASSED [ 38%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateCloning::test_clone_single_state PASSED [ 38%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateCloning::test_clone_multiple_states PASSED [ 38%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateCloning::test_clone_with_history PASSED [ 38%]
python/tests/test_gpu/test_gpu_game_states.py::TestStateCloning::test_clone_go_specific_state PASSED [ 38%]
python/tests/test_gpu/test_gpu_game_states.py::TestLegalMoves::test_gomoku_legal_moves_empty_board PASSED [ 38%]
python/tests/test_gpu/test_gpu_game_states.py::TestLegalMoves::test_gomoku_legal_moves_with_stones PASSED [ 38%]
python/tests/test_gpu/test_gpu_game_states.py::TestLegalMoves::test_go_legal_moves_ko PASSED [ 39%]
python/tests/test_gpu/test_gpu_game_states.py::TestLegalMoves::test_batch_legal_moves PASSED [ 39%]
python/tests/test_gpu/test_gpu_game_states.py::TestLegalMoves::test_chess_legal_moves_placeholder PASSED [ 39%]
python/tests/test_gpu/test_gpu_game_states.py::TestMoveApplication::test_apply_single_move_gomoku PASSED [ 39%]
python/tests/test_gpu/test_gpu_game_states.py::TestMoveApplication::test_apply_multiple_moves PASSED [ 39%]
python/tests/test_gpu/test_gpu_game_states.py::TestMoveApplication::test_sequential_moves PASSED [ 39%]
python/tests/test_gpu/test_gpu_game_states.py::TestMoveApplication::test_move_history_rolling PASSED [ 39%]
python/tests/test_gpu/test_gpu_game_states.py::TestTerminalStates::test_terminal_state_tracking PASSED [ 39%]
python/tests/test_gpu/test_gpu_game_states.py::TestNeuralNetworkFeatures::test_gomoku_basic_features PASSED [ 39%]
python/tests/test_gpu/test_gpu_game_states.py::TestNeuralNetworkFeatures::test_go_basic_features PASSED [ 40%]
python/tests/test_gpu/test_gpu_game_states.py::TestNeuralNetworkFeatures::test_batch_feature_extraction PASSED [ 40%]
python/tests/test_gpu/test_gpu_game_states.py::TestNeuralNetworkFeatures::test_nn_features_batch_alias PASSED [ 40%]
python/tests/test_gpu/test_gpu_game_states.py::TestNeuralNetworkFeatures::test_move_history_features PASSED [ 40%]
python/tests/test_gpu/test_gpu_game_states.py::TestEnhancedFeatures::test_enable_enhanced_features PASSED [ 40%]
python/tests/test_gpu/test_gpu_game_states.py::TestEnhancedFeatures::test_set_enhanced_channels PASSED [ 40%]
python/tests/test_gpu/test_gpu_game_states.py::TestEnhancedFeatures::test_enhanced_feature_extraction PASSED [ 40%]
python/tests/test_gpu/test_gpu_game_states.py::TestEnhancedFeatures::test_enhanced_features_18_channels PASSED [ 40%]
python/tests/test_gpu/test_gpu_game_states.py::TestEnhancedFeatures::test_clear_enhanced_cache PASSED [ 40%]
python/tests/test_gpu/test_gpu_game_states.py::TestUtilityMethods::test_get_feature_planes PASSED [ 41%]
python/tests/test_gpu/test_gpu_game_states.py::TestUtilityMethods::test_get_state_info PASSED [ 41%]
python/tests/test_gpu/test_gpu_game_states.py::TestUtilityMethods::test_get_state_info_go PASSED [ 41%]
python/tests/test_gpu/test_gpu_game_states.py::TestUtilityMethods::test_get_state_info_chess PASSED [ 41%]
python/tests/test_gpu/test_gpu_game_states.py::TestEdgeCases::test_cuda_device_handling PASSED [ 41%]
python/tests/test_gpu/test_gpu_game_states.py::TestEdgeCases::test_full_capacity_allocation PASSED [ 41%]
python/tests/test_gpu/test_gpu_game_states.py::TestEdgeCases::test_empty_batch_operations PASSED [ 41%]
python/tests/test_gpu/test_gpu_game_states.py::TestEdgeCases::test_large_board_sizes PASSED [ 41%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestMCTSGPUAcceleratorInitialization::test_basic_initialization_cpu PASSED [ 41%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestMCTSGPUAcceleratorInitialization::test_initialization_cuda PASSED [ 41%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestMCTSGPUAcceleratorInitialization::test_default_device_selection PASSED [ 42%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestMCTSGPUAcceleratorInitialization::test_cuda_disabled_by_environment PASSED [ 42%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestKernelLoading::test_cuda_kernel_loading_success PASSED [ 42%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestKernelLoading::test_cuda_kernel_loading_failure PASSED [ 42%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestKernelLoading::test_no_cuda_manager_available PASSED [ 42%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestBatchedUCBSelection::test_pytorch_ucb_selection PASSED [ 42%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestBatchedUCBSelection::test_ucb_selection_no_children PASSED [ 42%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestVectorizedBackup::test_pytorch_backup_basic PASSED [ 42%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestVectorizedBackup::test_backup_with_invalid_nodes PASSED [ 42%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestFindExpansionNodes::test_find_expansion_nodes_basic PASSED [ 43%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestFindExpansionNodes::test_find_expansion_nodes_empty PASSED [ 43%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestBatchedAddChildren::test_batched_add_children_validation PASSED [ 43%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestBatchedAddChildren::test_batched_add_children_no_cuda PASSED [ 43%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestBatchedAddChildren::test_batched_add_children_cuda_success PASSED [ 43%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestStatistics::test_get_stats_pytorch PASSED [ 43%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestStatistics::test_get_stats_cuda PASSED [ 43%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestStatistics::test_reset_stats PASSED [ 43%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestGlobalInstance::test_get_mcts_gpu_accelerator PASSED [ 43%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestGlobalInstance::test_get_global_accelerator PASSED [ 43%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestGlobalInstance::test_process_isolation FAILED [ 44%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestGlobalInstance::test_validate_mcts_accelerator PASSED [ 44%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestQuantumUCBSelection::test_quantum_ucb_fallback PASSED [ 44%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestEdgeCases::test_empty_batch_ucb_selection PASSED [ 44%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestEdgeCases::test_device_mismatch_handling PASSED [ 44%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestEdgeCases::test_dtype_error_handling PASSED [ 44%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestPerformance::test_large_batch_ucb_selection SKIPPED [ 44%]
python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestPerformance::test_large_batch_backup SKIPPED [ 44%]
python/tests/test_gpu/test_memory_growth_fix.py::TestMemoryGrowthFix::test_growth_with_sufficient_max_capacity PASSED [ 44%]
python/tests/test_gpu/test_memory_growth_fix.py::TestMemoryGrowthFix::test_growth_failure_at_max_limit FAILED [ 45%]
python/tests/test_gpu/test_memory_growth_fix.py::TestMemoryGrowthFix::test_growth_tracking_with_valid_growth PASSED [ 45%]
python/tests/test_gpu/test_memory_pool.py::TestMemoryPoolConfig::test_default_config PASSED [ 45%]
python/tests/test_gpu/test_memory_pool.py::TestMemoryPoolConfig::test_custom_config PASSED [ 45%]
python/tests/test_gpu/test_memory_pool.py::TestTensorPool::test_initialization PASSED [ 45%]
python/tests/test_gpu/test_memory_pool.py::TestTensorPool::test_allocate_new_tensor PASSED [ 45%]
python/tests/test_gpu/test_memory_pool.py::TestTensorPool::test_deallocate_tensor PASSED [ 45%]
python/tests/test_gpu/test_memory_pool.py::TestTensorPool::test_reuse_deallocated_tensor PASSED [ 45%]
python/tests/test_gpu/test_memory_pool.py::TestTensorPool::test_allocate_larger_than_available PASSED [ 45%]
python/tests/test_gpu/test_memory_pool.py::TestTensorPool::test_statistics PASSED [ 46%]
python/tests/test_gpu/test_memory_pool.py::TestTensorPool::test_defragmentation PASSED [ 46%]
python/tests/test_gpu/test_memory_pool.py::TestTensorPool::test_thread_safety PASSED [ 46%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_initialization PASSED [ 46%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_pre_allocated_trees PASSED [ 46%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_allocate_tree PASSED [ 46%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_deallocate_tree PASSED [ 46%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_allocate_beyond_pre_allocated PASSED [ 46%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_grow_tree_buffers PASSED [ 46%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_grow_with_specific_capacity PASSED [ 46%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_copy_tree_data PASSED [ 47%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_defragmentation PASSED [ 47%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_auto_defragmentation PASSED [ 47%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_statistics PASSED [ 47%]
python/tests/test_gpu/test_memory_pool.py::TestCSRTreeMemoryPool::test_thread_safe_allocation PASSED [ 47%]
python/tests/test_gpu/test_memory_pool.py::TestGlobalMemoryPool::test_get_memory_pool_testing PASSED [ 47%]
python/tests/test_gpu/test_memory_pool.py::TestGlobalMemoryPool::test_get_memory_pool_singleton PASSED [ 47%]
python/tests/test_gpu/test_memory_pool.py::TestGlobalMemoryPool::test_reset_memory_pool PASSED [ 47%]
python/tests/test_gpu/test_memory_pool.py::TestGlobalMemoryPool::test_auto_config_gpu PASSED [ 47%]
python/tests/test_gpu/test_memory_pool.py::TestGlobalMemoryPool::test_auto_config_cpu PASSED [ 48%]
python/tests/test_gpu/test_memory_pool.py::TestGlobalMemoryPool::test_auto_config_worker PASSED [ 48%]
python/tests/test_gpu/test_memory_pool.py::TestGlobalMemoryPool::test_invalid_tree_growth PASSED [ 48%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeDataConfig::test_default_config PASSED [ 48%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeDataConfig::test_custom_config PASSED [ 48%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeDataManagerInitialization::test_initialization PASSED [ 48%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeDataManagerInitialization::test_small_max_nodes PASSED [ 48%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeDataManagerInitialization::test_very_small_initial_capacity PASSED [ 48%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeDataManagerInitialization::test_cuda_device_fallback PASSED [ 48%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeDataManagerInitialization::test_initial_tensor_values PASSED [ 48%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeAllocation::test_single_node_allocation PASSED [ 49%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeAllocation::test_multiple_node_allocation PASSED [ 49%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeAllocation::test_batch_allocation PASSED [ 49%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeAllocation::test_allocation_triggers_growth PASSED [ 49%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeAllocation::test_batch_allocation_triggers_growth PASSED [ 49%]
python/tests/test_gpu/test_node_data_manager.py::TestMemoryGrowth::test_storage_growth PASSED [ 49%]
python/tests/test_gpu/test_node_data_manager.py::TestMemoryGrowth::test_growth_preserves_data PASSED [ 49%]
python/tests/test_gpu/test_node_data_manager.py::TestMemoryGrowth::test_max_nodes_limit PASSED [ 49%]
python/tests/test_gpu/test_node_data_manager.py::TestMemoryGrowth::test_reallocation_tracking PASSED [ 49%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeOperations::test_update_operations PASSED [ 50%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeOperations::test_batch_updates PASSED [ 50%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeOperations::test_q_value_calculation PASSED [ 50%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeOperations::test_q_values_batch PASSED [ 50%]
python/tests/test_gpu/test_node_data_manager.py::TestVirtualLoss::test_virtual_loss_application PASSED [ 50%]
python/tests/test_gpu/test_node_data_manager.py::TestVirtualLoss::test_virtual_loss_removal PASSED [ 50%]
python/tests/test_gpu/test_node_data_manager.py::TestVirtualLoss::test_effective_visits PASSED [ 50%]
python/tests/test_gpu/test_node_data_manager.py::TestVirtualLoss::test_effective_values PASSED [ 50%]
python/tests/test_gpu/test_node_data_manager.py::TestVirtualLoss::test_virtual_loss_disabled PASSED [ 50%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeFlags::test_terminal_flag PASSED [ 51%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeFlags::test_expanded_flag PASSED [ 51%]
python/tests/test_gpu/test_node_data_manager.py::TestNodeFlags::test_combined_flags PASSED [ 51%]
python/tests/test_gpu/test_node_data_manager.py::TestReset::test_reset_empty PASSED [ 51%]
python/tests/test_gpu/test_node_data_manager.py::TestReset::test_reset_with_data PASSED [ 51%]
python/tests/test_gpu/test_node_data_manager.py::TestReset::test_reset_preserves_capacity PASSED [ 51%]
python/tests/test_gpu/test_node_data_manager.py::TestMemoryUsage::test_memory_usage_calculation PASSED [ 51%]
python/tests/test_gpu/test_node_data_manager.py::TestMemoryUsage::test_memory_usage_grows PASSED [ 51%]
python/tests/test_gpu/test_node_data_manager.py::TestEdgeCases::test_zero_max_nodes PASSED [ 51%]
python/tests/test_gpu/test_node_data_manager.py::TestEdgeCases::test_large_batch_allocation PASSED [ 51%]
python/tests/test_gpu/test_node_data_manager.py::TestEdgeCases::test_invalid_node_index PASSED [ 52%]
python/tests/test_gpu/test_node_data_manager.py::TestEdgeCases::test_cuda_memory_calculation PASSED [ 52%]
python/tests/test_gpu/test_ucb_selector.py::TestUCBConfig::test_default_config PASSED [ 52%]
python/tests/test_gpu/test_ucb_selector.py::TestUCBConfig::test_custom_config PASSED [ 52%]
python/tests/test_gpu/test_ucb_selector.py::TestUCBSelectorInitialization::test_initialization PASSED [ 52%]
python/tests/test_gpu/test_ucb_selector.py::TestUCBSelectorInitialization::test_cuda_device_fallback PASSED [ 52%]
python/tests/test_gpu/test_ucb_selector.py::TestSingleNodeSelection::test_basic_selection PASSED [ 52%]
python/tests/test_gpu/test_ucb_selector.py::TestSingleNodeSelection::test_empty_children PASSED [ 52%]
python/tests/test_gpu/test_ucb_selector.py::TestSingleNodeSelection::test_all_unvisited PASSED [ 52%]
python/tests/test_gpu/test_ucb_selector.py::TestSingleNodeSelection::test_custom_c_puct PASSED [ 53%]
python/tests/test_gpu/test_ucb_selector.py::TestSingleNodeSelection::test_ucb_calculation_correctness PASSED [ 53%]
python/tests/test_gpu/test_ucb_selector.py::TestBatchSelection::test_basic_batch_selection PASSED [ 53%]
python/tests/test_gpu/test_ucb_selector.py::TestBatchSelection::test_empty_batch PASSED [ 53%]
python/tests/test_gpu/test_ucb_selector.py::TestBatchSelection::test_no_valid_children PASSED [ 53%]
python/tests/test_gpu/test_ucb_selector.py::TestBatchSelection::test_all_unvisited_nodes PASSED [ 53%]
python/tests/test_gpu/test_ucb_selector.py::TestBatchSelection::test_temperature_scaling PASSED [ 53%]
python/tests/test_gpu/test_ucb_selector.py::TestBatchSelection::test_parent_visits_zero PASSED [ 53%]
python/tests/test_gpu/test_ucb_selector.py::TestVirtualLoss::test_virtual_loss_application PASSED [ 53%]
python/tests/test_gpu/test_ucb_selector.py::TestVirtualLoss::test_virtual_loss_disabled PASSED [ 53%]
python/tests/test_gpu/test_ucb_selector.py::TestTieBreaking::test_equal_ucb_scores PASSED [ 54%]
python/tests/test_gpu/test_ucb_selector.py::TestTieBreaking::test_stochastic_selection_unvisited PASSED [ 54%]
python/tests/test_gpu/test_ucb_selector.py::TestEdgeCases::test_single_valid_child PASSED [ 54%]
python/tests/test_gpu/test_ucb_selector.py::TestEdgeCases::test_large_batch PASSED [ 54%]
python/tests/test_gpu/test_ucb_selector.py::TestEdgeCases::test_extreme_c_puct_values FAILED [ 54%]
python/tests/test_gpu/test_ucb_selector.py::TestEdgeCases::test_numerical_stability PASSED [ 54%]
python/tests/test_gpu/test_ucb_selector.py::TestEdgeCases::test_zero_temperature PASSED [ 54%]
python/tests/test_integration/test_integration.py::TestFullMCTSIntegration::test_mcts_with_mock_evaluator SKIPPED [ 54%]
python/tests/test_integration/test_integration.py::TestFullMCTSIntegration::test_mcts_with_batch_coordinator SKIPPED [ 54%]
python/tests/test_integration/test_integration.py::TestFullMCTSIntegration::test_mcts_with_gpu_acceleration SKIPPED [ 55%]
python/tests/test_integration/test_integration.py::TestSelfPlayIntegration::test_self_play_game SKIPPED [ 55%]
python/tests/test_integration/test_integration.py::TestSelfPlayIntegration::test_parallel_self_play SKIPPED [ 55%]
python/tests/test_integration/test_integration.py::TestTrainingPipelineIntegration::test_data_generation_and_training_format SKIPPED [ 55%]
python/tests/test_integration/test_integration.py::TestTrainingPipelineIntegration::test_model_update_integration SKIPPED [ 55%]
python/tests/test_integration/test_integration.py::TestGPUServiceIntegration::test_gpu_service_with_mcts SKIPPED [ 55%]
python/tests/test_integration/test_integration.py::TestEndToEndPerformance::test_performance_benchmark SKIPPED [ 55%]
python/tests/test_integration/test_integration.py::TestEndToEndPerformance::test_memory_efficiency SKIPPED [ 55%]
python/tests/test_integration/test_integration_mcts.py::TestMCTSNeuralNetworkIntegration::test_mcts_with_neural_evaluator PASSED [ 55%]
python/tests/test_integration/test_integration_mcts.py::TestMCTSNeuralNetworkIntegration::test_neural_evaluation_caching PASSED [ 56%]
python/tests/test_integration/test_integration_mcts.py::TestMCTSNeuralNetworkIntegration::test_batch_neural_evaluation PASSED [ 56%]
python/tests/test_integration/test_integration_mcts.py::TestMCTSNeuralNetworkIntegration::test_gpu_neural_evaluation PASSED [ 56%]
python/tests/test_integration/test_integration_mcts.py::TestMCTSGPUAcceleration::test_gpu_tree_integration PASSED [ 56%]
python/tests/test_integration/test_integration_mcts.py::TestMCTSGPUAcceleration::test_gpu_node_data_manager FAILED [ 56%]
python/tests/test_integration/test_integration_mcts.py::TestMCTSGPUAcceleration::test_gpu_ucb_selection FAILED [ 56%]
python/tests/test_integration/test_integration_mcts.py::TestWaveSearchIntegration::test_wave_search_basic PASSED [ 56%]
python/tests/test_integration/test_integration_mcts.py::TestWaveSearchIntegration::test_adaptive_wave_sizing PASSED [ 56%]
python/tests/test_integration/test_integration_mcts.py::TestWaveSearchIntegration::test_wave_batching_efficiency PASSED [ 56%]
python/tests/test_integration/test_integration_mcts.py::TestTreeReuseIntegration::test_tree_reuse_basic FAILED [ 56%]
python/tests/test_integration/test_integration_mcts.py::TestTreeReuseIntegration::test_tree_reuse_memory_management FAILED [ 57%]
python/tests/test_integration/test_integration_mcts.py::TestTreeReuseIntegration::test_tree_reuse_disabled FAILED [ 57%]
python/tests/test_integration/test_integration_mcts.py::TestGameIntegration::test_gomoku_gameplay FAILED [ 57%]
python/tests/test_integration/test_integration_mcts.py::TestGameIntegration::test_different_board_sizes FAILED [ 57%]
python/tests/test_integration/test_integration_mcts.py::TestGameIntegration::test_terminal_state_handling PASSED [ 57%]
python/tests/test_integration/test_integration_mcts.py::TestConcurrentMCTS::test_thread_safe_evaluation PASSED [ 57%]
python/tests/test_integration/test_integration_mcts.py::TestConcurrentMCTS::test_parallel_game_analysis PASSED [ 57%]
python/tests/test_integration/test_integration_mcts.py::TestPerformanceOptimizations::test_virtual_loss_integration FAILED [ 57%]
python/tests/test_integration/test_integration_mcts.py::TestPerformanceOptimizations::test_fast_ucb_computation FAILED [ 57%]
python/tests/test_integration/test_integration_training.py::TestTrainingPipelineIntegration::test_pipeline_initialization PASSED [ 58%]
python/tests/test_integration/test_integration_training.py::TestTrainingPipelineIntegration::test_single_iteration FAILED [ 58%]
python/tests/test_integration/test_integration_training.py::TestTrainingPipelineIntegration::test_training_data_flow FAILED [ 58%]
python/tests/test_integration/test_integration_training.py::TestTrainingPipelineIntegration::test_checkpoint_workflow FAILED [ 58%]
python/tests/test_integration/test_integration_training.py::TestTrainingPipelineIntegration::test_best_model_update FAILED [ 58%]
python/tests/test_integration/test_integration_training.py::TestSelfPlayIntegration::test_self_play_with_current_model FAILED [ 58%]
python/tests/test_integration/test_integration_training.py::TestSelfPlayIntegration::test_gpu_service_integration FAILED [ 58%]
python/tests/test_integration/test_integration_training.py::TestSelfPlayIntegration::test_multi_worker_coordination FAILED [ 58%]
python/tests/test_integration/test_integration_training.py::TestArenaIntegration::test_arena_model_comparison FAILED [ 58%]
python/tests/test_integration/test_integration_training.py::TestArenaIntegration::test_elo_tracking_integration FAILED [ 58%]
python/tests/test_integration/test_integration_training.py::TestTrainingLoopIntegration::test_full_training_loop FAILED [ 59%]
python/tests/test_integration/test_integration_training.py::TestTrainingLoopIntegration::test_training_metrics_tracking FAILED [ 59%]
python/tests/test_integration/test_integration_training.py::TestErrorHandlingIntegration::test_self_play_error_recovery FAILED [ 59%]
python/tests/test_integration/test_integration_training.py::TestErrorHandlingIntegration::test_training_error_recovery FAILED [ 59%]
python/tests/test_integration/test_integration_training.py::TestErrorHandlingIntegration::test_checkpoint_corruption_handling PASSED [ 59%]
python/tests/test_integration/test_integration_training.py::TestPerformanceIntegration::test_memory_management FAILED [ 59%]
python/tests/test_integration/test_integration_training.py::TestPerformanceIntegration::test_training_speed FAILED [ 59%]
python/tests/test_integration/test_integration_training.py::TestDistributedIntegration::test_multi_gpu_setup PASSED [ 59%]
python/tests/test_integration/test_integration_training.py::TestDistributedIntegration::test_distributed_self_play FAILED [ 59%]
python/tests/test_integration/test_multiprocessing.py::TestMultiWorkerSelfPlay::test_basic_multi_worker_setup SKIPPED [ 60%]
python/tests/test_integration/test_multiprocessing.py::TestMultiWorkerSelfPlay::test_worker_game_generation SKIPPED [ 60%]
python/tests/test_integration/test_multiprocessing.py::TestMultiWorkerSelfPlay::test_worker_coordination SKIPPED [ 60%]
python/tests/test_integration/test_multiprocessing.py::TestMultiWorkerSelfPlay::test_worker_crash_recovery SKIPPED [ 60%]
python/tests/test_integration/test_multiprocessing.py::TestMultiWorkerSelfPlay::test_queue_timeout_handling SKIPPED [ 60%]
python/tests/test_integration/test_multiprocessing.py::TestGPUServiceIntegration::test_gpu_service_startup SKIPPED [ 60%]
python/tests/test_integration/test_multiprocessing.py::TestGPUServiceIntegration::test_gpu_service_evaluation SKIPPED [ 60%]
python/tests/test_integration/test_multiprocessing.py::TestGPUServiceIntegration::test_gpu_service_batch_handling SKIPPED [ 60%]
python/tests/test_integration/test_multiprocessing.py::TestGPUServiceIntegration::test_gpu_service_process_isolation SKIPPED [ 60%]
python/tests/test_integration/test_multiprocessing.py::TestBatchCoordinatorMultiprocess::test_cross_process_coordination SKIPPED [ 61%]
python/tests/test_integration/test_multiprocessing.py::TestBatchCoordinatorMultiprocess::test_coordinator_performance_under_load SKIPPED [ 61%]
python/tests/test_integration/test_multiprocessing.py::TestSharedMemoryHandling::test_shared_memory_game_states SKIPPED [ 61%]
python/tests/test_integration/test_multiprocessing.py::TestSharedMemoryHandling::test_shared_memory_cleanup SKIPPED [ 61%]
python/tests/test_integration/test_multiprocessing.py::TestProcessCleanup::test_graceful_shutdown SKIPPED [ 61%]
python/tests/test_integration/test_multiprocessing.py::TestProcessCleanup::test_force_termination SKIPPED [ 61%]
python/tests/test_integration/test_multiprocessing.py::TestProcessCleanup::test_zombie_process_prevention SKIPPED [ 61%]
python/tests/test_integration/test_multiprocessing.py::TestDeadlockPrevention::test_queue_deadlock_prevention SKIPPED [ 61%]
python/tests/test_integration/test_multiprocessing.py::TestDeadlockPrevention::test_lock_ordering SKIPPED [ 61%]
python/tests/test_integration/test_multiprocessing.py::TestResourceContention::test_gpu_contention SKIPPED [ 61%]
python/tests/test_integration/test_multiprocessing.py::TestResourceContention::test_cpu_contention SKIPPED [ 62%]
python/tests/test_integration/test_multiprocessing.py::TestDistributedTraining::test_distributed_self_play SKIPPED [ 62%]
python/tests/test_integration/test_multiprocessing_skip.py::TestMultiWorkerSelfPlay::test_basic_multi_worker_setup SKIPPED [ 62%]
python/tests/test_integration/test_multiprocessing_skip.py::TestMultiWorkerSelfPlay::test_worker_game_generation SKIPPED [ 62%]
python/tests/test_integration/test_multiprocessing_skip.py::TestMultiWorkerSelfPlay::test_worker_coordination SKIPPED [ 62%]
python/tests/test_integration/test_multiprocessing_skip.py::TestMultiWorkerSelfPlay::test_worker_crash_recovery SKIPPED [ 62%]
python/tests/test_integration/test_multiprocessing_skip.py::TestMultiWorkerSelfPlay::test_queue_timeout_handling SKIPPED [ 62%]
python/tests/test_integration/test_multiprocessing_skip.py::TestGPUServiceIntegration::test_gpu_service_startup SKIPPED [ 62%]
python/tests/test_integration/test_multiprocessing_skip.py::TestGPUServiceIntegration::test_gpu_service_evaluation SKIPPED [ 62%]
python/tests/test_integration/test_multiprocessing_skip.py::TestGPUServiceIntegration::test_gpu_service_batch_handling SKIPPED [ 63%]
python/tests/test_integration/test_multiprocessing_skip.py::TestGPUServiceIntegration::test_gpu_service_process_isolation SKIPPED [ 63%]
python/tests/test_integration/test_multiprocessing_skip.py::TestBatchCoordinatorMultiprocess::test_cross_process_coordination SKIPPED [ 63%]
python/tests/test_integration/test_multiprocessing_skip.py::TestBatchCoordinatorMultiprocess::test_coordinator_performance_under_load SKIPPED [ 63%]
python/tests/test_integration/test_multiprocessing_skip.py::TestSharedMemoryHandling::test_shared_memory_game_states SKIPPED [ 63%]
python/tests/test_integration/test_multiprocessing_skip.py::TestSharedMemoryHandling::test_shared_memory_cleanup SKIPPED [ 63%]
python/tests/test_integration/test_multiprocessing_skip.py::TestProcessCleanup::test_graceful_shutdown SKIPPED [ 63%]
python/tests/test_integration/test_multiprocessing_skip.py::TestProcessCleanup::test_force_termination SKIPPED [ 63%]
python/tests/test_integration/test_multiprocessing_skip.py::TestProcessCleanup::test_zombie_process_prevention SKIPPED [ 63%]
python/tests/test_integration/test_multiprocessing_skip.py::TestDeadlockPrevention::test_queue_deadlock_prevention SKIPPED [ 64%]
python/tests/test_integration/test_multiprocessing_skip.py::TestDeadlockPrevention::test_lock_ordering SKIPPED [ 64%]
python/tests/test_integration/test_multiprocessing_skip.py::TestResourceContention::test_gpu_contention SKIPPED [ 64%]
python/tests/test_integration/test_multiprocessing_skip.py::TestResourceContention::test_cpu_contention SKIPPED [ 64%]
python/tests/test_integration/test_multiprocessing_skip.py::TestDistributedTraining::test_distributed_self_play SKIPPED [ 64%]
python/tests/test_integration/test_performance.py::TestMCTSPerformance::test_simulations_per_second PASSED [ 64%]
python/tests/test_integration/test_performance.py::TestMCTSPerformance::test_batch_evaluation_throughput PASSED [ 64%]
python/tests/test_integration/test_performance.py::TestMCTSPerformance::test_tree_operation_performance PASSED [ 64%]
python/tests/test_integration/test_performance.py::TestMCTSPerformance::test_gpu_acceleration_speedup PASSED [ 64%]
python/tests/test_integration/test_performance.py::TestMCTSPerformance::test_memory_usage_patterns FAILED [ 64%]
python/tests/test_integration/test_performance.py::TestScalingPerformance::test_scaling_with_tree_size PASSED [ 65%]
python/tests/test_integration/test_performance.py::TestScalingPerformance::test_scaling_with_board_size PASSED [ 65%]
python/tests/test_integration/test_performance.py::TestScalingPerformance::test_batch_size_scaling PASSED [ 65%]
python/tests/test_integration/test_performance.py::TestMultiGamePerformance::test_concurrent_game_performance PASSED [ 65%]
python/tests/test_integration/test_performance.py::TestMultiGamePerformance::test_game_switching_overhead PASSED [ 65%]
python/tests/test_integration/test_performance.py::TestTrainingPerformance::test_self_play_throughput FAILED [ 65%]
python/tests/test_integration/test_performance.py::TestTrainingPerformance::test_training_iteration_time FAILED [ 65%]
python/tests/test_integration/test_performance.py::TestOptimizationImpact::test_virtual_loss_impact PASSED [ 65%]
python/tests/test_integration/test_performance.py::TestOptimizationImpact::test_batch_coordinator_impact PASSED [ 65%]
python/tests/test_integration/test_performance.py::TestMemoryBandwidth::test_gpu_memory_bandwidth PASSED [ 66%]
python/tests/test_neural_networks/test_arena_module.py::TestArenaConfig::test_default_config PASSED [ 66%]
python/tests/test_neural_networks/test_arena_module.py::TestArenaConfig::test_custom_config PASSED [ 66%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_initialization PASSED [ 66%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_update_ratings_basic PASSED [ 66%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_update_ratings_draws PASSED [ 66%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_adaptive_k_factor PASSED [ 66%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_k_factor_vs_random PASSED [ 66%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_recent_performance_tracking PASSED [ 66%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_should_play_vs_random_logic PASSED [ 66%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_elo_growth_rate PASSED [ 67%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_rating_deflation PASSED [ 67%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_protect_best_elo PASSED [ 67%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_confidence_intervals PASSED [ 67%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_leaderboard PASSED [ 67%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_detailed_leaderboard PASSED [ 67%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_validation_metrics PASSED [ 67%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_save_load PASSED [ 67%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_health_report PASSED [ 67%]
python/tests/test_neural_networks/test_arena_module.py::TestELOTracker::test_cleanup_old_iterations PASSED [ 68%]
python/tests/test_neural_networks/test_arena_module.py::TestArenaManager::test_initialization PASSED [ 68%]
python/tests/test_neural_networks/test_arena_module.py::TestArenaManager::test_compare_models_sequential PASSED [ 68%]
python/tests/test_neural_networks/test_arena_module.py::TestArenaManager::test_compare_models_vs_random PASSED [ 68%]
python/tests/test_neural_networks/test_arena_module.py::TestArenaManager::test_cuda_error_handling PASSED [ 68%]
python/tests/test_neural_networks/test_arena_module.py::TestArenaManager::test_config_serialization PASSED [ 68%]
python/tests/test_neural_networks/test_arena_module.py::TestIntegration::test_tournament_simulation PASSED [ 68%]
python/tests/test_neural_networks/test_arena_module.py::TestIntegration::test_iteration_progression PASSED [ 68%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestResNetEvaluatorInitialization::test_init_with_model PASSED [ 68%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestResNetEvaluatorInitialization::test_init_without_model PASSED [ 69%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestResNetEvaluatorInitialization::test_init_with_checkpoint PASSED [ 69%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestResNetEvaluatorInitialization::test_init_with_network_config PASSED [ 69%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestResNetEvaluatorInitialization::test_init_with_input_channels PASSED [ 69%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestResNetEvaluatorInitialization::test_device_selection PASSED [ 69%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestConfigLoading::test_load_config_from_experiment_dir PASSED [ 69%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestConfigLoading::test_load_config_fallback_to_default PASSED [ 69%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestConfigLoading::test_load_config_handles_errors PASSED [ 69%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestForwardPass::test_forward_model PASSED [ 69%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestForwardPass::test_forward_batch_gpu_native PASSED [ 69%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestForwardPass::test_temperature_scaling PASSED [ 70%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestForwardPass::test_evaluate_single FAILED [ 70%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestForwardPass::test_evaluate_batch FAILED [ 70%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestForwardPass::test_mixed_precision FAILED [ 70%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestStatistics::test_get_stats FAILED [ 70%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestStatistics::test_reset_statistics PASSED [ 70%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestCheckpointing::test_save_checkpoint PASSED [ 70%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestCheckpointing::test_save_checkpoint_with_metadata PASSED [ 70%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestCheckpointing::test_from_checkpoint FAILED [ 70%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestGameSpecificCreation::test_create_evaluator_for_game PASSED [ 71%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestGameSpecificCreation::test_create_with_custom_architecture PASSED [ 71%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestGameSpecificCreation::test_create_with_config_path PASSED [ 71%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestGameSpecificCreation::test_create_chess_evaluator PASSED [ 71%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestGameSpecificCreation::test_create_go_evaluator PASSED [ 71%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestGameSpecificCreation::test_create_gomoku_evaluator PASSED [ 71%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestEdgeCases::test_empty_batch_evaluation FAILED [ 71%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestEdgeCases::test_single_sample_batch FAILED [ 71%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestEdgeCases::test_no_legal_moves FAILED [ 71%]
python/tests/test_neural_networks/test_resnet_evaluator.py::TestEdgeCases::test_device_mismatch_handling FAILED [ 71%]
python/tests/test_neural_networks/test_resnet_model.py::TestResNetConfig::test_default_config PASSED [ 72%]
python/tests/test_neural_networks/test_resnet_model.py::TestResNetConfig::test_custom_config PASSED [ 72%]
python/tests/test_neural_networks/test_resnet_model.py::TestResidualBlock::test_initialization PASSED [ 72%]
python/tests/test_neural_networks/test_resnet_model.py::TestResidualBlock::test_forward_pass PASSED [ 72%]
python/tests/test_neural_networks/test_resnet_model.py::TestResidualBlock::test_gradient_flow PASSED [ 72%]
python/tests/test_neural_networks/test_resnet_model.py::TestPolicyHead::test_initialization PASSED [ 72%]
python/tests/test_neural_networks/test_resnet_model.py::TestPolicyHead::test_forward_pass PASSED [ 72%]
python/tests/test_neural_networks/test_resnet_model.py::TestPolicyHead::test_weight_initialization PASSED [ 72%]
python/tests/test_neural_networks/test_resnet_model.py::TestPolicyHead::test_custom_hidden_size PASSED [ 72%]
python/tests/test_neural_networks/test_resnet_model.py::TestValueHead::test_initialization PASSED [ 73%]
python/tests/test_neural_networks/test_resnet_model.py::TestValueHead::test_forward_pass PASSED [ 73%]
python/tests/test_neural_networks/test_resnet_model.py::TestValueHead::test_weight_initialization PASSED [ 73%]
python/tests/test_neural_networks/test_resnet_model.py::TestValueHead::test_initial_output_near_zero PASSED [ 73%]
python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_initialization FAILED [ 73%]
python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_layer_structure PASSED [ 73%]
python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_forward_pass FAILED [ 73%]
python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_gradient_computation FAILED [ 73%]
python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_parameter_count PASSED [ 73%]
python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_eval_mode FAILED [ 74%]
python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_training_mode FAILED [ 74%]
python/tests/test_neural_networks/test_resnet_model.py::TestModelCreation::test_create_chess_model PASSED [ 74%]
python/tests/test_neural_networks/test_resnet_model.py::TestModelCreation::test_create_go_model PASSED [ 74%]
python/tests/test_neural_networks/test_resnet_model.py::TestModelCreation::test_create_gomoku_model PASSED [ 74%]
python/tests/test_neural_networks/test_resnet_model.py::TestModelCreation::test_create_with_custom_params PASSED [ 74%]
python/tests/test_neural_networks/test_resnet_model.py::TestModelCreation::test_invalid_game_type PASSED [ 74%]
python/tests/test_neural_networks/test_resnet_model.py::TestWeightInitialization::test_conv_initialization PASSED [ 74%]
python/tests/test_neural_networks/test_resnet_model.py::TestWeightInitialization::test_batchnorm_initialization PASSED [ 74%]
python/tests/test_neural_networks/test_resnet_model.py::TestWeightInitialization::test_spatial_symmetry_breaking PASSED [ 74%]
python/tests/test_neural_networks/test_resnet_model.py::TestMemoryUsage::test_batch_processing FAILED [ 75%]
python/tests/test_neural_networks/test_resnet_model.py::TestMemoryUsage::test_large_model_creation FAILED [ 75%]
python/tests/test_neural_networks/test_self_play_module.py::TestSelfPlayManagerInitialization::test_initialization PASSED [ 75%]
python/tests/test_neural_networks/test_self_play_module.py::TestSelfPlayManagerInitialization::test_game_type_conversion PASSED [ 75%]
python/tests/test_neural_networks/test_self_play_module.py::TestSelfPlayManagerInitialization::test_input_representation_handling PASSED [ 75%]
python/tests/test_neural_networks/test_self_play_module.py::TestSequentialSelfPlay::test_sequential_generation PASSED [ 75%]
python/tests/test_neural_networks/test_self_play_module.py::TestSequentialSelfPlay::test_progress_bar_handling PASSED [ 75%]
python/tests/test_neural_networks/test_self_play_module.py::TestParallelSelfPlay::test_parallel_generation_basic PASSED [ 75%]
python/tests/test_neural_networks/test_self_play_module.py::TestParallelSelfPlay::test_resource_allocation PASSED [ 75%]
python/tests/test_neural_networks/test_self_play_module.py::TestParallelSelfPlay::test_worker_timeout_handling PASSED [ 76%]
python/tests/test_neural_networks/test_self_play_module.py::TestSingleGameGeneration::test_play_single_game_basic PASSED [ 76%]
python/tests/test_neural_networks/test_self_play_module.py::TestSingleGameGeneration::test_temperature_annealing PASSED [ 76%]
python/tests/test_neural_networks/test_self_play_module.py::TestSingleGameGeneration::test_resignation_logic PASSED [ 76%]
python/tests/test_neural_networks/test_self_play_module.py::TestSingleGameGeneration::test_natural_termination PASSED [ 76%]
python/tests/test_neural_networks/test_self_play_module.py::TestSingleGameGeneration::test_move_selection PASSED [ 76%]
python/tests/test_neural_networks/test_self_play_module.py::TestSingleGameGeneration::test_state_synchronization_error PASSED [ 76%]
python/tests/test_neural_networks/test_self_play_module.py::TestValueAssignment::test_assign_values_consistently PASSED [ 76%]
python/tests/test_neural_networks/test_self_play_module.py::TestValueAssignment::test_assign_values_draw PASSED [ 76%]
python/tests/test_neural_networks/test_self_play_module.py::TestValueAssignment::test_assign_values_player2_wins PASSED [ 76%]
python/tests/test_neural_networks/test_self_play_module.py::TestGameCompletionLogging::test_log_game_completion_basic PASSED [ 77%]
python/tests/test_neural_networks/test_self_play_module.py::TestGameCompletionLogging::test_sanity_check_uniform_length PASSED [ 77%]
python/tests/test_neural_networks/test_self_play_module.py::TestGameCompletionLogging::test_sanity_check_resignation_values PASSED [ 77%]
python/tests/test_neural_networks/test_self_play_module.py::TestMCTSCreation::test_create_mcts_sequential PASSED [ 77%]
python/tests/test_neural_networks/test_self_play_module.py::TestMCTSCreation::test_create_mcts_worker PASSED [ 77%]
python/tests/test_neural_networks/test_self_play_module.py::TestMCTSCreation::test_mcts_config_parameters PASSED [ 77%]
python/tests/test_neural_networks/test_self_play_module.py::TestWorkerFunction::test_worker_wrapper_success PASSED [ 77%]
python/tests/test_neural_networks/test_self_play_module.py::TestWorkerFunction::test_worker_wrapper_error PASSED [ 77%]
python/tests/test_neural_networks/test_self_play_module.py::TestIntegration::test_generate_games_sequential PASSED [ 77%]
python/tests/test_neural_networks/test_self_play_module.py::TestIntegration::test_generate_games_parallel PASSED [ 78%]
python/tests/test_neural_networks/test_self_play_module.py::TestIntegration::test_adaptive_resignation_threshold PASSED [ 78%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_initialization PASSED [ 78%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_load_components PASSED [ 78%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_training_step PASSED [ 78%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_self_play_collection PASSED [ 78%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_network_training PASSED [ 78%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_model_evaluation FAILED [ 78%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_checkpoint_saving FAILED [ 78%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_checkpoint_loading FAILED [ 79%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_resume_training PASSED [ 79%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_training_loop PASSED [ 79%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_training_with_early_stopping PASSED [ 79%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_mixed_precision_training PASSED [ 79%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_learning_rate_scheduling PASSED [ 79%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_metrics_tracking FAILED [ 79%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_tensorboard_logging SKIPPED [ 79%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_distributed_training PASSED [ 79%]
python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_memory_optimization PASSED [ 79%]
python/tests/test_neural_networks/test_training_pipeline.py::TestTrainingMetrics::test_metrics_initialization SKIPPED [ 80%]
python/tests/test_neural_networks/test_training_pipeline.py::TestTrainingMetrics::test_add_training_metrics SKIPPED [ 80%]
python/tests/test_neural_networks/test_training_pipeline.py::TestTrainingMetrics::test_add_evaluation_metrics SKIPPED [ 80%]
python/tests/test_neural_networks/test_training_pipeline.py::TestTrainingMetrics::test_get_summary SKIPPED [ 80%]
python/tests/test_neural_networks/test_training_pipeline.py::TestTrainingMetrics::test_plot_metrics SKIPPED [ 80%]
python/tests/test_neural_networks/test_training_pipeline.py::TestModelCheckpoint::test_checkpoint_creation SKIPPED [ 80%]
python/tests/test_neural_networks/test_training_pipeline.py::TestModelCheckpoint::test_checkpoint_save_load SKIPPED [ 80%]
python/tests/test_neural_networks/test_training_pipeline.py::TestModelCheckpoint::test_checkpoint_compatibility SKIPPED [ 80%]
python/tests/test_utils/test_batch_coordinator.py::TestRequestBatchingCoordinator::test_basic_initialization PASSED [ 80%]
python/tests/test_utils/test_batch_coordinator.py::TestRequestBatchingCoordinator::test_multiprocessing_detection PASSED [ 81%]
python/tests/test_utils/test_batch_coordinator.py::TestRequestBatchingCoordinator::test_multiprocessing_disables_cross_worker_batching PASSED [ 81%]
python/tests/test_utils/test_batch_coordinator.py::TestRequestBatchingCoordinator::test_start_stop PASSED [ 81%]
python/tests/test_utils/test_batch_coordinator.py::TestBatchCoordination::test_immediate_batch_processing PASSED [ 81%]
python/tests/test_utils/test_batch_coordinator.py::TestBatchCoordination::test_small_batch_coordination PASSED [ 81%]
python/tests/test_utils/test_batch_coordinator.py::TestBatchCoordination::test_adaptive_timeout PASSED [ 81%]
python/tests/test_utils/test_batch_coordinator.py::TestBatchProcessing::test_batch_combination FAILED [ 81%]
python/tests/test_utils/test_batch_coordinator.py::TestBatchProcessing::test_mixed_tensor_numpy_inputs PASSED [ 81%]
python/tests/test_utils/test_batch_coordinator.py::TestErrorHandling::test_missing_queues_error PASSED [ 81%]
python/tests/test_utils/test_batch_coordinator.py::TestErrorHandling::test_gpu_service_timeout_handling PASSED [ 82%]
python/tests/test_utils/test_batch_coordinator.py::TestErrorHandling::test_batch_processing_error_recovery PASSED [ 82%]
python/tests/test_utils/test_batch_coordinator.py::TestErrorHandling::test_coordination_loop_error_recovery PASSED [ 82%]
python/tests/test_utils/test_batch_coordinator.py::TestStatistics::test_statistics_tracking FAILED [ 82%]
python/tests/test_utils/test_batch_coordinator.py::TestStatistics::test_cross_worker_batch_tracking PASSED [ 82%]
python/tests/test_utils/test_batch_coordinator.py::TestGlobalCoordinator::test_get_global_coordinator PASSED [ 82%]
python/tests/test_utils/test_batch_coordinator.py::TestGlobalCoordinator::test_process_isolation PASSED [ 82%]
python/tests/test_utils/test_batch_coordinator.py::TestGlobalCoordinator::test_cleanup_global_coordinator PASSED [ 82%]
python/tests/test_utils/test_batch_coordinator.py::TestIntegration::test_concurrent_requests_stress SKIPPED [ 82%]
python/tests/test_utils/test_batch_coordinator.py::TestIntegration::test_mixed_batch_sizes PASSED [ 82%]
python/tests/test_utils/test_config_system.py::TestAlphaZeroConfigInitialization::test_default_initialization PASSED [ 83%]
python/tests/test_utils/test_config_system.py::TestAlphaZeroConfigInitialization::test_initialization_with_overrides PASSED [ 83%]
python/tests/test_utils/test_config_system.py::TestAlphaZeroConfigInitialization::test_all_sections_present PASSED [ 83%]
python/tests/test_utils/test_config_system.py::TestGameConfig::test_game_config_defaults PASSED [ 83%]
python/tests/test_utils/test_config_system.py::TestGameConfig::test_game_specific_settings PASSED [ 83%]
python/tests/test_utils/test_config_system.py::TestGameConfig::test_invalid_game_type PASSED [ 83%]
python/tests/test_utils/test_config_system.py::TestNetworkConfig::test_network_config_defaults PASSED [ 83%]
python/tests/test_utils/test_config_system.py::TestNetworkConfig::test_architecture_validation PASSED [ 83%]
python/tests/test_utils/test_config_system.py::TestNetworkConfig::test_input_representation_options FAILED [ 83%]
python/tests/test_utils/test_config_system.py::TestTrainingConfig::test_training_config_defaults FAILED [ 84%]
python/tests/test_utils/test_config_system.py::TestTrainingConfig::test_optimizer_settings FAILED [ 84%]
python/tests/test_utils/test_config_system.py::TestTrainingConfig::test_data_generation_settings FAILED [ 84%]
python/tests/test_utils/test_config_system.py::TestTrainingConfig::test_learning_rate_schedule FAILED [ 84%]
python/tests/test_utils/test_config_system.py::TestMCTSConfig::test_mcts_config_defaults FAILED [ 84%]
python/tests/test_utils/test_config_system.py::TestMCTSConfig::test_performance_settings FAILED [ 84%]
python/tests/test_utils/test_config_system.py::TestMCTSConfig::test_wave_sizing_settings FAILED [ 84%]
python/tests/test_utils/test_config_system.py::TestArenaConfig::test_arena_config_defaults FAILED [ 84%]
python/tests/test_utils/test_config_system.py::TestArenaConfig::test_elo_settings FAILED [ 84%]
python/tests/test_utils/test_config_system.py::TestResourceConfig::test_resource_config_defaults FAILED [ 84%]
python/tests/test_utils/test_config_system.py::TestResourceConfig::test_memory_allocation FAILED [ 85%]
python/tests/test_utils/test_config_system.py::TestConfigSerialization::test_to_dict PASSED [ 85%]
python/tests/test_utils/test_config_system.py::TestConfigSerialization::test_from_dict PASSED [ 85%]
python/tests/test_utils/test_config_system.py::TestConfigSerialization::test_save_yaml PASSED [ 85%]
python/tests/test_utils/test_config_system.py::TestConfigSerialization::test_load_yaml PASSED [ 85%]
python/tests/test_utils/test_config_system.py::TestConfigSerialization::test_save_json FAILED [ 85%]
python/tests/test_utils/test_config_system.py::TestConfigMerging::test_merge_configs_basic FAILED [ 85%]
python/tests/test_utils/test_config_system.py::TestConfigMerging::test_deep_merge FAILED [ 85%]
python/tests/test_utils/test_config_system.py::TestConfigMerging::test_merge_with_new_keys FAILED [ 85%]
python/tests/test_utils/test_config_system.py::TestConfigValidation::test_validate_valid_config PASSED [ 86%]
python/tests/test_utils/test_config_system.py::TestConfigValidation::test_validate_game_config FAILED [ 86%]
python/tests/test_utils/test_config_system.py::TestConfigValidation::test_validate_network_config FAILED [ 86%]
python/tests/test_utils/test_config_system.py::TestConfigValidation::test_validate_training_config FAILED [ 86%]
python/tests/test_utils/test_config_system.py::TestConfigValidation::test_validate_mcts_config FAILED [ 86%]
python/tests/test_utils/test_config_system.py::TestConfigUtilities::test_load_config_file_not_found PASSED [ 86%]
python/tests/test_utils/test_config_system.py::TestConfigUtilities::test_load_config_invalid_format PASSED [ 86%]
python/tests/test_utils/test_config_system.py::TestConfigUtilities::test_save_config_create_directories PASSED [ 86%]
python/tests/test_utils/test_config_system.py::TestConfigUtilities::test_config_string_representation FAILED [ 86%]
python/tests/test_utils/test_config_system.py::TestConfigUtilities::test_config_equality PASSED [ 87%]
python/tests/test_utils/test_config_system.py::TestConfigDefaults::test_experiment_defaults FAILED [ 87%]
python/tests/test_utils/test_config_system.py::TestConfigDefaults::test_log_defaults FAILED [ 87%]
python/tests/test_utils/test_config_system.py::TestConfigDefaults::test_device_defaults FAILED [ 87%]
python/tests/test_utils/test_config_system.py::TestConfigIntegration::test_full_training_config PASSED [ 87%]
python/tests/test_utils/test_config_system.py::TestConfigIntegration::test_experiment_config_loading PASSED [ 87%]
python/tests/test_utils/test_config_system.py::TestConfigIntegration::test_distributed_training_config PASSED [ 87%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestGPUServiceInitialization::test_initialization PASSED [ 87%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestGPUServiceInitialization::test_device_setup PASSED [ 87%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestGPUServiceInitialization::test_request_queue_creation PASSED [ 87%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestGPUServiceInitialization::test_statistics_initialization PASSED [ 88%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestServiceLifecycle::test_start_service PASSED [ 88%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestServiceLifecycle::test_stop_service PASSED [ 88%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestServiceLifecycle::test_restart_service PASSED [ 88%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestServiceLifecycle::test_service_already_running PASSED [ 88%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestQueueManagement::test_get_request_queue PASSED [ 88%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestQueueManagement::test_create_worker_queue PASSED [ 88%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestQueueManagement::test_get_existing_worker_queue PASSED [ 88%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestQueueManagement::test_cleanup_worker_queue PASSED [ 88%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestBatchProcessing::test_process_batch_basic PASSED [ 89%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestBatchProcessing::test_dynamic_batching PASSED [ 89%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestBatchProcessing::test_batch_statistics_tracking PASSED [ 89%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestErrorHandling::test_model_forward_error PASSED [ 89%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestErrorHandling::test_cuda_error_recovery PASSED [ 89%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestErrorHandling::test_queue_full_handling PASSED [ 89%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestErrorHandling::test_worker_queue_error PASSED [ 89%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestResourceManagement::test_memory_monitoring PASSED [ 89%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestResourceManagement::test_memory_limit_enforcement PASSED [ 89%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestResourceManagement::test_resource_cleanup PASSED [ 89%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestPerformanceOptimizations::test_batch_padding_optimization PASSED [ 90%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestPerformanceOptimizations::test_pinned_memory_usage PASSED [ 90%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestPerformanceOptimizations::test_mixed_precision_inference PASSED [ 90%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestPerformanceOptimizations::test_profiling_mode PASSED [ 90%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestConcurrency::test_multiple_workers PASSED [ 90%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestConcurrency::test_request_ordering PASSED [ 90%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestIntegration::test_end_to_end_evaluation PASSED [ 90%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestIntegration::test_stress_test PASSED [ 90%]
python/tests/test_utils/test_gpu_evaluator_service.py::TestIntegration::test_graceful_shutdown PASSED [ 90%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestOptimizedRemoteEvaluatorInitialization::test_initialization PASSED [ 91%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestOptimizedRemoteEvaluatorInitialization::test_initialization_without_coordination PASSED [ 91%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestOptimizedRemoteEvaluatorInitialization::test_coordinator_setup PASSED [ 91%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestOptimizedRemoteEvaluatorInitialization::test_statistics_initialization PASSED [ 91%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestSynchronousEvaluation::test_evaluate_single_state PASSED [ 91%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestSynchronousEvaluation::test_evaluate_multiple_states PASSED [ 91%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestSynchronousEvaluation::test_evaluate_batch PASSED [ 91%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestSynchronousEvaluation::test_evaluate_batch_with_temperatures PASSED [ 91%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestBatchCoordinatorIntegration::test_worker_id_propagation PASSED [ 91%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestBatchCoordinatorIntegration::test_coordinator_timeout_handling PASSED [ 92%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestBatchCoordinatorIntegration::test_coordinator_batch_optimization PASSED [ 92%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestErrorHandling::test_queue_full_error PASSED [ 92%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestErrorHandling::test_response_timeout PASSED [ 92%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestErrorHandling::test_invalid_response_type PASSED [ 92%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestPerformanceOptimizations::test_batch_size_optimization PASSED [ 92%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestPerformanceOptimizations::test_statistics_tracking PASSED [ 92%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestPerformanceOptimizations::test_reset_statistics PASSED [ 92%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestIntegration::test_temperature_handling PASSED [ 92%]
python/tests/test_utils/test_optimized_remote_evaluator.py::TestIntegration::test_legal_mask_handling PASSED [ 92%]
python/tests/test_utils/test_training_metrics.py::TestMetricSnapshot::test_creation PASSED [ 93%]
python/tests/test_utils/test_training_metrics.py::TestMetricSnapshot::test_optional_fields PASSED [ 93%]
python/tests/test_utils/test_training_metrics.py::TestMetricSnapshot::test_custom_metrics PASSED [ 93%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_initialization PASSED [ 93%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_record_training_step PASSED [ 93%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_record_evaluation PASSED [ 93%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_record_self_play_metrics PASSED [ 93%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_custom_metrics PASSED [ 93%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_moving_average FAILED [ 93%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_metric_trend PASSED [ 94%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_best_metrics_tracking PASSED [ 94%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_auto_save PASSED [ 94%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_save_and_load PASSED [ 94%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_get_summary PASSED [ 94%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_export_for_plotting PASSED [ 94%]
python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_print_summary PASSED [ 94%]
python/tests/test_utils/test_training_metrics.py::TestMetricsVisualizer::test_visualizer_creation PASSED [ 94%]
python/tests/test_utils/test_training_metrics.py::TestMetricsVisualizer::test_plot_training_curves FAILED [ 94%]
python/tests/test_utils/test_training_metrics.py::TestMetricsVisualizer::test_plot_no_data PASSED [ 94%]
python/tests/test_utils/test_training_metrics.py::TestMetricsVisualizer::test_plot_no_matplotlib PASSED [ 95%]
python/tests/test_utils/test_validation.py::TestStateValidation::test_validate_state_valid PASSED [ 95%]
python/tests/test_utils/test_validation.py::TestStateValidation::test_validate_state_wrong_shape PASSED [ 95%]
python/tests/test_utils/test_validation.py::TestStateValidation::test_validate_state_wrong_channels PASSED [ 95%]
python/tests/test_utils/test_validation.py::TestStateValidation::test_validate_state_wrong_dtype PASSED [ 95%]
python/tests/test_utils/test_validation.py::TestStateValidation::test_validate_state_nan_values PASSED [ 95%]
python/tests/test_utils/test_validation.py::TestStateValidation::test_validate_state_inf_values PASSED [ 95%]
python/tests/test_utils/test_validation.py::TestActionValidation::test_validate_action_valid PASSED [ 95%]
python/tests/test_utils/test_validation.py::TestActionValidation::test_validate_action_out_of_bounds PASSED [ 95%]
python/tests/test_utils/test_validation.py::TestActionValidation::test_validate_action_wrong_type PASSED [ 96%]
python/tests/test_utils/test_validation.py::TestActionValidation::test_validate_action_with_legal_moves PASSED [ 96%]
python/tests/test_utils/test_validation.py::TestPolicyValidation::test_validate_policy_valid PASSED [ 96%]
python/tests/test_utils/test_validation.py::TestPolicyValidation::test_validate_policy_wrong_size PASSED [ 96%]
python/tests/test_utils/test_validation.py::TestPolicyValidation::test_validate_policy_negative_values PASSED [ 96%]
python/tests/test_utils/test_validation.py::TestPolicyValidation::test_validate_policy_not_normalized PASSED [ 96%]
python/tests/test_utils/test_validation.py::TestPolicyValidation::test_validate_policy_tolerance PASSED [ 96%]
python/tests/test_utils/test_validation.py::TestPolicyValidation::test_validate_policy_with_mask PASSED [ 96%]
python/tests/test_utils/test_validation.py::TestValueValidation::test_validate_value_valid PASSED [ 96%]
python/tests/test_utils/test_validation.py::TestValueValidation::test_validate_value_out_of_range PASSED [ 97%]
python/tests/test_utils/test_validation.py::TestValueValidation::test_validate_value_wrong_type PASSED [ 97%]
python/tests/test_utils/test_validation.py::TestValueValidation::test_validate_value_nan PASSED [ 97%]
python/tests/test_utils/test_validation.py::TestValueValidation::test_validate_value_custom_range PASSED [ 97%]
python/tests/test_utils/test_validation.py::TestBatchValidation::test_validate_batch_states_valid PASSED [ 97%]
python/tests/test_utils/test_validation.py::TestBatchValidation::test_validate_batch_states_wrong_shape PASSED [ 97%]
python/tests/test_utils/test_validation.py::TestBatchValidation::test_validate_batch_states_empty PASSED [ 97%]
python/tests/test_utils/test_validation.py::TestBatchValidation::test_validate_batch_policies_valid PASSED [ 97%]
python/tests/test_utils/test_validation.py::TestBatchValidation::test_validate_batch_policies_not_normalized PASSED [ 97%]
python/tests/test_utils/test_validation.py::TestBatchValidation::test_validate_batch_values_valid PASSED [ 97%]
python/tests/test_utils/test_validation.py::TestBatchValidation::test_validate_batch_values_out_of_range PASSED [ 98%]
python/tests/test_utils/test_validation.py::TestConfigValidation::test_validate_config_parameters_valid PASSED [ 98%]
python/tests/test_utils/test_validation.py::TestConfigValidation::test_validate_config_parameters_out_of_range PASSED [ 98%]
python/tests/test_utils/test_validation.py::TestConfigValidation::test_validate_config_parameters_wrong_type PASSED [ 98%]
python/tests/test_utils/test_validation.py::TestConfigValidation::test_validate_config_parameters_missing_required PASSED [ 98%]
python/tests/test_utils/test_validation.py::TestModelOutputValidation::test_validate_model_output_valid PASSED [ 98%]
python/tests/test_utils/test_validation.py::TestModelOutputValidation::test_validate_model_output_wrong_shape PASSED [ 98%]
python/tests/test_utils/test_validation.py::TestModelOutputValidation::test_validate_model_output_numpy PASSED [ 98%]
python/tests/test_utils/test_validation.py::TestGameExampleValidation::test_validate_game_example_valid PASSED [ 98%]
python/tests/test_utils/test_validation.py::TestGameExampleValidation::test_validate_game_example_missing_field PASSED [ 99%]
python/tests/test_utils/test_validation.py::TestGameExampleValidation::test_validate_game_example_invalid_state PASSED [ 99%]
python/tests/test_utils/test_validation.py::TestGameExampleValidation::test_validate_game_example_inconsistent PASSED [ 99%]
python/tests/test_utils/test_validation.py::TestTensorUtilities::test_check_tensor_device PASSED [ 99%]
python/tests/test_utils/test_validation.py::TestTensorUtilities::test_check_tensor_dtype PASSED [ 99%]
python/tests/test_utils/test_validation.py::TestTensorUtilities::test_ensure_numpy_array PASSED [ 99%]
python/tests/test_utils/test_validation.py::TestTensorUtilities::test_ensure_torch_tensor PASSED [ 99%]
python/tests/test_utils/test_validation.py::TestEdgeCases::test_validate_empty_arrays PASSED [ 99%]
python/tests/test_utils/test_validation.py::TestEdgeCases::test_validate_special_values PASSED [ 99%]
python/tests/test_utils/test_validation.py::TestEdgeCases::test_type_conversion_edge_cases PASSED [100%]

=================================== FAILURES ===================================
________________ TestMCTSTreeReuse.test_subtree_reuse_disabled _________________
python/tests/test_core/test_mcts.py:554: in test_subtree_reuse_disabled
    assert nodes_after_second < nodes_after_first * 1.5
E   assert 101 < (31 * 1.5)
________ TestTerminalDetectionDebug.test_terminal_position_step_by_step ________
python/tests/test_core/test_terminal_detection_debug.py:78: in test_terminal_position_step_by_step
    assert False, "Debug test - examine output above"
E   AssertionError: Debug test - examine output above
E   assert False
----------------------------- Captured stdout call -----------------------------
DEBUG: State is terminal: True
DEBUG: Game result: GameResult.WIN_PLAYER1
DEBUG: Initial tree nodes: 1
DEBUG: Root state index: 0
DEBUG: Tree nodes after root init: 1
DEBUG: GPU game state terminal: True
DEBUG: Running one simulation...
DEBUG: Completed simulations: 1
DEBUG: Tree nodes after one simulation: 1
DEBUG: Root has 0 children
DEBUG: Actions: tensor([], device='cuda:0', dtype=torch.int32)
_______________ TestNodeInformation.test_get_root_children_info ________________
python/tests/test_core/test_tree_operations.py:249: in test_get_root_children_info
    assert torch.allclose(ret_actions, torch.tensor(actions, device=device))
E   RuntimeError: Int did not match Long
____________ TestWaveBackpropagation.test_parallel_backpropagation _____________
python/tests/test_core/test_wave_search.py:530: in test_parallel_backpropagation
    assert abs(root_value - (-0.1)) < 1e-5
E   assert 0.6 < 1e-05
E    +  where 0.6 = abs((0.5 - -0.1))
__ TestWaveSearchInitialization.test_expand_batch_vectorized_without_run_wave __
python/tests/test_core/test_wave_search_init.py:32: in test_expand_batch_vectorized_without_run_wave
    expanded_nodes = wave_search._expand_batch_vectorized(
python/mcts/core/wave_search.py:732: in _expand_batch_vectorized
    child_state_indices = self.game_states.clone_states(parent_indices, num_clones)
python/mcts/gpu/gpu_game_states.py:261: in clone_states
    parent_mapping = torch.repeat_interleave(parent_indices, num_clones_per_parent)
E   RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)
_ TestWaveSearchInitialization.test_expand_batch_vectorized_with_manual_initialization _
python/tests/test_core/test_wave_search_init.py:59: in test_expand_batch_vectorized_with_manual_initialization
    expanded_nodes = wave_search._expand_batch_vectorized(torch.tensor([0]))
python/mcts/core/wave_search.py:732: in _expand_batch_vectorized
    child_state_indices = self.game_states.clone_states(parent_indices, num_clones)
python/mcts/gpu/gpu_game_states.py:261: in clone_states
    parent_mapping = torch.repeat_interleave(parent_indices, num_clones_per_parent)
E   RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)
__________________ TestGomokuWithMCTS.test_mcts_opening_moves __________________
python/tests/test_games/test_gomoku_gameplay.py:367: in test_mcts_opening_moves
    assert center_area_prob > 0.5  # Most probability in center
E   assert np.float64(0.43500000000000005) > 0.5
__________________ TestGlobalInstance.test_process_isolation ___________________
python/tests/test_gpu/test_mcts_gpu_accelerator.py:485: in test_process_isolation
    process.start()
/usr/lib/python3.10/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
/usr/lib/python3.10/multiprocessing/context.py:224: in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
/usr/lib/python3.10/multiprocessing/context.py:288: in _Popen
    return Popen(process_obj)
/usr/lib/python3.10/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
/usr/lib/python3.10/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
/usr/lib/python3.10/multiprocessing/popen_spawn_posix.py:47: in _launch
    reduction.dump(process_obj, fp)
/usr/lib/python3.10/multiprocessing/reduction.py:60: in dump
    ForkingPickler(file, protocol).dump(obj)
E   AttributeError: Can't pickle local object 'TestGlobalInstance.test_process_isolation.<locals>.get_accelerator_id'
_____________ TestMemoryGrowthFix.test_growth_failure_at_max_limit _____________
python/tests/test_gpu/test_memory_growth_fix.py:65: in test_growth_failure_at_max_limit
    with pytest.raises(RuntimeError, match="Cannot grow edge storage beyond"):
E   Failed: DID NOT RAISE <class 'RuntimeError'>
----------------------------- Captured stdout call -----------------------------
DEBUG: Initial capacity: 10
DEBUG: Max edges: 20
DEBUG: Trying to grow beyond max to: 21
___________________ TestEdgeCases.test_extreme_c_puct_values ___________________
python/tests/test_gpu/test_ucb_selector.py:484: in test_extreme_c_puct_values
    assert best_idx == expected_idx
E   assert 2 == 1
______________ TestMCTSGPUAcceleration.test_gpu_node_data_manager ______________
python/tests/test_integration/test_integration_mcts.py:200: in test_gpu_node_data_manager
    with patch('mcts.core.mcts.NodeDataManager', return_value=node_manager):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: <module 'mcts.core.mcts' from '/home/cosmosapjw/omoknuni_quantum/python/mcts/core/mcts.py'> does not have the attribute 'NodeDataManager'
________________ TestMCTSGPUAcceleration.test_gpu_ucb_selection ________________
python/tests/test_integration/test_integration_mcts.py:226: in test_gpu_ucb_selection
    selected = ucb_selector.select_batch(
E   TypeError: UCBSelector.select_batch() got an unexpected keyword argument 'batch_size'
________________ TestTreeReuseIntegration.test_tree_reuse_basic ________________
python/tests/test_integration/test_integration_mcts.py:333: in test_tree_reuse_basic
    visits1 = mcts_instance.get_visits_distribution().copy()
E   AttributeError: 'MCTS' object has no attribute 'get_visits_distribution'
__________ TestTreeReuseIntegration.test_tree_reuse_memory_management __________
python/tests/test_integration/test_integration_mcts.py:359: in test_tree_reuse_memory_management
    initial_nodes = mcts_instance.get_tree_stats()['total_nodes']
E   AttributeError: 'MCTS' object has no attribute 'get_tree_stats'
______________ TestTreeReuseIntegration.test_tree_reuse_disabled _______________
python/tests/test_integration/test_integration_mcts.py:379: in test_tree_reuse_disabled
    nodes_after_first = mcts.get_tree_stats()['total_nodes']
E   AttributeError: 'MCTS' object has no attribute 'get_tree_stats'
___________________ TestGameIntegration.test_gomoku_gameplay ___________________
python/tests/test_integration/test_integration_mcts.py:402: in test_gomoku_gameplay
    policy = mcts.search(state)
python/mcts/core/mcts.py:242: in search
    self._ensure_root_initialized(state)
python/mcts/core/mcts.py:268: in _ensure_root_initialized
    self._initialize_root(state)
python/mcts/core/mcts.py:621: in _initialize_root
    obs = self.cached_game.state_to_numpy(root_state)
E   AttributeError: 'AlphaZeroEvaluator' object has no attribute 'state_to_numpy'
________________ TestGameIntegration.test_different_board_sizes ________________
python/tests/test_integration/test_integration_mcts.py:422: in test_different_board_sizes
    policy = mcts.search(state)
python/mcts/core/mcts.py:242: in search
    self._ensure_root_initialized(state)
python/mcts/core/mcts.py:268: in _ensure_root_initialized
    self._initialize_root(state)
python/mcts/core/mcts.py:621: in _initialize_root
    obs = self.cached_game.state_to_numpy(root_state)
E   AttributeError: 'AlphaZeroEvaluator' object has no attribute 'state_to_numpy'
__________ TestPerformanceOptimizations.test_virtual_loss_integration __________
python/tests/test_integration/test_integration_mcts.py:531: in test_virtual_loss_integration
    stats = mcts.get_tree_stats()
E   AttributeError: 'MCTS' object has no attribute 'get_tree_stats'
____________ TestPerformanceOptimizations.test_fast_ucb_computation ____________
python/tests/test_integration/test_integration_mcts.py:544: in test_fast_ucb_computation
    mcts_fast.search(state)
python/mcts/core/mcts.py:242: in search
    self._ensure_root_initialized(state)
python/mcts/core/mcts.py:268: in _ensure_root_initialized
    self._initialize_root(state)
python/mcts/core/mcts.py:621: in _initialize_root
    obs = self.cached_game.state_to_numpy(root_state)
E   AttributeError: 'AlphaZeroEvaluator' object has no attribute 'state_to_numpy'
____________ TestTrainingPipelineIntegration.test_single_iteration _____________
python/tests/test_integration/test_integration_training.py:116: in test_single_iteration
    training_pipeline.train_iteration(iteration=1)
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute 'train_iteration'
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:44 - INFO - Logging configured - Console: INFO, File: /tmp/tmpw7f6c36q/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204544.log
2025-07-07 20:45:44 - INFO - Experiment directory: /tmp/tmpw7f6c36q/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:44 - INFO - Configuration saved to /tmp/tmpw7f6c36q/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:44 - INFO - Starting fresh training
___________ TestTrainingPipelineIntegration.test_training_data_flow ____________
python/tests/test_integration/test_integration_training.py:129: in test_training_data_flow
    with patch.object(training_pipeline.self_play_manager, 'generate_games',
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute 'self_play_manager'
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:44 - INFO - Logging configured - Console: INFO, File: /tmp/tmp1rjbi7o4/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204544.log
2025-07-07 20:45:44 - INFO - Experiment directory: /tmp/tmp1rjbi7o4/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:44 - INFO - Configuration saved to /tmp/tmp1rjbi7o4/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:44 - INFO - Starting fresh training
___________ TestTrainingPipelineIntegration.test_checkpoint_workflow ___________
python/tests/test_integration/test_integration_training.py:148: in test_checkpoint_workflow
    training_pipeline._save_checkpoint(1, checkpoint_path)
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute '_save_checkpoint'. Did you mean: 'save_checkpoint'?
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:44 - INFO - Logging configured - Console: INFO, File: /tmp/tmpqkd6ou91/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204544.log
2025-07-07 20:45:44 - INFO - Experiment directory: /tmp/tmpqkd6ou91/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:44 - INFO - Configuration saved to /tmp/tmpqkd6ou91/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:44 - INFO - Starting fresh training
____________ TestTrainingPipelineIntegration.test_best_model_update ____________
python/tests/test_integration/test_integration_training.py:161: in test_best_model_update
    with patch.object(training_pipeline.arena_manager, 'compare_models') as mock_arena:
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute 'arena_manager'
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:44 - INFO - Logging configured - Console: INFO, File: /tmp/tmpdwha1yey/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204544.log
2025-07-07 20:45:44 - INFO - Experiment directory: /tmp/tmpdwha1yey/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:44 - INFO - Configuration saved to /tmp/tmpdwha1yey/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:44 - INFO - Starting fresh training
__________ TestSelfPlayIntegration.test_self_play_with_current_model ___________
python/tests/test_integration/test_integration_training.py:188: in test_self_play_with_current_model
    examples = training_pipeline.self_play_manager.generate_games(
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute 'self_play_manager'
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:44 - INFO - Logging configured - Console: INFO, File: /tmp/tmpdor9rkwj/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204544.log
2025-07-07 20:45:44 - INFO - Experiment directory: /tmp/tmpdor9rkwj/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:44 - INFO - Configuration saved to /tmp/tmpdor9rkwj/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:45 - INFO - Starting fresh training
_____________ TestSelfPlayIntegration.test_gpu_service_integration _____________
python/tests/test_integration/test_integration_training.py:216: in test_gpu_service_integration
    assert gpu_service.state.name == 'RUNNING'
E   AttributeError: 'GPUEvaluatorService' object has no attribute 'state'. Did you mean: 'stats'?
----------------------------- Captured stdout call -----------------------------
[07/07/2025-20:45:46] [TRT] [E] IBuilder::buildSerializedNetwork: Error Code 4: API Usage Error (Tensor output_0 set to TensorLocation::kHOST but only kDEVICE is supported (host outputs are not supported).)
----------------------------- Captured stderr call -----------------------------
2025-07-07 20:45:45 - INFO - Worker 2406533: Acquired lock for TensorRT conversion
2025-07-07 20:45:45 - INFO - Worker 2406533: Starting TensorRT conversion...
2025-07-07 20:45:45 - INFO - Converting gomoku model (policy_size=225)
2025-07-07 20:45:46 - ERROR - Worker 2406533: TensorRT conversion failed: 'TRTModule' object has no attribute 'context'
2025-07-07 20:45:46 - WARNING - Worker 2406533: TensorRT conversion failed, falling back to PyTorch
------------------------------ Captured log call -------------------------------
INFO     mcts.utils.tensorrt_manager:tensorrt_manager.py:140 Worker 2406533: Acquired lock for TensorRT conversion
INFO     mcts.utils.tensorrt_manager:tensorrt_manager.py:148 Worker 2406533: Starting TensorRT conversion...
INFO     mcts.neural_networks.tensorrt_converter:tensorrt_converter.py:93 Converting gomoku model (policy_size=225)
DEBUG    mcts.neural_networks.tensorrt_converter:tensorrt_converter.py:104 Converting model to TensorRT with input shape: (18, 15, 15)
DEBUG    mcts.neural_networks.tensorrt_converter:tensorrt_converter.py:105 FP16 mode: True, INT8 mode: False
DEBUG    mcts.neural_networks.tensorrt_converter:tensorrt_converter.py:106 Optimizing for batch sizes: [1, 8, 32, 64, 128, 256, 512]
DEBUG    mcts.neural_networks.tensorrt_converter:tensorrt_converter.py:139 TensorRT conversion completed successfully
ERROR    mcts.utils.tensorrt_manager:tensorrt_manager.py:179 Worker 2406533: TensorRT conversion failed: 'TRTModule' object has no attribute 'context'
WARNING  mcts.utils.gpu_evaluator_service:gpu_evaluator_service.py:180 Worker 2406533: TensorRT conversion failed, falling back to PyTorch
____________ TestSelfPlayIntegration.test_multi_worker_coordination ____________
python/tests/test_integration/test_integration_training.py:235: in test_multi_worker_coordination
    examples = training_pipeline.self_play_manager._parallel_self_play(
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute 'self_play_manager'
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:46 - INFO - Logging configured - Console: INFO, File: /tmp/tmp97lokyb_/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204546.log
2025-07-07 20:45:46 - INFO - Experiment directory: /tmp/tmp97lokyb_/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:46 - INFO - Configuration saved to /tmp/tmp97lokyb_/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:46 - INFO - Starting fresh training
_______________ TestArenaIntegration.test_arena_model_comparison _______________
python/tests/test_integration/test_integration_training.py:257: in test_arena_model_comparison
    with patch.object(training_pipeline.arena_manager.game_interface, 'is_terminal',
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute 'arena_manager'
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:46 - INFO - Logging configured - Console: INFO, File: /tmp/tmpjanagtrt/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204546.log
2025-07-07 20:45:46 - INFO - Experiment directory: /tmp/tmpjanagtrt/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:46 - INFO - Configuration saved to /tmp/tmpjanagtrt/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:46 - INFO - Starting fresh training
______________ TestArenaIntegration.test_elo_tracking_integration ______________
python/tests/test_integration/test_integration_training.py:273: in test_elo_tracking_integration
    elo_tracker = training_pipeline.arena_manager.elo_tracker
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute 'arena_manager'
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:46 - INFO - Logging configured - Console: INFO, File: /tmp/tmplmjsozjj/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204546.log
2025-07-07 20:45:46 - INFO - Experiment directory: /tmp/tmplmjsozjj/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:46 - INFO - Configuration saved to /tmp/tmplmjsozjj/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:46 - INFO - Starting fresh training
_____________ TestTrainingLoopIntegration.test_full_training_loop ______________
python/tests/test_integration/test_integration_training.py:309: in test_full_training_loop
    with patch.object(pipeline, '_train_epoch'):
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
/usr/lib/python3.10/unittest/mock.py:1420: in get_original
    raise AttributeError(
E   AttributeError: <mcts.neural_networks.unified_training_pipeline.UnifiedTrainingPipeline object at 0x70da4cd12590> does not have the attribute '_train_epoch'
----------------------------- Captured stderr call -----------------------------
2025-07-07 20:45:46 - INFO - Logging configured - Console: INFO, File: /tmp/tmpbh9790e6/omoknuni_experiments/test_integration/logs/training_20250707_204546.log
2025-07-07 20:45:46 - INFO - Experiment directory: /tmp/tmpbh9790e6/omoknuni_experiments/test_integration
2025-07-07 20:45:46 - INFO - Configuration saved to /tmp/tmpbh9790e6/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:46 - INFO - Starting fresh training
__________ TestTrainingLoopIntegration.test_training_metrics_tracking __________
python/tests/test_integration/test_integration_training.py:319: in test_training_metrics_tracking
    with patch.object(training_pipeline.self_play_manager, 'generate_games',
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute 'self_play_manager'
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:46 - INFO - Logging configured - Console: INFO, File: /tmp/tmp6y4vl0lb/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204546.log
2025-07-07 20:45:46 - INFO - Experiment directory: /tmp/tmp6y4vl0lb/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:46 - INFO - Configuration saved to /tmp/tmp6y4vl0lb/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:46 - INFO - Starting fresh training
__________ TestErrorHandlingIntegration.test_self_play_error_recovery __________
python/tests/test_integration/test_integration_training.py:343: in test_self_play_error_recovery
    with patch.object(training_pipeline.self_play_manager, 'generate_games') as mock_sp:
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute 'self_play_manager'
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:46 - INFO - Logging configured - Console: INFO, File: /tmp/tmp3s8ggt1f/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204546.log
2025-07-07 20:45:46 - INFO - Experiment directory: /tmp/tmp3s8ggt1f/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:47 - INFO - Configuration saved to /tmp/tmp3s8ggt1f/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:47 - INFO - Starting fresh training
__________ TestErrorHandlingIntegration.test_training_error_recovery ___________
python/tests/test_integration/test_integration_training.py:357: in test_training_error_recovery
    dataset = training_pipeline._prepare_training_data(sample_game_examples)
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute '_prepare_training_data'. Did you mean: '_augment_training_data'?
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:47 - INFO - Logging configured - Console: INFO, File: /tmp/tmp5luv22o9/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204547.log
2025-07-07 20:45:47 - INFO - Experiment directory: /tmp/tmp5luv22o9/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:47 - INFO - Configuration saved to /tmp/tmp5luv22o9/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:47 - INFO - Starting fresh training
______________ TestPerformanceIntegration.test_memory_management _______________
python/tests/test_integration/test_integration_training.py:390: in test_memory_management
    with patch.object(training_pipeline.self_play_manager, 'generate_games',
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute 'self_play_manager'
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:47 - INFO - Logging configured - Console: INFO, File: /tmp/tmpqt1qs3sz/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204547.log
2025-07-07 20:45:47 - INFO - Experiment directory: /tmp/tmpqt1qs3sz/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:47 - INFO - Configuration saved to /tmp/tmpqt1qs3sz/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:47 - INFO - Starting fresh training
________________ TestPerformanceIntegration.test_training_speed ________________
python/tests/test_integration/test_integration_training.py:408: in test_training_speed
    dataset = training_pipeline._prepare_training_data(sample_game_examples)
E   AttributeError: 'UnifiedTrainingPipeline' object has no attribute '_prepare_training_data'. Did you mean: '_augment_training_data'?
---------------------------- Captured stderr setup -----------------------------
2025-07-07 20:45:47 - INFO - Logging configured - Console: INFO, File: /tmp/tmp2e0p3afv/test_experiment/omoknuni_experiments/test_integration/logs/training_20250707_204547.log
2025-07-07 20:45:47 - INFO - Experiment directory: /tmp/tmp2e0p3afv/test_experiment/omoknuni_experiments/test_integration
2025-07-07 20:45:47 - INFO - Configuration saved to /tmp/tmp2e0p3afv/test_experiment/omoknuni_experiments/test_integration/config.yaml
2025-07-07 20:45:47 - INFO - Starting fresh training
____________ TestDistributedIntegration.test_distributed_self_play _____________
python/tests/test_integration/test_integration_training.py:450: in test_distributed_self_play
    pipeline = UnifiedTrainingPipeline(training_config)
python/mcts/neural_networks/unified_training_pipeline.py:128: in __init__
    self._setup_logging()
python/mcts/neural_networks/unified_training_pipeline.py:241: in _setup_logging
    file_handler = logging.handlers.RotatingFileHandler(
/usr/lib/python3.10/logging/handlers.py:155: in __init__
    BaseRotatingHandler.__init__(self, filename, mode, encoding=encoding,
/usr/lib/python3.10/logging/handlers.py:58: in __init__
    logging.FileHandler.__init__(self, filename, mode=mode,
/usr/lib/python3.10/logging/__init__.py:1169: in __init__
    StreamHandler.__init__(self, self._open())
/usr/lib/python3.10/logging/__init__.py:1201: in _open
    return open_func(self.baseFilename, self.mode,
E   FileNotFoundError: [Errno 2] No such file or directory: '/home/cosmosapjw/omoknuni_quantum/MagicMock/Path().resolve().parent.parent.parent.parent.__truediv__().__truediv__().__truediv__().__truediv__()/124082883813360'
________________ TestMCTSPerformance.test_memory_usage_patterns ________________
python/tests/test_integration/test_performance.py:259: in test_memory_usage_patterns
    assert late_avg < early_avg * 3  # Not growing excessively
E   assert np.float64(69.5) < (np.float64(18.6875) * 3)
----------------------------- Captured stdout call -----------------------------
Iteration 1: 7.1MB growth
Iteration 2: 20.8MB growth
Iteration 3: 28.1MB growth
Iteration 4: 35.1MB growth
Iteration 5: 42.1MB growth
Iteration 6: 48.6MB growth
Iteration 7: 48.6MB growth
Iteration 8: 61.9MB growth
Iteration 9: 69.4MB growth
Iteration 10: 77.2MB growth
------------------------------ Captured log call -------------------------------
DEBUG    mcts.core.wave_search:wave_search.py:104 Initialized tactical move detector for Gomoku
DEBUG    mcts.core.mcts:mcts.py:678 Loading board from GameInterface to GPUGameStates
DEBUG    mcts.core.mcts:mcts.py:679 Number of channels: 18
DEBUG    mcts.core.mcts:mcts.py:680 board unique values after mapping: tensor([0], device='cuda:0', dtype=torch.int8)
DEBUG    mcts.core.wave_search:wave_search.py:494 Checking root expansion: has 0 children
DEBUG    mcts.core.wave_search:wave_search.py:559 Board state for tactical detection:
DEBUG    mcts.core.wave_search:wave_search.py:560 Current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:610 Board shape: torch.Size([15, 15]), current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:614 Max boost value: 3.0000
DEBUG    mcts.core.wave_search:wave_search.py:622 Capture move boost: 0.0000
DEBUG    mcts.core.wave_search:wave_search.py:623 Capture move prior: 0.004444 -> 0.003111
DEBUG    mcts.core.wave_search:wave_search.py:624 Full priors before boost: min=0.004444, max=0.004444, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:625 Boosted priors: min=0.003111, max=0.028825, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 0 with 0 visits, expanding 20/225 children
DEBUG    mcts.core.wave_search:wave_search.py:104 Initialized tactical move detector for Gomoku
DEBUG    mcts.core.mcts:mcts.py:678 Loading board from GameInterface to GPUGameStates
DEBUG    mcts.core.mcts:mcts.py:679 Number of channels: 18
DEBUG    mcts.core.mcts:mcts.py:680 board unique values after mapping: tensor([0], device='cuda:0', dtype=torch.int8)
DEBUG    mcts.core.wave_search:wave_search.py:494 Checking root expansion: has 0 children
DEBUG    mcts.core.wave_search:wave_search.py:559 Board state for tactical detection:
DEBUG    mcts.core.wave_search:wave_search.py:560 Current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:610 Board shape: torch.Size([15, 15]), current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:614 Max boost value: 3.0000
DEBUG    mcts.core.wave_search:wave_search.py:622 Capture move boost: 0.0000
DEBUG    mcts.core.wave_search:wave_search.py:623 Capture move prior: 0.004444 -> 0.003111
DEBUG    mcts.core.wave_search:wave_search.py:624 Full priors before boost: min=0.004444, max=0.004444, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:625 Boosted priors: min=0.003111, max=0.028825, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 0 with 0 visits, expanding 20/225 children
DEBUG    mcts.core.wave_search:wave_search.py:104 Initialized tactical move detector for Gomoku
DEBUG    mcts.core.mcts:mcts.py:678 Loading board from GameInterface to GPUGameStates
DEBUG    mcts.core.mcts:mcts.py:679 Number of channels: 18
DEBUG    mcts.core.mcts:mcts.py:680 board unique values after mapping: tensor([0], device='cuda:0', dtype=torch.int8)
DEBUG    mcts.core.wave_search:wave_search.py:494 Checking root expansion: has 0 children
DEBUG    mcts.core.wave_search:wave_search.py:559 Board state for tactical detection:
DEBUG    mcts.core.wave_search:wave_search.py:560 Current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:610 Board shape: torch.Size([15, 15]), current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:614 Max boost value: 3.0000
DEBUG    mcts.core.wave_search:wave_search.py:622 Capture move boost: 0.0000
DEBUG    mcts.core.wave_search:wave_search.py:623 Capture move prior: 0.004444 -> 0.003111
DEBUG    mcts.core.wave_search:wave_search.py:624 Full priors before boost: min=0.004444, max=0.004444, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:625 Boosted priors: min=0.003111, max=0.028825, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 0 with 0 visits, expanding 20/225 children
DEBUG    mcts.core.wave_search:wave_search.py:104 Initialized tactical move detector for Gomoku
DEBUG    mcts.core.mcts:mcts.py:678 Loading board from GameInterface to GPUGameStates
DEBUG    mcts.core.mcts:mcts.py:679 Number of channels: 18
DEBUG    mcts.core.mcts:mcts.py:680 board unique values after mapping: tensor([0], device='cuda:0', dtype=torch.int8)
DEBUG    mcts.core.wave_search:wave_search.py:494 Checking root expansion: has 0 children
DEBUG    mcts.core.wave_search:wave_search.py:559 Board state for tactical detection:
DEBUG    mcts.core.wave_search:wave_search.py:560 Current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:610 Board shape: torch.Size([15, 15]), current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:614 Max boost value: 3.0000
DEBUG    mcts.core.wave_search:wave_search.py:622 Capture move boost: 0.0000
DEBUG    mcts.core.wave_search:wave_search.py:623 Capture move prior: 0.004444 -> 0.003111
DEBUG    mcts.core.wave_search:wave_search.py:624 Full priors before boost: min=0.004444, max=0.004444, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:625 Boosted priors: min=0.003111, max=0.028825, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 0 with 0 visits, expanding 20/225 children
DEBUG    mcts.core.wave_search:wave_search.py:104 Initialized tactical move detector for Gomoku
DEBUG    mcts.core.mcts:mcts.py:678 Loading board from GameInterface to GPUGameStates
DEBUG    mcts.core.mcts:mcts.py:679 Number of channels: 18
DEBUG    mcts.core.mcts:mcts.py:680 board unique values after mapping: tensor([0], device='cuda:0', dtype=torch.int8)
DEBUG    mcts.core.wave_search:wave_search.py:494 Checking root expansion: has 0 children
DEBUG    mcts.core.wave_search:wave_search.py:559 Board state for tactical detection:
DEBUG    mcts.core.wave_search:wave_search.py:560 Current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:610 Board shape: torch.Size([15, 15]), current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:614 Max boost value: 3.0000
DEBUG    mcts.core.wave_search:wave_search.py:622 Capture move boost: 0.0000
DEBUG    mcts.core.wave_search:wave_search.py:623 Capture move prior: 0.004444 -> 0.003111
DEBUG    mcts.core.wave_search:wave_search.py:624 Full priors before boost: min=0.004444, max=0.004444, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:625 Boosted priors: min=0.003111, max=0.028825, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 0 with 0 visits, expanding 20/225 children
DEBUG    mcts.core.wave_search:wave_search.py:104 Initialized tactical move detector for Gomoku
DEBUG    mcts.core.mcts:mcts.py:678 Loading board from GameInterface to GPUGameStates
DEBUG    mcts.core.mcts:mcts.py:679 Number of channels: 18
DEBUG    mcts.core.mcts:mcts.py:680 board unique values after mapping: tensor([0], device='cuda:0', dtype=torch.int8)
DEBUG    mcts.core.wave_search:wave_search.py:494 Checking root expansion: has 0 children
DEBUG    mcts.core.wave_search:wave_search.py:559 Board state for tactical detection:
DEBUG    mcts.core.wave_search:wave_search.py:560 Current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:610 Board shape: torch.Size([15, 15]), current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:614 Max boost value: 3.0000
DEBUG    mcts.core.wave_search:wave_search.py:622 Capture move boost: 0.0000
DEBUG    mcts.core.wave_search:wave_search.py:623 Capture move prior: 0.004444 -> 0.003111
DEBUG    mcts.core.wave_search:wave_search.py:624 Full priors before boost: min=0.004444, max=0.004444, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:625 Boosted priors: min=0.003111, max=0.028825, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 0 with 0 visits, expanding 20/225 children
DEBUG    mcts.core.wave_search:wave_search.py:104 Initialized tactical move detector for Gomoku
DEBUG    mcts.core.mcts:mcts.py:678 Loading board from GameInterface to GPUGameStates
DEBUG    mcts.core.mcts:mcts.py:679 Number of channels: 18
DEBUG    mcts.core.mcts:mcts.py:680 board unique values after mapping: tensor([0], device='cuda:0', dtype=torch.int8)
DEBUG    mcts.core.wave_search:wave_search.py:494 Checking root expansion: has 0 children
DEBUG    mcts.core.wave_search:wave_search.py:559 Board state for tactical detection:
DEBUG    mcts.core.wave_search:wave_search.py:560 Current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:610 Board shape: torch.Size([15, 15]), current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:614 Max boost value: 3.0000
DEBUG    mcts.core.wave_search:wave_search.py:622 Capture move boost: 0.0000
DEBUG    mcts.core.wave_search:wave_search.py:623 Capture move prior: 0.004444 -> 0.003111
DEBUG    mcts.core.wave_search:wave_search.py:624 Full priors before boost: min=0.004444, max=0.004444, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:625 Boosted priors: min=0.003111, max=0.028825, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 0 with 0 visits, expanding 20/225 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 2 with 184 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 3 with 205 visits, expanding 17/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 4 with 162 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 5 with 190 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 6 with 209 visits, expanding 17/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 7 with 224 visits, expanding 17/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 8 with 181 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 9 with 171 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 10 with 112 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 11 with 105 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 12 with 106 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 13 with 110 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 14 with 92 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 15 with 117 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 16 with 117 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 17 with 89 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 18 with 81 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 19 with 95 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 20 with 113 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:104 Initialized tactical move detector for Gomoku
DEBUG    mcts.core.mcts:mcts.py:678 Loading board from GameInterface to GPUGameStates
DEBUG    mcts.core.mcts:mcts.py:679 Number of channels: 18
DEBUG    mcts.core.mcts:mcts.py:680 board unique values after mapping: tensor([0], device='cuda:0', dtype=torch.int8)
DEBUG    mcts.core.wave_search:wave_search.py:494 Checking root expansion: has 0 children
DEBUG    mcts.core.wave_search:wave_search.py:559 Board state for tactical detection:
DEBUG    mcts.core.wave_search:wave_search.py:560 Current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:610 Board shape: torch.Size([15, 15]), current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:614 Max boost value: 3.0000
DEBUG    mcts.core.wave_search:wave_search.py:622 Capture move boost: 0.0000
DEBUG    mcts.core.wave_search:wave_search.py:623 Capture move prior: 0.004444 -> 0.003111
DEBUG    mcts.core.wave_search:wave_search.py:624 Full priors before boost: min=0.004444, max=0.004444, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:625 Boosted priors: min=0.003111, max=0.028825, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 0 with 0 visits, expanding 20/225 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 1 with 392 visits, expanding 19/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 2 with 193 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 3 with 182 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 4 with 225 visits, expanding 17/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 5 with 182 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 6 with 186 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 7 with 187 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 8 with 190 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 9 with 194 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 10 with 116 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 11 with 110 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 12 with 90 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 13 with 105 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 14 with 109 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 15 with 102 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 16 with 100 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 17 with 86 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 18 with 106 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 19 with 113 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 20 with 104 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:104 Initialized tactical move detector for Gomoku
DEBUG    mcts.core.mcts:mcts.py:678 Loading board from GameInterface to GPUGameStates
DEBUG    mcts.core.mcts:mcts.py:679 Number of channels: 18
DEBUG    mcts.core.mcts:mcts.py:680 board unique values after mapping: tensor([0], device='cuda:0', dtype=torch.int8)
DEBUG    mcts.core.wave_search:wave_search.py:494 Checking root expansion: has 0 children
DEBUG    mcts.core.wave_search:wave_search.py:559 Board state for tactical detection:
DEBUG    mcts.core.wave_search:wave_search.py:560 Current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:610 Board shape: torch.Size([15, 15]), current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:614 Max boost value: 3.0000
DEBUG    mcts.core.wave_search:wave_search.py:622 Capture move boost: 0.0000
DEBUG    mcts.core.wave_search:wave_search.py:623 Capture move prior: 0.004444 -> 0.003111
DEBUG    mcts.core.wave_search:wave_search.py:624 Full priors before boost: min=0.004444, max=0.004444, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:625 Boosted priors: min=0.003111, max=0.028825, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 0 with 0 visits, expanding 20/225 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 1 with 405 visits, expanding 20/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 2 with 198 visits, expanding 17/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 3 with 188 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 4 with 197 visits, expanding 17/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 5 with 184 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 6 with 184 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 7 with 209 visits, expanding 17/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 8 with 181 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 9 with 205 visits, expanding 17/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 10 with 89 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 11 with 103 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 12 with 111 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 13 with 78 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 14 with 97 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 15 with 115 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 16 with 122 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 17 with 98 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 18 with 106 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 19 with 98 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 20 with 104 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:104 Initialized tactical move detector for Gomoku
DEBUG    mcts.core.mcts:mcts.py:678 Loading board from GameInterface to GPUGameStates
DEBUG    mcts.core.mcts:mcts.py:679 Number of channels: 18
DEBUG    mcts.core.mcts:mcts.py:680 board unique values after mapping: tensor([0], device='cuda:0', dtype=torch.int8)
DEBUG    mcts.core.wave_search:wave_search.py:494 Checking root expansion: has 0 children
DEBUG    mcts.core.wave_search:wave_search.py:559 Board state for tactical detection:
DEBUG    mcts.core.wave_search:wave_search.py:560 Current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:571   . . . . .
DEBUG    mcts.core.wave_search:wave_search.py:610 Board shape: torch.Size([15, 15]), current player: 1
DEBUG    mcts.core.wave_search:wave_search.py:614 Max boost value: 3.0000
DEBUG    mcts.core.wave_search:wave_search.py:622 Capture move boost: 0.0000
DEBUG    mcts.core.wave_search:wave_search.py:623 Capture move prior: 0.004444 -> 0.003111
DEBUG    mcts.core.wave_search:wave_search.py:624 Full priors before boost: min=0.004444, max=0.004444, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:625 Boosted priors: min=0.003111, max=0.028825, mean=0.004444
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 0 with 0 visits, expanding 20/225 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 1 with 411 visits, expanding 20/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 2 with 193 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 3 with 204 visits, expanding 17/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 4 with 193 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 5 with 191 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 6 with 184 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 7 with 199 visits, expanding 17/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 8 with 183 visits, expanding 16/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 9 with 196 visits, expanding 17/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 10 with 111 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 11 with 102 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 12 with 121 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 13 with 117 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 14 with 95 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 15 with 86 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 16 with 87 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 17 with 101 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 18 with 95 visits, expanding 14/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 19 with 110 visits, expanding 15/224 children
DEBUG    mcts.core.wave_search:wave_search.py:637 Progressive widening: Node 20 with 93 visits, expanding 14/224 children
______________ TestTrainingPerformance.test_self_play_throughput _______________
python/tests/test_integration/test_performance.py:482: in test_self_play_throughput
    assert games_per_second > 0.5  # At least 0.5 games/sec
E   assert 0.10054902163471606 > 0.5
----------------------------- Captured stdout call -----------------------------

Self-play throughput: 0.10 games/sec
----------------------------- Captured stderr call -----------------------------
2025-07-07 20:46:34 - INFO - Logging configured - Console: INFO, File: /tmp/pytest-of-cosmosapjw/pytest-43/test_self_play_throughput0/omoknuni_experiments/perf_test/logs/training_20250707_204634.log
2025-07-07 20:46:34 - INFO - Experiment directory: /tmp/pytest-of-cosmosapjw/pytest-43/test_self_play_throughput0/omoknuni_experiments/perf_test
2025-07-07 20:46:34 - INFO - Configuration saved to /tmp/pytest-of-cosmosapjw/pytest-43/test_self_play_throughput0/omoknuni_experiments/perf_test/config.yaml
2025-07-07 20:46:34 - INFO - Starting fresh training
2025-07-07 20:46:34 - INFO - Worker 2406533: Acquired lock for TensorRT conversion
2025-07-07 20:46:34 - INFO - Worker 2406533: Loading TensorRT engine from cache...
2025-07-07 20:46:34 - INFO - Worker 2406533: Successfully loaded TensorRT engine
2025-07-07 20:46:34 - INFO - Worker 2406533: Using TensorRT acceleration


Self-play games:   0%|          | 0/20 [00:00<?, ?game/s][A[A2025-07-07 20:46:36 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:36 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:37 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:38 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:38 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:38 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:38 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:38 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:38 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:38 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:38 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:38 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:38 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:38 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:39 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:39 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:39 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:39 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:39 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:39 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:39 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:39 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:40 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:40 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:40 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:40 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:40 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:40 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:40 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:40 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:40 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:41 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:41 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:41 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:41 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:41 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:41 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:41 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:41 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:41 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:41 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:42 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:43 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:43 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:43 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:43 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:43 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:43 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:43 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:43 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:43 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:44 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:44 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:44 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:44 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:44 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:44 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:45 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:45 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:45 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:45 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:45 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:45 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:45 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:45 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:45 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:45 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:45 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:46 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:46 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:46 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:46 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:46 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:46 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:46 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:47 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:47 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:47 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:47 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:47 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:47 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:47 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:47 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:47 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:47 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:47 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:48 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:48 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:48 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:48 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:48 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:48 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:48 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:49 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:49 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:49 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:49 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:49 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:49 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:49 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:49 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:49 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:49 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:50 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:50 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:50 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:50 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:50 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:50 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:50 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:50 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:51 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:51 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:51 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:51 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:51 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:51 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:51 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:51 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:51 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:51 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:52 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:53 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:53 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:53 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:53 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:53 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:53 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:54 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:54 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:54 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:54 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:55 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:55 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:55 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:55 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:55 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:55 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:56 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:56 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'


Self-play games:   5%|         | 1/20 [00:22<07:03, 22.30s/game][A[A2025-07-07 20:46:56 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:56 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:57 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:57 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:57 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:46:57 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'


Self-play games:  20%|        | 4/20 [00:24<01:15,  4.70s/game][A[A2025-07-07 20:47:00 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:00 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:01 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:01 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:01 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:01 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:01 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:01 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:01 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:01 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:02 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:02 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:02 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:02 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:02 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:02 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:02 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:02 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:03 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:04 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:05 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:05 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:05 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:05 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:05 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:05 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:05 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:05 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:05 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:05 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:06 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:06 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:06 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:06 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:06 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:06 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:06 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:06 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:07 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:07 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:07 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:07 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:07 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:07 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:07 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:07 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:07 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:07 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:07 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:08 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:08 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:08 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:08 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:08 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:08 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:08 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:09 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:09 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:09 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:09 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:09 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:09 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:09 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:09 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:10 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:10 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:10 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:10 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:10 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:10 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:10 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:11 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:11 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:11 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:11 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:11 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:11 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:11 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:11 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:11 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:11 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:12 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:12 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:12 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:12 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:12 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:12 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:12 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:12 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:12 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:13 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:13 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:13 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:13 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:13 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:13 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:13 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:14 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:14 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:14 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:14 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:14 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:14 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:14 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:15 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:15 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:15 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:15 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:15 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:15 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:15 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:15 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:15 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:16 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:16 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:16 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:16 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:16 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:16 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:16 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:17 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:17 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:17 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:17 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:17 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:17 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:17 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:18 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:18 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:18 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:18 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:18 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:18 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:19 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:19 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:19 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:19 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:19 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:20 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:20 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:20 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:20 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:21 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:21 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:21 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:21 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:21 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:21 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:21 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:22 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:22 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:22 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:22 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:22 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:22 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:22 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:22 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:23 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:23 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:23 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:23 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:23 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:24 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:24 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:24 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:24 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:25 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:25 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:25 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:25 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:25 - ERROR - Error processing optimized batch 36: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:26 - ERROR - Error processing optimized batch 36: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:26 - ERROR - Error processing optimized batch 36: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:26 - ERROR - Error processing optimized batch 36: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:26 - ERROR - Error processing optimized batch 37: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:26 - ERROR - Error processing optimized batch 37: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:26 - ERROR - Error processing optimized batch 37: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:26 - ERROR - Error processing optimized batch 37: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:27 - ERROR - Error processing optimized batch 38: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:27 - ERROR - Error processing optimized batch 38: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:27 - ERROR - Error processing optimized batch 38: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:27 - ERROR - Error processing optimized batch 38: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:28 - ERROR - Error processing optimized batch 39: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:28 - ERROR - Error processing optimized batch 39: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:28 - ERROR - Error processing optimized batch 39: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:28 - ERROR - Error processing optimized batch 39: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:29 - ERROR - Error processing optimized batch 40: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:29 - ERROR - Error processing optimized batch 40: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:29 - ERROR - Error processing optimized batch 40: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:29 - ERROR - Error processing optimized batch 40: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:29 - ERROR - Error processing optimized batch 41: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:29 - ERROR - Error processing optimized batch 41: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:29 - ERROR - Error processing optimized batch 41: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:29 - ERROR - Error processing optimized batch 41: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:30 - ERROR - Error processing optimized batch 42: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:30 - ERROR - Error processing optimized batch 42: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:30 - ERROR - Error processing optimized batch 42: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:30 - ERROR - Error processing optimized batch 42: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:31 - ERROR - Error processing optimized batch 43: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:31 - ERROR - Error processing optimized batch 43: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:31 - ERROR - Error processing optimized batch 43: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:31 - ERROR - Error processing optimized batch 43: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:32 - ERROR - Error processing optimized batch 44: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:32 - ERROR - Error processing optimized batch 44: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:32 - ERROR - Error processing optimized batch 44: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:32 - ERROR - Error processing optimized batch 44: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:32 - ERROR - Error processing optimized batch 45: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:33 - ERROR - Error processing optimized batch 45: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:33 - ERROR - Error processing optimized batch 45: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:33 - ERROR - Error processing optimized batch 45: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:33 - ERROR - Error processing optimized batch 46: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:33 - ERROR - Error processing optimized batch 46: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:33 - ERROR - Error processing optimized batch 46: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:33 - ERROR - Error processing optimized batch 46: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:34 - ERROR - Error processing optimized batch 47: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:34 - ERROR - Error processing optimized batch 47: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:35 - ERROR - Error processing optimized batch 48: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:35 - ERROR - Error processing optimized batch 48: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:36 - ERROR - Error processing optimized batch 49: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:36 - ERROR - Error processing optimized batch 49: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:36 - ERROR - Error processing optimized batch 50: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:36 - ERROR - Error processing optimized batch 50: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:37 - ERROR - Error processing optimized batch 51: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:37 - ERROR - Error processing optimized batch 51: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:38 - ERROR - Error processing optimized batch 52: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:38 - ERROR - Error processing optimized batch 52: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:39 - ERROR - Error processing optimized batch 53: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:39 - ERROR - Error processing optimized batch 53: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:39 - ERROR - Error processing optimized batch 54: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:40 - ERROR - Error processing optimized batch 54: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:40 - ERROR - Error processing optimized batch 55: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:40 - ERROR - Error processing optimized batch 55: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'


Self-play games:  25%|       | 5/20 [01:07<03:50, 15.37s/game][A[A

Self-play games:  40%|      | 8/20 [01:07<01:24,  7.03s/game][A[A2025-07-07 20:47:43 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:43 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:44 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:44 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:44 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:44 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:44 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:44 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:44 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:44 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:44 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:45 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:45 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:45 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:45 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:45 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:45 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:45 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:45 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:46 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:46 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:46 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:46 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:46 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:46 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:46 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:46 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:47 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:48 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:49 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:49 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:49 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:49 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:49 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:49 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:49 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:49 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:49 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:49 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:50 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:50 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:50 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:50 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:50 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:50 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:50 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:50 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:51 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:51 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:51 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:51 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:51 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:51 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:51 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:51 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:51 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:51 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:51 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:52 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:52 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:52 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:52 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:52 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:52 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:52 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:52 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:52 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:53 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:53 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:53 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:53 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:53 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:53 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:53 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:53 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:54 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:54 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'


Self-play games:  40%|      | 8/20 [01:20<01:24,  7.03s/game][A[A2025-07-07 20:47:54 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:54 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:54 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:54 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:55 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:55 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:55 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:55 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:55 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:55 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:55 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:56 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:56 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:56 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:56 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:56 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:56 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:56 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:56 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:56 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:57 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:57 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:57 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:57 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:57 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:57 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:57 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:57 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:57 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:58 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:58 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:58 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:58 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:58 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:58 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:58 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:58 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:58 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:58 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:58 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:59 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:59 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:59 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:59 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:59 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:47:59 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:00 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:00 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:00 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:00 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:00 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:00 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:00 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:00 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:00 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:00 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:01 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:01 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:01 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:01 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:01 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:01 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:01 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:01 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:02 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:02 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:02 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:02 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:02 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:02 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:02 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:02 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:02 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:03 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:03 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:03 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:03 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:03 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:03 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:03 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:03 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:03 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:03 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:03 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'


Self-play games:  45%|     | 9/20 [01:29<01:52, 10.20s/game][A[A2025-07-07 20:48:04 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:04 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:05 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:05 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:06 - ERROR - Error processing optimized batch 36: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:06 - ERROR - Error processing optimized batch 36: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:06 - ERROR - Error processing optimized batch 37: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:06 - ERROR - Error processing optimized batch 37: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:07 - ERROR - Error processing optimized batch 38: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:07 - ERROR - Error processing optimized batch 38: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:08 - ERROR - Error processing optimized batch 39: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:08 - ERROR - Error processing optimized batch 39: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:09 - ERROR - Error processing optimized batch 40: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:09 - ERROR - Error processing optimized batch 40: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:09 - ERROR - Error processing optimized batch 41: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:10 - ERROR - Error processing optimized batch 41: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:10 - ERROR - Error processing optimized batch 42: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:10 - ERROR - Error processing optimized batch 42: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:11 - ERROR - Error processing optimized batch 43: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:11 - ERROR - Error processing optimized batch 43: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:12 - ERROR - Error processing optimized batch 44: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:12 - ERROR - Error processing optimized batch 44: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:12 - ERROR - Error processing optimized batch 45: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:13 - ERROR - Error processing optimized batch 45: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:13 - ERROR - Error processing optimized batch 46: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:13 - ERROR - Error processing optimized batch 46: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:14 - ERROR - Error processing optimized batch 47: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:14 - ERROR - Error processing optimized batch 47: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:15 - ERROR - Error processing optimized batch 48: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:15 - ERROR - Error processing optimized batch 48: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:16 - ERROR - Error processing optimized batch 49: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:16 - ERROR - Error processing optimized batch 49: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:16 - ERROR - Error processing optimized batch 50: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:16 - ERROR - Error processing optimized batch 50: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:17 - ERROR - Error processing optimized batch 51: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:17 - ERROR - Error processing optimized batch 51: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'


Self-play games:  55%|    | 11/20 [01:43<01:21,  9.05s/game][A[A2025-07-07 20:48:19 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:20 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:21 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:21 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:21 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:21 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:21 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:21 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:21 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:21 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:21 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:21 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:22 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:22 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:22 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:22 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:22 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:22 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:22 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:22 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:22 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:22 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:22 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:23 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:23 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:23 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:23 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:23 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:23 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:23 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:23 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:23 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:23 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:23 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:24 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:25 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:25 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:25 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:25 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:25 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:25 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:25 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:25 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:25 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:25 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:26 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:26 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:26 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:26 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:26 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:26 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:26 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:26 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:26 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:26 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:26 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:27 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:28 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:29 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:30 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:30 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:30 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:30 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:30 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:30 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:30 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:30 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:31 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:31 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:31 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:31 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:31 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:31 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:31 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:31 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:31 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:31 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:32 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:33 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:34 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:34 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:34 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:34 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:34 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:34 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:34 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:34 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:34 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:34 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:34 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:35 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:35 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:35 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:35 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:36 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:36 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:36 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:36 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:36 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:36 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:37 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:37 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:37 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:37 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:38 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:38 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:38 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:38 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:38 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:38 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:38 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:38 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:39 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:39 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:39 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:39 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:40 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:40 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:40 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:40 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:41 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:41 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:41 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:41 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:41 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:42 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:42 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:42 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:42 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:42 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:42 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:42 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:43 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:43 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:43 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:43 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:44 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:44 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:44 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:44 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:45 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:45 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:45 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:45 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:45 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:46 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:46 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:46 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:46 - ERROR - Error processing optimized batch 36: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:46 - ERROR - Error processing optimized batch 36: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:46 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:47 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:47 - ERROR - Error processing optimized batch 37: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:47 - ERROR - Error processing optimized batch 37: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'


Self-play games:  65%|   | 13/20 [02:13<01:17, 11.02s/game][A[A2025-07-07 20:48:48 - ERROR - Error processing optimized batch 38: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:48 - ERROR - Error processing optimized batch 38: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:49 - ERROR - Error processing optimized batch 39: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:49 - ERROR - Error processing optimized batch 39: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:49 - ERROR - Error processing optimized batch 40: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:49 - ERROR - Error processing optimized batch 40: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:50 - ERROR - Error processing optimized batch 41: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:50 - ERROR - Error processing optimized batch 41: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:51 - ERROR - Error processing optimized batch 42: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:51 - ERROR - Error processing optimized batch 42: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:52 - ERROR - Error processing optimized batch 43: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:52 - ERROR - Error processing optimized batch 43: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:53 - ERROR - Error processing optimized batch 44: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:53 - ERROR - Error processing optimized batch 44: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:53 - ERROR - Error processing optimized batch 45: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:53 - ERROR - Error processing optimized batch 45: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:54 - ERROR - Error processing optimized batch 46: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:54 - ERROR - Error processing optimized batch 46: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:55 - ERROR - Error processing optimized batch 47: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:55 - ERROR - Error processing optimized batch 47: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:56 - ERROR - Error processing optimized batch 48: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:56 - ERROR - Error processing optimized batch 48: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:56 - ERROR - Error processing optimized batch 49: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:56 - ERROR - Error processing optimized batch 49: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:57 - ERROR - Error processing optimized batch 50: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:57 - ERROR - Error processing optimized batch 50: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:58 - ERROR - Error processing optimized batch 51: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:58 - ERROR - Error processing optimized batch 51: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:59 - ERROR - Error processing optimized batch 52: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:59 - ERROR - Error processing optimized batch 52: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:59 - ERROR - Error processing optimized batch 53: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:48:59 - ERROR - Error processing optimized batch 53: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:00 - ERROR - Error processing optimized batch 54: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:00 - ERROR - Error processing optimized batch 54: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:01 - ERROR - Error processing optimized batch 55: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:01 - ERROR - Error processing optimized batch 55: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:02 - ERROR - Error processing optimized batch 56: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:02 - ERROR - Error processing optimized batch 56: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:02 - ERROR - Error processing optimized batch 57: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:03 - ERROR - Error processing optimized batch 57: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:03 - ERROR - Error processing optimized batch 58: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:03 - ERROR - Error processing optimized batch 58: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:04 - ERROR - Error processing optimized batch 59: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:04 - ERROR - Error processing optimized batch 59: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:05 - ERROR - Error processing optimized batch 60: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:05 - ERROR - Error processing optimized batch 60: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:06 - ERROR - Error processing optimized batch 61: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:06 - ERROR - Error processing optimized batch 61: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:06 - ERROR - Error processing optimized batch 62: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:06 - ERROR - Error processing optimized batch 62: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:07 - ERROR - Error processing optimized batch 63: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:07 - ERROR - Error processing optimized batch 63: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:08 - ERROR - Error processing optimized batch 64: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:08 - ERROR - Error processing optimized batch 64: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:09 - ERROR - Error processing optimized batch 65: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:09 - ERROR - Error processing optimized batch 65: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:09 - ERROR - Error processing optimized batch 66: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:09 - ERROR - Error processing optimized batch 66: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:10 - ERROR - Error processing optimized batch 67: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:10 - ERROR - Error processing optimized batch 67: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:11 - ERROR - Error processing optimized batch 68: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:11 - ERROR - Error processing optimized batch 68: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:12 - ERROR - Error processing optimized batch 69: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:12 - ERROR - Error processing optimized batch 69: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:12 - ERROR - Error processing optimized batch 70: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:12 - ERROR - Error processing optimized batch 70: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:13 - ERROR - Error processing optimized batch 71: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:13 - ERROR - Error processing optimized batch 71: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:14 - ERROR - Error processing optimized batch 72: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:14 - ERROR - Error processing optimized batch 72: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:15 - ERROR - Error processing optimized batch 73: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:15 - ERROR - Error processing optimized batch 73: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:15 - ERROR - Error processing optimized batch 74: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:16 - ERROR - Error processing optimized batch 74: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:16 - ERROR - Error processing optimized batch 75: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:16 - ERROR - Error processing optimized batch 75: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'


Self-play games:  80%|  | 16/20 [02:43<00:42, 10.55s/game][A[A2025-07-07 20:49:18 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 1: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:19 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 2: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:20 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:21 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:21 - ERROR - Error processing optimized batch 3: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:21 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:21 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:21 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:21 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:21 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:21 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:21 - ERROR - Error processing optimized batch 4: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:21 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:21 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:22 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:22 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:22 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:22 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:22 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:22 - ERROR - Error processing optimized batch 5: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:22 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:22 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:22 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:22 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:23 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:23 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:23 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:23 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:23 - ERROR - Error processing optimized batch 6: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:23 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:23 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:23 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:24 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:24 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:24 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:24 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:24 - ERROR - Error processing optimized batch 7: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:24 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:24 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:24 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:24 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:24 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:25 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:25 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:25 - ERROR - Error processing optimized batch 8: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:25 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:25 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:25 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:25 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:25 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:25 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:25 - ERROR - Error processing optimized batch 9: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:25 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:26 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:26 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:26 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:26 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:26 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:26 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:26 - ERROR - Error processing optimized batch 10: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:26 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:26 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:27 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:27 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:27 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:27 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:27 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:27 - ERROR - Error processing optimized batch 11: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:27 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:27 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:27 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:27 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:28 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:28 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:28 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:28 - ERROR - Error processing optimized batch 12: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:28 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:28 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:28 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:28 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:28 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:29 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:29 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:29 - ERROR - Error processing optimized batch 13: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:29 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:29 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:29 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:29 - ERROR - Error processing optimized batch 14: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:29 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:29 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:29 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:29 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 15: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:30 - ERROR - Error processing optimized batch 16: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 17: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:31 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:32 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:32 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:32 - ERROR - Error processing optimized batch 18: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:32 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:32 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:32 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:32 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:32 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:32 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 19: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 20: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:33 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:34 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:34 - ERROR - Error processing optimized batch 21: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:34 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:34 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:34 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:34 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:34 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:34 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:34 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:34 - ERROR - Error processing optimized batch 22: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:35 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:35 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:35 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:35 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:35 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:35 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:35 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:35 - ERROR - Error processing optimized batch 23: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 24: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:36 - ERROR - Error processing optimized batch 25: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:37 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:37 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:37 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:37 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:37 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:37 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:37 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:37 - ERROR - Error processing optimized batch 26: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:37 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:37 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:38 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:38 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:38 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:38 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:38 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:38 - ERROR - Error processing optimized batch 27: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:38 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:38 - ERROR - Error processing optimized batch 28: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:38 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:38 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:39 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:39 - ERROR - Error processing optimized batch 29: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:39 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:39 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:39 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:39 - ERROR - Error processing optimized batch 30: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:40 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:40 - ERROR - Error processing optimized batch 31: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'


Self-play games:  85%| | 17/20 [03:05<00:37, 12.62s/game][A[A2025-07-07 20:49:41 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:41 - ERROR - Error processing optimized batch 32: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:41 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:41 - ERROR - Error processing optimized batch 33: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:42 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:42 - ERROR - Error processing optimized batch 34: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:43 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:43 - ERROR - Error processing optimized batch 35: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:44 - ERROR - Error processing optimized batch 36: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:44 - ERROR - Error processing optimized batch 36: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:44 - ERROR - Error processing optimized batch 37: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:44 - ERROR - Error processing optimized batch 37: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:45 - ERROR - Error processing optimized batch 38: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:45 - ERROR - Error processing optimized batch 38: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:46 - ERROR - Error processing optimized batch 39: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:46 - ERROR - Error processing optimized batch 39: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:47 - ERROR - Error processing optimized batch 40: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:47 - ERROR - Error processing optimized batch 40: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:47 - ERROR - Error processing optimized batch 41: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:47 - ERROR - Error processing optimized batch 41: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:48 - ERROR - Error processing optimized batch 42: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:48 - ERROR - Error processing optimized batch 42: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:49 - ERROR - Error processing optimized batch 43: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:49 - ERROR - Error processing optimized batch 43: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:50 - ERROR - Error processing optimized batch 44: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:50 - ERROR - Error processing optimized batch 44: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:50 - ERROR - Error processing optimized batch 45: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:51 - ERROR - Error processing optimized batch 45: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:51 - ERROR - Error processing optimized batch 46: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:51 - ERROR - Error processing optimized batch 46: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:52 - ERROR - Error processing optimized batch 47: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'
2025-07-07 20:49:52 - ERROR - Error processing optimized batch 47: '>' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/utils/gpu_evaluator_service.py", line 514, in _process_optimized_batch_request
    policies, values = self.model.forward_batch(state_tensor, legal_mask_tensor, temp_value)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 472, in forward_batch
    policy_logits, values = self(states)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 354, in __call__
    return self._manual_inference(x)
  File "/home/cosmosapjw/omoknuni_quantum/python/mcts/neural_networks/tensorrt_converter.py", line 359, in _manual_inference
    if batch_size > self.max_batch_size:
TypeError: '>' not supported between instances of 'int' and 'NoneType'


Self-play games:  95%|| 19/20 [03:18<00:10, 10.62s/game][A[A

                                                                  [A[A2025-07-07 20:49:53 - INFO - ================================================================================
2025-07-07 20:49:53 - INFO - SELF-PLAY GAME QUALITY METRICS
2025-07-07 20:49:53 - INFO - ================================================================================
2025-07-07 20:49:53 - INFO - Total games played: 20
2025-07-07 20:49:53 - INFO - Game length: avg=32.7, std=15.2, min=13, max=75
2025-07-07 20:49:53 - INFO - Outcomes: P1 wins=20.0%, P2 wins=80.0%, Draws=0.0%
2025-07-07 20:49:53 - INFO - Resignations: 0 (0.0%)
2025-07-07 20:49:53 - INFO - Average policy entropy: 1.440 (trend: stable)
2025-07-07 20:49:53 - INFO - Value prediction accuracy: 60.0%
2025-07-07 20:49:53 - INFO - Illegal move attempts: 0
2025-07-07 20:49:53 - WARNING -   High win rate imbalance detected! Check for first-player advantage.
2025-07-07 20:49:53 - INFO - ================================================================================
_____________ TestTrainingPerformance.test_training_iteration_time _____________
python/tests/test_integration/test_performance.py:516: in test_training_iteration_time
    pipeline.train(num_iterations=1)
python/mcts/neural_networks/unified_training_pipeline.py:495: in train
    self_play_examples = self.generate_self_play_data()
python/mcts/neural_networks/unified_training_pipeline.py:613: in generate_self_play_data
    self._collect_metrics_from_examples(examples)
python/mcts/neural_networks/unified_training_pipeline.py:636: in _collect_metrics_from_examples
    game_id = example.game_id
E   AttributeError: 'dict' object has no attribute 'game_id'
----------------------------- Captured stderr call -----------------------------
2025-07-07 20:49:53 - INFO - Logging configured - Console: INFO, File: /tmp/pytest-of-cosmosapjw/pytest-43/test_training_iteration_time0/omoknuni_experiments/alphazero_experiment/logs/training_20250707_204953.log
2025-07-07 20:49:53 - INFO - Experiment directory: /tmp/pytest-of-cosmosapjw/pytest-43/test_training_iteration_time0/omoknuni_experiments/alphazero_experiment
2025-07-07 20:49:53 - INFO - Configuration saved to /tmp/pytest-of-cosmosapjw/pytest-43/test_training_iteration_time0/omoknuni_experiments/alphazero_experiment/config.yaml
2025-07-07 20:49:53 - INFO - Starting fresh training
2025-07-07 20:49:53 - INFO - Training from iteration 1 to 1
Training iterations:   0%|          | 0/1 [00:00<?, ?iter/s]2025-07-07 20:49:53 - INFO -  Warming up CUDA kernels...
2025-07-07 20:49:53 - INFO -    Loading unified kernels...
2025-07-07 20:49:53 - INFO -    Pre-compiling TensorRT engine...
2025-07-07 20:49:53 - INFO -    Input shape: (18, 15, 15)
2025-07-07 20:49:53 - INFO -    Optimizing for batch sizes: [1, 8, 32, 64, 128, 32, 512]
2025-07-07 20:49:53 - INFO - Worker 0: Using cached TensorRT model
2025-07-07 20:49:53 - INFO -    TensorRT engine compiled successfully in 0.00s
2025-07-07 20:49:53 - INFO -    Engine cached at: /tmp/omoknuni_tensorrt_cache/engine_9a25a06e96f18d67.trt
2025-07-07 20:49:53 - INFO -    Engine file verified
2025-07-07 20:49:53 - INFO -     Initializing MCTS system...
2025-07-07 20:49:53 - INFO -    Warming up kernels...
Training iterations: 100%|| 1/1 [00:00<00:00,  5.93iter/s]2025-07-07 20:49:53 - INFO - 

================================================================================
2025-07-07 20:49:53 - INFO - ITERATION 1
2025-07-07 20:49:53 - INFO - ================================================================================

2025-07-07 20:49:53 - INFO - [1/4] Generating self-play data...
_____________________ TestForwardPass.test_evaluate_single _____________________
python/tests/test_neural_networks/test_resnet_evaluator.py:309: in test_evaluate_single
    policy, value = gomoku_evaluator.evaluate(state)
python/mcts/neural_networks/base_neural_evaluator.py:195: in evaluate
    policy, value = self._forward_model(states)
python/mcts/neural_networks/resnet_evaluator.py:153: in _forward_model
    log_policies, values = self.model(states)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[1, 20, 15, 15] to have 18 channels, but got 20 channels instead
_____________________ TestForwardPass.test_evaluate_batch ______________________
python/tests/test_neural_networks/test_resnet_evaluator.py:319: in test_evaluate_batch
    policies, values = gomoku_evaluator.evaluate_batch(states)
python/mcts/neural_networks/base_neural_evaluator.py:244: in evaluate_batch
    policy, value = self._forward_model(states)
python/mcts/neural_networks/resnet_evaluator.py:153: in _forward_model
    log_policies, values = self.model(states)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[8, 20, 15, 15] to have 18 channels, but got 20 channels instead
--------------------------- Captured stderr teardown ---------------------------
Training iterations: 100%|| 1/1 [00:02<00:00,  2.50s/iter]
_____________________ TestForwardPass.test_mixed_precision _____________________
python/tests/test_neural_networks/test_resnet_evaluator.py:336: in test_mixed_precision
    policies, values = evaluator._forward_model(states)
python/mcts/neural_networks/resnet_evaluator.py:153: in _forward_model
    log_policies, values = self.model(states)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[4, 20, 15, 15] to have 18 channels, but got 20 channels instead
________________________ TestStatistics.test_get_stats _________________________
python/tests/test_neural_networks/test_resnet_evaluator.py:347: in test_get_stats
    gomoku_evaluator._forward_model(states)
python/mcts/neural_networks/resnet_evaluator.py:153: in _forward_model
    log_policies, values = self.model(states)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[4, 20, 15, 15] to have 18 channels, but got 20 channels instead
____________________ TestCheckpointing.test_from_checkpoint ____________________
python/tests/test_neural_networks/test_resnet_evaluator.py:432: in test_from_checkpoint
    assert evaluator.model == mock_model
E   AssertionError: assert <Mock name='mock.to()' id='124082884188464'> == <Mock id='124082883623856'>
E    +  where <Mock name='mock.to()' id='124082884188464'> = <mcts.neural_networks.resnet_evaluator.ResNetEvaluator object at 0x70da4c335420>.model
----------------------------- Captured stderr call -----------------------------
2025-07-07 20:49:56 - INFO - Loading neural network config from /home/cosmosapjw/omoknuni_quantum/configs/gomoku_classical.yaml
2025-07-07 20:49:56 - INFO - Configuration loaded from /home/cosmosapjw/omoknuni_quantum/configs/gomoku_classical.yaml
2025-07-07 20:49:56 - INFO - Detected hardware: 12 CPU cores, 62.7GB RAM
2025-07-07 20:49:56 - INFO - GPU: NVIDIA GeForce RTX 3060 Ti (7831MB)
2025-07-07 20:49:56 - INFO - Preserving YAML values: max_tree_nodes=400000, memory_pool_size_mb=4096, min_wave_size=3072, max_wave_size=3072, batch_size=1024
2025-07-07 20:49:56 - INFO - Adjusted config: 12 workers, 4096MB memory pool
------------------------------ Captured log call -------------------------------
INFO     mcts.neural_networks.resnet_evaluator:resnet_evaluator.py:64 Loading neural network config from /home/cosmosapjw/omoknuni_quantum/configs/gomoku_classical.yaml
INFO     mcts.utils.config_system:config_system.py:662 Configuration loaded from /home/cosmosapjw/omoknuni_quantum/configs/gomoku_classical.yaml
INFO     mcts.utils.config_system:config_system.py:830 Detected hardware: 12 CPU cores, 62.7GB RAM
INFO     mcts.utils.config_system:config_system.py:833 GPU: NVIDIA GeForce RTX 3060 Ti (7831MB)
INFO     mcts.utils.config_system:config_system.py:870 Preserving YAML values: max_tree_nodes=400000, memory_pool_size_mb=4096, min_wave_size=3072, max_wave_size=3072, batch_size=1024
INFO     mcts.utils.config_system:config_system.py:881 Adjusted config: 12 workers, 4096MB memory pool
__________________ TestEdgeCases.test_empty_batch_evaluation ___________________
python/tests/test_neural_networks/test_resnet_evaluator.py:509: in test_empty_batch_evaluation
    policies, values = gomoku_evaluator._forward_model(empty_states)
python/mcts/neural_networks/resnet_evaluator.py:153: in _forward_model
    log_policies, values = self.model(states)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[0, 20, 15, 15] to have 18 channels, but got 20 channels instead
____________________ TestEdgeCases.test_single_sample_batch ____________________
python/tests/test_neural_networks/test_resnet_evaluator.py:518: in test_single_sample_batch
    policies, values = gomoku_evaluator.forward_batch(single_state)
../venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
python/mcts/neural_networks/resnet_evaluator.py:196: in forward_batch
    log_policies, values = self.model(states_tensor)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[1, 20, 15, 15] to have 18 channels, but got 20 channels instead
______________________ TestEdgeCases.test_no_legal_moves _______________________
python/tests/test_neural_networks/test_resnet_evaluator.py:528: in test_no_legal_moves
    policies, values = gomoku_evaluator.forward_batch(states, legal_mask)
../venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
python/mcts/neural_networks/resnet_evaluator.py:196: in forward_batch
    log_policies, values = self.model(states_tensor)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[2, 20, 15, 15] to have 18 channels, but got 20 channels instead
_________________ TestEdgeCases.test_device_mismatch_handling __________________
python/tests/test_neural_networks/test_resnet_evaluator.py:540: in test_device_mismatch_handling
    policies, values = gomoku_evaluator.evaluate_batch(cuda_states.cpu().numpy())
python/mcts/neural_networks/base_neural_evaluator.py:244: in evaluate_batch
    policy, value = self._forward_model(states)
python/mcts/neural_networks/resnet_evaluator.py:153: in _forward_model
    log_policies, values = self.model(states)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[4, 20, 15, 15] to have 18 channels, but got 20 channels instead
_____________________ TestResNetModel.test_initialization ______________________
python/tests/test_neural_networks/test_resnet_model.py:268: in test_initialization
    assert gomoku_model.metadata.input_channels == 20
E   AssertionError: assert 18 == 20
E    +  where 18 = ModelMetadata(game_type='gomoku', board_size=15, num_actions=225, input_channels=18, num_blocks=3, num_filters=64, version='1.0', training_steps=0, elo_rating=1200.0).input_channels
E    +    where ModelMetadata(game_type='gomoku', board_size=15, num_actions=225, input_channels=18, num_blocks=3, num_filters=64, version='1.0', training_steps=0, elo_rating=1200.0) = ResNetModel(\n  (conv_input): Conv2d(18, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn_input): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (residual_blocks): ModuleList(\n    (0-2): 3 x ResidualBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (policy_head): PolicyHead(\n    (conv): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (fc1): Linear(in_features=450, out_features=128, bias=True)\n    (fc2): Linear(in_features=128, out_features=225, bias=True)\n  )\n  (value_head): ValueHead(\n    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (fc1): Linear(in_features=225, out_features=128, bias=True)\n    (fc2): Linear(in_features=128, out_features=1, bias=True)\n  )\n).metadata
______________________ TestResNetModel.test_forward_pass _______________________
python/tests/test_neural_networks/test_resnet_model.py:288: in test_forward_pass
    policy, value = gomoku_model(sample_input)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[4, 20, 15, 15] to have 18 channels, but got 20 channels instead
__________________ TestResNetModel.test_gradient_computation ___________________
python/tests/test_neural_networks/test_resnet_model.py:304: in test_gradient_computation
    policy, value = gomoku_model(sample_input)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[4, 20, 15, 15] to have 18 channels, but got 20 channels instead
________________________ TestResNetModel.test_eval_mode ________________________
python/tests/test_neural_networks/test_resnet_model.py:338: in test_eval_mode
    policy1, value1 = gomoku_model(sample_input)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[4, 20, 15, 15] to have 18 channels, but got 20 channels instead
______________________ TestResNetModel.test_training_mode ______________________
python/tests/test_neural_networks/test_resnet_model.py:349: in test_training_mode
    policy1, value1 = gomoku_model(sample_input)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[4, 20, 15, 15] to have 18 channels, but got 20 channels instead
____________________ TestMemoryUsage.test_batch_processing _____________________
python/tests/test_neural_networks/test_resnet_model.py:466: in test_batch_processing
    policy, value = gomoku_model(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [64, 18, 3, 3], expected input[1, 20, 15, 15] to have 18 channels, but got 20 channels instead
__________________ TestMemoryUsage.test_large_model_creation ___________________
python/tests/test_neural_networks/test_resnet_model.py:491: in test_large_model_creation
    policy, value = model(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
python/mcts/neural_networks/resnet_model.py:252: in forward
    x = self.conv_input(x)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554: in forward
    return self._conv_forward(input, self.weight, self.bias)
../venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: in _conv_forward
    return F.conv2d(
E   RuntimeError: Given groups=1, weight of size [256, 18, 3, 3], expected input[2, 20, 19, 19] to have 18 channels, but got 20 channels instead
______________ TestUnifiedTrainingPipeline.test_model_evaluation _______________
python/tests/test_neural_networks/test_training_pipeline.py:228: in test_model_evaluation
    result = pipeline.evaluate_model_with_elo()
python/mcts/neural_networks/unified_training_pipeline.py:1161: in evaluate_model_with_elo
    if current_key not in self.elo_tracker.ratings:
E   TypeError: argument of type 'Mock' is not iterable
----------------------------- Captured stderr call -----------------------------
2025-07-07 20:49:59 - INFO - Logging configured - Console: INFO, File: /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment/logs/training_20250707_204959.log
2025-07-07 20:49:59 - INFO - Experiment directory: /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment
2025-07-07 20:49:59 - INFO - Configuration saved to /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment/config.yaml
2025-07-07 20:49:59 - INFO - Starting fresh training
______________ TestUnifiedTrainingPipeline.test_checkpoint_saving ______________
python/tests/test_neural_networks/test_training_pipeline.py:258: in test_checkpoint_saving
    checkpoint = torch.load(checkpoint_files[0], map_location='cpu')
../venv/lib/python3.10/site-packages/torch/serialization.py:1524: in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
E   _pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
E   	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
E   	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
E   	WeightsUnpickler error: Unsupported global: GLOBAL mcts.utils.config_system.AlphaZeroConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([mcts.utils.config_system.AlphaZeroConfig])` or the `torch.serialization.safe_globals([mcts.utils.config_system.AlphaZeroConfig])` context manager to allowlist this global if you trust this class/function.
E   
E   Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
----------------------------- Captured stderr call -----------------------------
2025-07-07 20:49:59 - INFO - Logging configured - Console: INFO, File: /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment/logs/training_20250707_204959.log
2025-07-07 20:49:59 - INFO - Experiment directory: /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment
2025-07-07 20:49:59 - INFO - Configuration saved to /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment/config.yaml
2025-07-07 20:49:59 - INFO - Starting fresh training
2025-07-07 20:49:59 - INFO - Saved checkpoint at iteration 5
_____________ TestUnifiedTrainingPipeline.test_checkpoint_loading ______________
python/tests/test_neural_networks/test_training_pipeline.py:291: in test_checkpoint_loading
    loaded = pipeline.load_checkpoint(checkpoint_path)
python/mcts/neural_networks/unified_training_pipeline.py:1958: in load_checkpoint
    self.optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
../venv/lib/python3.10/site-packages/torch/_compile.py:51: in inner
    return disable_fn(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: in _fn
    return fn(*args, **kwargs)
../venv/lib/python3.10/site-packages/torch/optim/optimizer.py:863: in load_state_dict
    saved_groups = deepcopy(state_dict["param_groups"])
E   KeyError: 'param_groups'
----------------------------- Captured stderr call -----------------------------
2025-07-07 20:50:00 - INFO - Logging configured - Console: INFO, File: /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment/logs/training_20250707_205000.log
2025-07-07 20:50:00 - INFO - Experiment directory: /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment
2025-07-07 20:50:00 - INFO - Configuration saved to /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment/config.yaml
2025-07-07 20:50:00 - INFO - Starting fresh training
2025-07-07 20:50:00 - INFO - Loading checkpoint from /tmp/tmp_hd9l1p5/checkpoints/checkpoint_010.pth
--------------------------- Captured stderr teardown ---------------------------
Training iterations: 100%|| 1/1 [00:00<00:00,  1.25iter/s]
______________ TestUnifiedTrainingPipeline.test_metrics_tracking _______________
python/tests/test_neural_networks/test_training_pipeline.py:435: in test_metrics_tracking
    metrics = pipeline.train_neural_network()
python/mcts/neural_networks/unified_training_pipeline.py:1053: in train_neural_network
    pred_policies, pred_values = self.model(states)
E   ValueError: not enough values to unpack (expected 2, got 0)
----------------------------- Captured stderr call -----------------------------
2025-07-07 20:50:00 - INFO - Logging configured - Console: INFO, File: /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment/logs/training_20250707_205000.log
2025-07-07 20:50:00 - INFO - Experiment directory: /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment
2025-07-07 20:50:00 - INFO - Configuration saved to /home/cosmosapjw/omoknuni_quantum/experiments/alphazero_experiment/config.yaml
2025-07-07 20:50:00 - INFO - Starting fresh training

Training epoch 1/2:   0%|          | 0/4 [00:00<?, ?batch/s][A
                                                            [A
__________________ TestBatchProcessing.test_batch_combination __________________
python/tests/test_utils/test_batch_coordinator.py:330: in test_batch_combination
    gpu_queue.put.assert_called_once()
/usr/lib/python3.10/unittest/mock.py:908: in assert_called_once
    raise AssertionError(msg)
E   AssertionError: Expected 'put' to have been called once. Called 0 times.
___________________ TestStatistics.test_statistics_tracking ____________________
python/tests/test_utils/test_batch_coordinator.py:561: in test_statistics_tracking
    assert stats['fallback_to_direct'] == 1
E   assert 0 == 1
----------------------------- Captured stderr call -----------------------------
2025-07-07 20:50:07 - INFO - Stopping RequestBatchingCoordinator...
2025-07-07 20:50:07 - INFO - Batch coordination loop stopped
2025-07-07 20:50:07 - INFO - RequestBatchingCoordinator stopped
------------------------------ Captured log call -------------------------------
INFO     mcts.utils.batch_evaluation_coordinator:batch_evaluation_coordinator.py:157 Stopping RequestBatchingCoordinator...
INFO     mcts.utils.batch_evaluation_coordinator:batch_evaluation_coordinator.py:352 Batch coordination loop stopped
INFO     mcts.utils.batch_evaluation_coordinator:batch_evaluation_coordinator.py:169 RequestBatchingCoordinator stopped
_____________ TestNetworkConfig.test_input_representation_options ______________
python/tests/test_utils/test_config_system.py:175: in test_input_representation_options
    assert config.input_channels == 20
E   AssertionError: assert 18 == 20
E    +  where 18 = NeuralNetworkConfig(model_type='resnet', input_channels=18, input_representation='enhanced', num_res_blocks=10, num_filters=256, fc_hidden_size=256, value_head_hidden_size=256, policy_head_filters=2, dropout_rate=0.1, batch_norm=True, batch_norm_momentum=0.997, l2_regularization=0.0001, activation='relu', leaky_relu_alpha=0.01, weight_init='he_normal', bias_init=0.0).input_channels
_______________ TestTrainingConfig.test_training_config_defaults _______________
python/tests/test_utils/test_config_system.py:189: in test_training_config_defaults
    assert config.num_iterations == 100
E   AttributeError: 'TrainingFullConfig' object has no attribute 'num_iterations'
__________________ TestTrainingConfig.test_optimizer_settings __________________
python/tests/test_utils/test_config_system.py:202: in test_optimizer_settings
    assert config.momentum == 0.9
E   AttributeError: 'TrainingFullConfig' object has no attribute 'momentum'
_______________ TestTrainingConfig.test_data_generation_settings _______________
python/tests/test_utils/test_config_system.py:211: in test_data_generation_settings
    assert config.temperature_threshold == 30
E   AttributeError: 'TrainingFullConfig' object has no attribute 'temperature_threshold'
________________ TestTrainingConfig.test_learning_rate_schedule ________________
python/tests/test_utils/test_config_system.py:218: in test_learning_rate_schedule
    assert hasattr(config, 'lr_schedule')
E   AssertionError: assert False
E    +  where False = hasattr(TrainingFullConfig(batch_size=512, learning_rate=0.01, learning_rate_schedule='step', lr_decay_steps=50, lr_decay_rate=0.1, min_learning_rate=1e-05, optimizer='adam', adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, sgd_momentum=0.9, sgd_nesterov=True, weight_decay=0.0001, gradient_accumulation_steps=1, max_grad_norm=5.0, gradient_clip_value=None, final_tournament_enabled=True, final_tournament_model_selection_step=10, final_tournament_max_models=10, num_epochs=10, early_stopping_patience=50, early_stopping_min_delta=0.0001, num_games_per_iteration=100, num_workers=4, games_per_worker=25, max_moves_per_game=500, resign_threshold=-0.98, resign_check_moves=10, resign_start_iteration=20, resign_threshold_decay=0.995, resign_randomness=0.1, window_size=500000, augment_data=True, shuffle_buffer_size=10000, dataloader_workers=4, pin_memory=True, mixed_precision=True, amp_opt_level='O1', loss_scale='dynamic', static_loss_scale=1.0, save_dir='checkpoints', tensorboard_dir='runs', data_dir='self_play_data', distributed=False), 'lr_schedule')
___________________ TestMCTSConfig.test_mcts_config_defaults ___________________
python/tests/test_utils/test_config_system.py:230: in test_mcts_config_defaults
    assert config.num_simulations == 200
E   AssertionError: assert 800 == 200
E    +  where 800 = MCTSFullConfig(num_simulations=800, c_puct=1.0, dirichlet_alpha=0.3, dirichlet_epsilon=0.25, temperature=1.0, temperature_threshold=30, temperature_final=0.1, min_wave_size=256, max_wave_size=3072, batch_size=256, virtual_loss=1.0, memory_pool_size_mb=2048, max_tree_nodes=500000, tree_reuse=True, use_cuda_graphs=True, use_mixed_precision=True, use_tensor_cores=True, use_tensorrt=True, tensorrt_fp16=True, tensorrt_fallback=True, tensorrt_workspace_size=2048, tensorrt_int8=False, tensorrt_max_batch_size=512, tensorrt_engine_cache_dir=None, enable_quantum=False, wave_min_size=256, wave_max_size=2048, wave_adaptive_sizing=True, wave_target_sims_per_second=100000, wave_target_gpu_utilization=0.95, wave_num_pipelines=3, wave_async_expansion=True, wave_prefetch_evaluations=True, wave_memory_pool_mb=1024, csr_max_actions=10, csr_use_sparse_operations=True, interference_threshold=0.1, constructive_interference_factor=0.1, destructive_interference_factor=0.05, device='cuda', num_threads=4).num_simulations
___________________ TestMCTSConfig.test_performance_settings ___________________
python/tests/test_utils/test_config_system.py:242: in test_performance_settings
    assert config.enable_virtual_loss == True
E   AttributeError: 'MCTSFullConfig' object has no attribute 'enable_virtual_loss'
___________________ TestMCTSConfig.test_wave_sizing_settings ___________________
python/tests/test_utils/test_config_system.py:250: in test_wave_sizing_settings
    assert config.min_wave_size == 4
E   AssertionError: assert 256 == 4
E    +  where 256 = MCTSFullConfig(num_simulations=800, c_puct=1.0, dirichlet_alpha=0.3, dirichlet_epsilon=0.25, temperature=1.0, temperature_threshold=30, temperature_final=0.1, min_wave_size=256, max_wave_size=3072, batch_size=256, virtual_loss=1.0, memory_pool_size_mb=2048, max_tree_nodes=500000, tree_reuse=True, use_cuda_graphs=True, use_mixed_precision=True, use_tensor_cores=True, use_tensorrt=True, tensorrt_fp16=True, tensorrt_fallback=True, tensorrt_workspace_size=2048, tensorrt_int8=False, tensorrt_max_batch_size=512, tensorrt_engine_cache_dir=None, enable_quantum=False, wave_min_size=256, wave_max_size=2048, wave_adaptive_sizing=True, wave_target_sims_per_second=100000, wave_target_gpu_utilization=0.95, wave_num_pipelines=3, wave_async_expansion=True, wave_prefetch_evaluations=True, wave_memory_pool_mb=1024, csr_max_actions=10, csr_use_sparse_operations=True, interference_threshold=0.1, constructive_interference_factor=0.1, destructive_interference_factor=0.05, device='cuda', num_threads=4).min_wave_size
__________________ TestArenaConfig.test_arena_config_defaults __________________
python/tests/test_utils/test_config_system.py:266: in test_arena_config_defaults
    assert config.temperature == 0.0
E   AssertionError: assert 0.1 == 0.0
E    +  where 0.1 = ArenaFullConfig(num_games=40, num_workers=4, games_per_worker=10, win_threshold=0.55, statistical_significance=True, confidence_level=0.95, temperature=0.1, mcts_simulations=400, c_puct=1.0, max_moves=500, time_limit_seconds=None, randomize_start_player=True, elo_k_factor=32.0, elo_initial_rating=1500.0, elo_anchor_rating=0.0, update_elo=True, min_win_rate_vs_random=0.95, tournament_rounds=1, tournament_games_per_pair=10, save_game_records=False, save_arena_logs=True, arena_log_dir='arena_logs', elo_save_path='elo_ratings.json', enable_current_vs_previous=True, enable_adaptive_random_matches=True, enable_elo_consistency_checks=True, enable_elo_auto_adjustment=True).temperature
______________________ TestArenaConfig.test_elo_settings _______________________
python/tests/test_utils/test_config_system.py:274: in test_elo_settings
    assert config.initial_elo == 1500.0
E   AttributeError: 'ArenaFullConfig' object has no attribute 'initial_elo'
_______________ TestResourceConfig.test_resource_config_defaults _______________
python/tests/test_utils/test_config_system.py:287: in test_resource_config_defaults
    assert config.max_gpu_memory_gb == 8.0
E   AttributeError: 'AlphaZeroConfig' object has no attribute 'max_gpu_memory_gb'
__________________ TestResourceConfig.test_memory_allocation ___________________
python/tests/test_utils/test_config_system.py:297: in test_memory_allocation
    assert hasattr(config, 'batch_queue_size')
E   AssertionError: assert False
E    +  where False = hasattr(<mcts.utils.config_system.AlphaZeroConfig object at 0x70daac4c3d30>, 'batch_queue_size')
____________________ TestConfigSerialization.test_save_json ____________________
python/tests/test_utils/test_config_system.py:361: in test_save_json
    default_config.save(str(config_path), format='json')
E   TypeError: AlphaZeroConfig.save() got an unexpected keyword argument 'format'
__________________ TestConfigMerging.test_merge_configs_basic __________________
python/tests/test_utils/test_config_system.py:383: in test_merge_configs_basic
    merged = merge_configs(base_config.to_dict(), override_config)
python/mcts/utils/config_system.py:929: in merge_configs
    base_dict = base.to_dict()
E   AttributeError: 'dict' object has no attribute 'to_dict'
______________________ TestConfigMerging.test_deep_merge _______________________
python/tests/test_utils/test_config_system.py:405: in test_deep_merge
    merged = merge_configs(base, override)
python/mcts/utils/config_system.py:929: in merge_configs
    base_dict = base.to_dict()
E   AttributeError: 'dict' object has no attribute 'to_dict'
__________________ TestConfigMerging.test_merge_with_new_keys __________________
python/tests/test_utils/test_config_system.py:416: in test_merge_with_new_keys
    merged = merge_configs(base, override)
python/mcts/utils/config_system.py:929: in merge_configs
    base_dict = base.to_dict()
E   AttributeError: 'dict' object has no attribute 'to_dict'
________________ TestConfigValidation.test_validate_game_config ________________
python/tests/test_utils/test_config_system.py:438: in test_validate_game_config
    with pytest.raises(ValueError, match="board size"):
E   Failed: DID NOT RAISE <class 'ValueError'>
______________ TestConfigValidation.test_validate_network_config _______________
python/tests/test_utils/test_config_system.py:448: in test_validate_network_config
    with pytest.raises(ValueError, match="res blocks"):
E   Failed: DID NOT RAISE <class 'ValueError'>
______________ TestConfigValidation.test_validate_training_config ______________
python/tests/test_utils/test_config_system.py:458: in test_validate_training_config
    with pytest.raises(ValueError, match="batch size"):
E   Failed: DID NOT RAISE <class 'ValueError'>
________________ TestConfigValidation.test_validate_mcts_config ________________
python/tests/test_utils/test_config_system.py:475: in test_validate_mcts_config
    with pytest.raises(ValueError, match="simulations"):
E   Failed: DID NOT RAISE <class 'ValueError'>
____________ TestConfigUtilities.test_config_string_representation _____________
python/tests/test_utils/test_config_system.py:518: in test_config_string_representation
    assert 'game_type' in config_str
E   AssertionError: assert 'game_type' in '<mcts.utils.config_system.AlphaZeroConfig object at 0x70daabee57e0>'
_________________ TestConfigDefaults.test_experiment_defaults __________________
python/tests/test_utils/test_config_system.py:539: in test_experiment_defaults
    assert default_config.experiment_name == 'default'
E   AssertionError: assert 'alphazero_experiment' == 'default'
E     
E     - default
E     + alphazero_experiment
_____________________ TestConfigDefaults.test_log_defaults _____________________
python/tests/test_utils/test_config_system.py:549: in test_log_defaults
    assert config.level == 'INFO'
E   AttributeError: 'AlphaZeroConfig' object has no attribute 'level'
___________________ TestConfigDefaults.test_device_defaults ____________________
python/tests/test_utils/test_config_system.py:564: in test_device_defaults
    assert hasattr(default_config.training, 'device')
E   AssertionError: assert False
E    +  where False = hasattr(TrainingFullConfig(batch_size=512, learning_rate=0.01, learning_rate_schedule='step', lr_decay_steps=50, lr_decay_rate=0.1, min_learning_rate=1e-05, optimizer='adam', adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, sgd_momentum=0.9, sgd_nesterov=True, weight_decay=0.0001, gradient_accumulation_steps=1, max_grad_norm=5.0, gradient_clip_value=None, final_tournament_enabled=True, final_tournament_model_selection_step=10, final_tournament_max_models=10, num_epochs=10, early_stopping_patience=50, early_stopping_min_delta=0.0001, num_games_per_iteration=100, num_workers=4, games_per_worker=25, max_moves_per_game=500, resign_threshold=-0.98, resign_check_moves=10, resign_start_iteration=20, resign_threshold_decay=0.995, resign_randomness=0.1, window_size=500000, augment_data=True, shuffle_buffer_size=10000, dataloader_workers=4, pin_memory=True, mixed_precision=True, amp_opt_level='O1', loss_scale='dynamic', static_loss_scale=1.0, save_dir='checkpoints', tensorboard_dir='runs', data_dir='self_play_data', distributed=False), 'device')
E    +    where TrainingFullConfig(batch_size=512, learning_rate=0.01, learning_rate_schedule='step', lr_decay_steps=50, lr_decay_rate=0.1, min_learning_rate=1e-05, optimizer='adam', adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, sgd_momentum=0.9, sgd_nesterov=True, weight_decay=0.0001, gradient_accumulation_steps=1, max_grad_norm=5.0, gradient_clip_value=None, final_tournament_enabled=True, final_tournament_model_selection_step=10, final_tournament_max_models=10, num_epochs=10, early_stopping_patience=50, early_stopping_min_delta=0.0001, num_games_per_iteration=100, num_workers=4, games_per_worker=25, max_moves_per_game=500, resign_threshold=-0.98, resign_check_moves=10, resign_start_iteration=20, resign_threshold_decay=0.995, resign_randomness=0.1, window_size=500000, augment_data=True, shuffle_buffer_size=10000, dataloader_workers=4, pin_memory=True, mixed_precision=True, amp_opt_level='O1', loss_scale='dynamic', static_loss_scale=1.0, save_dir='checkpoints', tensorboard_dir='runs', data_dir='self_play_data', distributed=False) = <mcts.utils.config_system.AlphaZeroConfig object at 0x70daac4e8910>.training
_______________ TestTrainingMetricsRecorder.test_moving_average ________________
python/tests/test_utils/test_training_metrics.py:184: in test_moving_average
    assert abs(avg_policy_loss - expected) < 1e-6
E   assert np.float64(0.02499999999999991) < 1e-06
E    +  where np.float64(0.02499999999999991) = abs((np.float64(0.5700000000000001) - np.float64(0.595)))
------------------------------ Captured log call -------------------------------
DEBUG    mcts.utils.training_metrics:training_metrics.py:370 Saved metrics to /tmp/pytest-of-cosmosapjw/pytest-43/test_moving_average0/metrics/metrics_iter5.json
DEBUG    mcts.utils.training_metrics:training_metrics.py:370 Saved metrics to /tmp/pytest-of-cosmosapjw/pytest-43/test_moving_average0/metrics/metrics_iter10.json
_______________ TestMetricsVisualizer.test_plot_training_curves ________________
python/tests/test_utils/test_training_metrics.py:454: in test_plot_training_curves
    mock_figure.assert_called_once()
/usr/lib/python3.10/unittest/mock.py:908: in assert_called_once
    raise AssertionError(msg)
E   AssertionError: Expected 'figure' to have been called once. Called 2 times.
E   Calls: [call(figsize=(15, 10)),
E    call().add_subplot(GridSpec(3, 2)[0:1, 0:2]),
E    call().add_subplot().plot([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [0.5, 0.49, 0.48, 0.47, 0.46, 0.45, 0.44, 0.43, 0.42, 0.41000000000000003, 0.4, 0.39, 0.38, 0.37, 0.36, 0.35, 0.33999999999999997, 0.32999999999999996, 0.32, 0.31], label='Policy Loss', alpha=0.7),
E    call().add_subplot().plot([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [0.3, 0.295, 0.29, 0.285, 0.27999999999999997, 0.27499999999999997, 0.27, 0.265, 0.26, 0.255, 0.25, 0.245, 0.24, 0.235, 0.22999999999999998, 0.22499999999999998, 0.21999999999999997, 0.21499999999999997, 0.21, 0.205], label='Value Loss', alpha=0.7),
E    call().add_subplot().plot([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [0.8, 0.785, 0.77, 0.755, 0.74, 0.7250000000000001, 0.7100000000000001, 0.6950000000000001, 0.68, 0.665, 0.65, 0.635, 0.6200000000000001, 0.605, 0.5900000000000001, 0.5750000000000001, 0.56, 0.545, 0.53, 0.5150000000000001], label='Total Loss', linewidth=2),
E    call().add_subplot().set_xlabel('Iteration'),
E    call().add_subplot().set_ylabel('Loss'),
E    call().add_subplot().set_title('Training Losses'),
E    call().add_subplot().legend(),
E    call().add_subplot().grid(True, alpha=0.3),
E    call().add_subplot(GridSpec(3, 2)[1:2, 0:1]),
E    call().add_subplot().plot([0, 5, 10, 15], [0.5, 0.55, 0.6, 0.65], color='green', linewidth=2, marker='o'),
E    call().add_subplot().axhline(y=0.5, color='red', linestyle='--', alpha=0.5),
E    call().add_subplot().set_xlabel('Iteration'),
E    call().add_subplot().set_ylabel('Win Rate'),
E    call().add_subplot().set_title('Win Rate vs Previous Best'),
E    call().add_subplot().grid(True, alpha=0.3),
E    call().add_subplot().set_ylim([0, 1]),
E    call().add_subplot(GridSpec(3, 2)[1:2, 1:2]),
E    call().add_subplot().plot([0, 5, 10, 15], [1500, 1550, 1600, 1650], color='blue', linewidth=2, marker='o'),
E    call().add_subplot().set_xlabel('Iteration'),
E    call().add_subplot().set_ylabel('ELO Rating'),
E    call().add_subplot().set_title('ELO Progression'),
E    call().add_subplot().grid(True, alpha=0.3),
E    call().add_subplot(GridSpec(3, 2)[2:3, 0:1]),
E    call().add_subplot().semilogy([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [0.001, 0.0009000000000000001, 0.0008100000000000001, 0.0007290000000000002, 0.0006561000000000001, 0.00059049, 0.000531441, 0.0004782969000000001, 0.0004304672100000001, 0.0003874204890000001, 0.0003486784401000001, 0.0003138105960900001, 0.0002824295364810001, 0.0002541865828329001, 0.0002287679245496101, 0.0002058911320946491, 0.00018530201888518417, 0.00016677181699666576, 0.00015009463529699917, 0.0001350851717672993], color='orange'),
E    call().add_subplot().set_xlabel('Iteration'),
E    call().add_subplot().set_ylabel('Learning Rate'),
E    call().add_subplot().set_title('Learning Rate Schedule'),
E    call().add_subplot().grid(True, alpha=0.3),
E    call().add_subplot(GridSpec(3, 2)[2:3, 1:2]),
E    call().add_subplot().plot([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3], label='Policy Entropy', alpha=0.7),
E    call().add_subplot().twinx(),
E    call().add_subplot().twinx().plot([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], label='Avg Game Length', color='red', alpha=0.7),
E    call().add_subplot().twinx().set_ylabel('Game Length'),
E    call().add_subplot().set_xlabel('Iteration'),
E    call().add_subplot().set_ylabel('Entropy'),
E    call().add_subplot().set_title('Game Statistics'),
E    call().add_subplot().grid(True, alpha=0.3),
E    call(),
E    call().tight_layout(pad=1.08, h_pad=None, w_pad=None, rect=None)].
----------------------------- Captured stderr call -----------------------------
2025-07-07 20:50:13 - INFO - Saved plot to /tmp/pytest-of-cosmosapjw/pytest-43/test_plot_training_curves0/metrics/test_plot.png
------------------------------ Captured log call -------------------------------
DEBUG    mcts.utils.training_metrics:training_metrics.py:370 Saved metrics to /tmp/pytest-of-cosmosapjw/pytest-43/test_plot_training_curves0/metrics/metrics_iter5.json
DEBUG    mcts.utils.training_metrics:training_metrics.py:370 Saved metrics to /tmp/pytest-of-cosmosapjw/pytest-43/test_plot_training_curves0/metrics/metrics_iter10.json
DEBUG    mcts.utils.training_metrics:training_metrics.py:370 Saved metrics to /tmp/pytest-of-cosmosapjw/pytest-43/test_plot_training_curves0/metrics/metrics_iter15.json
INFO     mcts.utils.training_metrics:training_metrics.py:547 Saved plot to /tmp/pytest-of-cosmosapjw/pytest-43/test_plot_training_curves0/metrics/test_plot.png
================================ tests coverage ================================
_______________ coverage: platform linux, python 3.10.18-final-0 _______________

Coverage HTML written to dir htmlcov
=========================== short test summary info ============================
FAILED python/tests/test_core/test_mcts.py::TestMCTSTreeReuse::test_subtree_reuse_disabled
FAILED python/tests/test_core/test_terminal_detection_debug.py::TestTerminalDetectionDebug::test_terminal_position_step_by_step
FAILED python/tests/test_core/test_tree_operations.py::TestNodeInformation::test_get_root_children_info
FAILED python/tests/test_core/test_wave_search.py::TestWaveBackpropagation::test_parallel_backpropagation
FAILED python/tests/test_core/test_wave_search_init.py::TestWaveSearchInitialization::test_expand_batch_vectorized_without_run_wave
FAILED python/tests/test_core/test_wave_search_init.py::TestWaveSearchInitialization::test_expand_batch_vectorized_with_manual_initialization
FAILED python/tests/test_games/test_gomoku_gameplay.py::TestGomokuWithMCTS::test_mcts_opening_moves
FAILED python/tests/test_gpu/test_mcts_gpu_accelerator.py::TestGlobalInstance::test_process_isolation
FAILED python/tests/test_gpu/test_memory_growth_fix.py::TestMemoryGrowthFix::test_growth_failure_at_max_limit
FAILED python/tests/test_gpu/test_ucb_selector.py::TestEdgeCases::test_extreme_c_puct_values
FAILED python/tests/test_integration/test_integration_mcts.py::TestMCTSGPUAcceleration::test_gpu_node_data_manager
FAILED python/tests/test_integration/test_integration_mcts.py::TestMCTSGPUAcceleration::test_gpu_ucb_selection
FAILED python/tests/test_integration/test_integration_mcts.py::TestTreeReuseIntegration::test_tree_reuse_basic
FAILED python/tests/test_integration/test_integration_mcts.py::TestTreeReuseIntegration::test_tree_reuse_memory_management
FAILED python/tests/test_integration/test_integration_mcts.py::TestTreeReuseIntegration::test_tree_reuse_disabled
FAILED python/tests/test_integration/test_integration_mcts.py::TestGameIntegration::test_gomoku_gameplay
FAILED python/tests/test_integration/test_integration_mcts.py::TestGameIntegration::test_different_board_sizes
FAILED python/tests/test_integration/test_integration_mcts.py::TestPerformanceOptimizations::test_virtual_loss_integration
FAILED python/tests/test_integration/test_integration_mcts.py::TestPerformanceOptimizations::test_fast_ucb_computation
FAILED python/tests/test_integration/test_integration_training.py::TestTrainingPipelineIntegration::test_single_iteration
FAILED python/tests/test_integration/test_integration_training.py::TestTrainingPipelineIntegration::test_training_data_flow
FAILED python/tests/test_integration/test_integration_training.py::TestTrainingPipelineIntegration::test_checkpoint_workflow
FAILED python/tests/test_integration/test_integration_training.py::TestTrainingPipelineIntegration::test_best_model_update
FAILED python/tests/test_integration/test_integration_training.py::TestSelfPlayIntegration::test_self_play_with_current_model
FAILED python/tests/test_integration/test_integration_training.py::TestSelfPlayIntegration::test_gpu_service_integration
FAILED python/tests/test_integration/test_integration_training.py::TestSelfPlayIntegration::test_multi_worker_coordination
FAILED python/tests/test_integration/test_integration_training.py::TestArenaIntegration::test_arena_model_comparison
FAILED python/tests/test_integration/test_integration_training.py::TestArenaIntegration::test_elo_tracking_integration
FAILED python/tests/test_integration/test_integration_training.py::TestTrainingLoopIntegration::test_full_training_loop
FAILED python/tests/test_integration/test_integration_training.py::TestTrainingLoopIntegration::test_training_metrics_tracking
FAILED python/tests/test_integration/test_integration_training.py::TestErrorHandlingIntegration::test_self_play_error_recovery
FAILED python/tests/test_integration/test_integration_training.py::TestErrorHandlingIntegration::test_training_error_recovery
FAILED python/tests/test_integration/test_integration_training.py::TestPerformanceIntegration::test_memory_management
FAILED python/tests/test_integration/test_integration_training.py::TestPerformanceIntegration::test_training_speed
FAILED python/tests/test_integration/test_integration_training.py::TestDistributedIntegration::test_distributed_self_play
FAILED python/tests/test_integration/test_performance.py::TestMCTSPerformance::test_memory_usage_patterns
FAILED python/tests/test_integration/test_performance.py::TestTrainingPerformance::test_self_play_throughput
FAILED python/tests/test_integration/test_performance.py::TestTrainingPerformance::test_training_iteration_time
FAILED python/tests/test_neural_networks/test_resnet_evaluator.py::TestForwardPass::test_evaluate_single
FAILED python/tests/test_neural_networks/test_resnet_evaluator.py::TestForwardPass::test_evaluate_batch
FAILED python/tests/test_neural_networks/test_resnet_evaluator.py::TestForwardPass::test_mixed_precision
FAILED python/tests/test_neural_networks/test_resnet_evaluator.py::TestStatistics::test_get_stats
FAILED python/tests/test_neural_networks/test_resnet_evaluator.py::TestCheckpointing::test_from_checkpoint
FAILED python/tests/test_neural_networks/test_resnet_evaluator.py::TestEdgeCases::test_empty_batch_evaluation
FAILED python/tests/test_neural_networks/test_resnet_evaluator.py::TestEdgeCases::test_single_sample_batch
FAILED python/tests/test_neural_networks/test_resnet_evaluator.py::TestEdgeCases::test_no_legal_moves
FAILED python/tests/test_neural_networks/test_resnet_evaluator.py::TestEdgeCases::test_device_mismatch_handling
FAILED python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_initialization
FAILED python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_forward_pass
FAILED python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_gradient_computation
FAILED python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_eval_mode
FAILED python/tests/test_neural_networks/test_resnet_model.py::TestResNetModel::test_training_mode
FAILED python/tests/test_neural_networks/test_resnet_model.py::TestMemoryUsage::test_batch_processing
FAILED python/tests/test_neural_networks/test_resnet_model.py::TestMemoryUsage::test_large_model_creation
FAILED python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_model_evaluation
FAILED python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_checkpoint_saving
FAILED python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_checkpoint_loading
FAILED python/tests/test_neural_networks/test_training_pipeline.py::TestUnifiedTrainingPipeline::test_metrics_tracking
FAILED python/tests/test_utils/test_batch_coordinator.py::TestBatchProcessing::test_batch_combination
FAILED python/tests/test_utils/test_batch_coordinator.py::TestStatistics::test_statistics_tracking
FAILED python/tests/test_utils/test_config_system.py::TestNetworkConfig::test_input_representation_options
FAILED python/tests/test_utils/test_config_system.py::TestTrainingConfig::test_training_config_defaults
FAILED python/tests/test_utils/test_config_system.py::TestTrainingConfig::test_optimizer_settings
FAILED python/tests/test_utils/test_config_system.py::TestTrainingConfig::test_data_generation_settings
FAILED python/tests/test_utils/test_config_system.py::TestTrainingConfig::test_learning_rate_schedule
FAILED python/tests/test_utils/test_config_system.py::TestMCTSConfig::test_mcts_config_defaults
FAILED python/tests/test_utils/test_config_system.py::TestMCTSConfig::test_performance_settings
FAILED python/tests/test_utils/test_config_system.py::TestMCTSConfig::test_wave_sizing_settings
FAILED python/tests/test_utils/test_config_system.py::TestArenaConfig::test_arena_config_defaults
FAILED python/tests/test_utils/test_config_system.py::TestArenaConfig::test_elo_settings
FAILED python/tests/test_utils/test_config_system.py::TestResourceConfig::test_resource_config_defaults
FAILED python/tests/test_utils/test_config_system.py::TestResourceConfig::test_memory_allocation
FAILED python/tests/test_utils/test_config_system.py::TestConfigSerialization::test_save_json
FAILED python/tests/test_utils/test_config_system.py::TestConfigMerging::test_merge_configs_basic
FAILED python/tests/test_utils/test_config_system.py::TestConfigMerging::test_deep_merge
FAILED python/tests/test_utils/test_config_system.py::TestConfigMerging::test_merge_with_new_keys
FAILED python/tests/test_utils/test_config_system.py::TestConfigValidation::test_validate_game_config
FAILED python/tests/test_utils/test_config_system.py::TestConfigValidation::test_validate_network_config
FAILED python/tests/test_utils/test_config_system.py::TestConfigValidation::test_validate_training_config
FAILED python/tests/test_utils/test_config_system.py::TestConfigValidation::test_validate_mcts_config
FAILED python/tests/test_utils/test_config_system.py::TestConfigUtilities::test_config_string_representation
FAILED python/tests/test_utils/test_config_system.py::TestConfigDefaults::test_experiment_defaults
FAILED python/tests/test_utils/test_config_system.py::TestConfigDefaults::test_log_defaults
FAILED python/tests/test_utils/test_config_system.py::TestConfigDefaults::test_device_defaults
FAILED python/tests/test_utils/test_training_metrics.py::TestTrainingMetricsRecorder::test_moving_average
FAILED python/tests/test_utils/test_training_metrics.py::TestMetricsVisualizer::test_plot_training_curves
============ 86 failed, 778 passed, 75 skipped in 350.22s (0:05:50) ============
