# Test Configuration for Stability Verification
# Tests new 19-channel representation with Q-value training and KL regularization

experiment_name: test_stability
seed: 42
log_level: INFO
num_iterations: 10

game:
  game_type: gomoku
  board_size: 15

mcts:
  # Moderate settings for meaningful testing
  num_simulations: 200
  c_puct: 1.4
  dirichlet_alpha: 0.3
  dirichlet_epsilon: 0.25
  temperature: 1.0
  temperature_threshold: 20
  
  # Performance optimization
  min_wave_size: 1024
  max_wave_size: 4096
  batch_size: 512
  virtual_loss: 1.0
  enable_virtual_loss: true
  enable_fast_ucb: true
  
  # Memory settings
  memory_pool_size_mb: 1024
  max_tree_nodes: 100000
  enable_subtree_reuse: false
  
  # GPU settings
  device: cuda
  num_threads: 22
  
  # No tactical boost for stability testing
  enable_tactical_boost: false

network:
  # Standard network for testing
  model_type: resnet
  input_channels: 19  # New 19-channel representation
  input_representation: basic
  num_res_blocks: 6
  num_filters: 64
  value_head_hidden_size: 128
  policy_head_filters: 2
  
  # Regularization
  dropout_rate: 0.15
  batch_norm: true
  batch_norm_momentum: 0.995
  l2_regularization: 0.0003
  
  # Activation
  activation: relu
  weight_init: he_normal

training:
  # Conservative training parameters
  batch_size: 256
  learning_rate: 0.0005
  learning_rate_schedule: cosine
  lr_decay_steps: 20
  lr_decay_rate: 0.9
  min_learning_rate: 0.00005
  
  # Optimizer
  optimizer: adam
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1e-8
  weight_decay: 0.0001
  
  # Gradient handling
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0
  
  # Training loop
  num_epochs: 5
  early_stopping_patience: 10
  early_stopping_min_delta: 0.0005
  
  # Self-play settings
  num_games_per_iteration: 50
  num_workers: 4
  max_moves_per_game: 225
  resign_threshold: -0.95
  resign_check_moves: 20
  resign_start_iteration: 20  # Don't resign early in testing
  
  # Q-value training - ENABLED for stability
  use_mcts_q_values: true
  q_value_weight: 0.7
  q_value_temperature: 0.1
  
  # KL divergence regularization - ENABLED
  kl_weight: 0.3
  kl_warmup_iterations: 3
  
  # Data handling
  window_size: 5000
  augment_data: true
  shuffle_buffer_size: 2000
  dataloader_workers: 4
  pin_memory: true
  
  # Mixed precision
  mixed_precision: true
  loss_scale: dynamic
  
  # Paths
  save_dir: experiments/test_stability/checkpoints
  tensorboard_dir: experiments/test_stability/runs
  data_dir: experiments/test_stability/self_play_data

arena:
  # Thorough evaluation
  num_games: 20
  num_workers: 4
  win_threshold: 0.52
  statistical_significance: true
  confidence_level: 0.95
  
  # Game settings
  temperature: 0.0
  mcts_simulations: 200
  c_puct: 1.4
  max_moves: 225
  randomize_start_player: true
  
  # ELO settings
  elo_k_factor: 32.0
  elo_initial_rating: 0.0
  update_elo: true
  
  # Tournament settings
  tournament_rounds: 1
  tournament_games_per_pair: 10
  
  # Data saving
  save_game_records: true
  save_arena_logs: true
  arena_log_dir: experiments/test_stability/arena_logs
  elo_save_path: experiments/test_stability/elo_ratings.json

# Monitoring for stability
monitoring:
  track_policy_entropy: true
  min_policy_entropy: 0.5
  track_value_distribution: true
  track_gradient_norms: true
  save_frequency: 5
  
  # Collapse detection
  collapse_detection_enabled: true
  min_win_rate_difference: 0.15
  max_consecutive_one_sided_games: 15
  min_game_length: 15