# Hybrid CPU-GPU Gomoku Training Configuration
# Optimized for maximum performance using CPU tree operations + GPU neural network
# Based on gomoku_stabilized_training.yaml with hybrid mode optimizations

experiment_name: gomoku_hybrid
seed: 42
log_level: INFO
num_iterations: 200

game:
  game_type: gomoku
  board_size: 15

mcts:
  # HYBRID MODE CONFIGURATION
  backend: hybrid  # Use hybrid CPU-GPU backend
  
  # Optimized for hybrid performance with 12 threads and improved batching
  num_simulations: 500
  c_puct: 1.4
  dirichlet_alpha: 0.3
  dirichlet_epsilon: 0.25
  temperature: 1.0
  temperature_threshold: 30
  
  # Conservative expansion strategy - OPTIMIZED FOR PERFORMANCE
  # Based on analysis: 13.1x faster than single-node, 3.1x faster than aggressive
  min_wave_size: 128    # Balanced for GPU utilization
  max_wave_size: 128    # Moderate batch for efficiency
  wave_size: 128        # Conservative wave size for controlled growth
  batch_size: 128       # GPU batch size for neural network evaluation
  initial_children_per_expansion: 2  # Conservative: 2 children per expansion
  
  # CPU thread configuration (adjust based on your CPU)
  num_threads: 22
  
  # Parallel MCTS configuration (NEW - Improved Implementation)
  use_parallel_mcts: true         # Enable parallel MCTS workers
  num_mcts_workers: 8            # Number of parallel workers (threads) for tree operations
  use_improved_parallel: true     # Use improved wave-parallel implementation with depth synchronization
  
  # Virtual loss for parallelization
  virtual_loss: 1.0
  enable_virtual_loss: true
  
  # Tree reuse - enable now that we've fixed the validation bug
  enable_subtree_reuse: true
  subtree_reuse_min_visits: 5
  
  # Memory optimization (hybrid mode is very memory efficient)
  memory_pool_size_mb: 2048  # Reduced from 4096 as hybrid is more efficient
  max_tree_nodes: 2000000    # Can handle more nodes due to efficient CPU tree
  
  # Performance optimizations
  enable_fast_ucb: true
  use_mixed_precision: true  # For GPU evaluation
  use_cuda_graphs: false     # Not compatible with hybrid mode
  
  # CSR tree configuration for Gomoku
  csr_max_actions: 225
  
  # Device configuration
  device: cuda  # GPU for neural network
  
  # Production mode
  enable_debug_logging: false
  enable_state_pool_debug: false
  
  # Disable tactical boost for stability
  enable_tactical_boost: false

network:
  # Optimized ResNet for hybrid mode
  model_type: resnet
  input_channels: 19
  input_representation: basic
  num_res_blocks: 9
  num_filters: 64
  value_head_hidden_size: 128
  policy_head_filters: 2
  
  # Regularization
  dropout_rate: 0.15
  batch_norm: true
  batch_norm_momentum: 0.995
  l2_regularization: 0.0003
  
  # Activation
  activation: gelu
  weight_init: he_normal

training:
  # STABILITY FIXES (inherited from stabilized config)
  # 1. Disable resignation for early iterations
  enable_resign: false
  resign_threshold: -0.98
  resign_check_moves: 30
  resign_start_iteration: 50
  
  # 2. Increase exploration for diversity
  temperature: 1.2
  temperature_decay: 0.99
  min_temperature: 0.5
  
  # 3. Reduce early stopping sensitivity
  early_stopping_enabled: true
  monitor_alert_threshold: 5
  
  # Optimized for hybrid mode throughput
  batch_size: 1024
  learning_rate: 0.0005
  learning_rate_schedule: cosine
  lr_decay_steps: 40
  lr_decay_rate: 0.85
  min_learning_rate: 0.00005
  
  # AdamW optimizer
  optimizer: adamw
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1e-8
  weight_decay: 0.01
  
  # Gradient handling
  gradient_accumulation_steps: 2
  max_grad_norm: 3.0
  gradient_clip_value: null
  
  # Training loop
  num_epochs: 10
  early_stopping_patience: 15
  early_stopping_min_delta: 0.0003
  
  # Batch processing - optimized for hybrid throughput
  inference_batch_size: 128  # Match hybrid GPU batch size
  
  # Self-play settings - can generate more games due to higher throughput
  num_games_per_iteration: 100
  max_moves_per_game: 225
  
  # Replay buffer
  window_size: 100000
  sample_weight_by_game_length: true
  augment_data: true
  shuffle_buffer_size: 20000
  dataloader_workers: 16
  pin_memory: true
  
  # Q-value training
  use_mcts_q_values: true
  q_value_weight: 0.6
  q_value_temperature: 0.1
  
  # KL divergence
  kl_weight: 0.3
  kl_warmup_iterations: 10
  
  # Mixed precision
  mixed_precision: true
  loss_scale: dynamic
  
  # Paths
  save_dir: experiments/gomoku_hybrid/checkpoints
  tensorboard_dir: experiments/gomoku_hybrid/runs
  data_dir: self_play_data
  
  # Population-based training
  opponent_buffer_size: 10
  opponent_selection_temperature: 1.0
  opponent_use_elo_weighting: true
  opponent_min_elo_difference: 50.0

arena:
  # Evaluation settings - use hybrid mode for faster evaluation
  num_games: 40
  win_threshold: 0.53
  statistical_significance: true
  confidence_level: 0.95
  
  # Game settings with hybrid backend
  backend: hybrid  # Use hybrid mode for arena games too
  temperature: 0.0
  mcts_simulations: 500
  c_puct: 1.4
  max_moves: 225
  time_limit_seconds: null
  randomize_start_player: true
  
  # ELO settings
  elo_k_factor: 32.0
  elo_initial_rating: 0.0
  elo_anchor_rating: 0.0
  update_elo: true
  
  # Tournament settings
  tournament_rounds: 1
  tournament_games_per_pair: 24
  
  # Data saving
  save_game_records: true
  save_arena_logs: true
  arena_log_dir: arena_logs
  elo_save_path: elo_ratings.json

# HYBRID MODE ADVANTAGES:
# 1. 14,600+ sims/sec throughput (using GPU game states optimization)
# 2. Fast tensor-based state cloning (0.025ms vs 0.72ms for C++ clone)
# 3. Efficient memory usage with GPU tensor operations
# 4. Parallel MCTS workers with ~2x speedup in self-play (NEW)
# 5. Improved wave-parallel implementation with depth synchronization
# 6. Producer-consumer pattern for optimal GPU batch utilization
# 7. Allows training with more simulations and games per iteration
#
# PARALLEL MCTS SETTINGS:
# - use_parallel_mcts: Enable/disable parallel tree operations
# - num_mcts_workers: Number of CPU threads for parallel selection (2-16 recommended)
# - use_improved_parallel: Use improved implementation with better CPU/GPU coordination
# - virtual_loss: Controls thread divergence (higher = more exploration diversity)
#
# PERFORMANCE WITH PARALLEL MCTS:
# - Sequential: ~1,400 sims/sec
# - Parallel-8: ~2,600 sims/sec (1.87x speedup)
# - Move time reduced from 574ms to 307ms
#
# TUNING TIPS:
# - num_mcts_workers: Set to CPU cores / 2 for best balance
# - Wave size of 128 is optimal for GPU tensor operations
# - Batch size of 128 provides best balance of throughput and latency
# - Monitor both CPU and GPU utilization during self-play
# - Increase num_games_per_iteration to leverage higher throughput