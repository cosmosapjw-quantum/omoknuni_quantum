# Optimized Chess Configuration for RTX 3060 Ti (8GB VRAM) on Ryzen 9 5900X
# Fully utilizing 12 cores/24 threads CPU and 4864 CUDA cores GPU

experiment_name: chess_ryzen9_3060ti_optimized
seed: 42
log_level: INFO
num_iterations: 300

game:
  game_type: chess

mcts:
  # Core MCTS parameters - optimized for complex chess positions
  num_simulations: 2400  # More simulations for chess complexity
  c_puct: 1.5  # Higher exploration for chess
  dirichlet_alpha: 0.3
  dirichlet_epsilon: 0.25
  temperature: 1.0
  temperature_threshold: 15  # Earlier temperature reduction for chess
  temperature_final: 0.1
  
  # Performance optimization - RTX 3060 Ti optimal
  min_wave_size: 3072      # Optimal for 80k+ sims/sec
  max_wave_size: 3072      # Fixed size for best performance
  adaptive_wave_sizing: false  # CRITICAL: Must be false
  batch_size: 512         # Optimal batch size
  
  # Virtual loss for leaf parallelization
  virtual_loss: 3.0
  
  # Memory settings - Conservative for 8GB VRAM with chess complexity
  memory_pool_size_mb: 1536   # Optimized for RTX 3060 Ti stability
  max_tree_nodes: 400000      # Slightly less for chess's higher branching
  tree_reuse: true
  tree_reuse_fraction: 0.5
  
  # GPU optimization - RTX 3060 Ti
  use_cuda_graphs: true
  use_mixed_precision: true
  use_tensor_cores: true
  compile_mode: reduce-overhead
  
  # Quantum features - disabled for classical
  quantum_level: classical
  enable_quantum: false
  
  # Device settings
  device: cuda
  num_threads: 8

network:
  # Larger network for chess complexity
  model_type: resnet
  input_channels: 20  # Enhanced representation
  num_res_blocks: 20  # Deeper for chess
  num_filters: 256  # Wider for chess patterns
  value_head_hidden_size: 512
  policy_head_filters: 4
  
  # Regularization
  dropout_rate: 0.1
  batch_norm: true
  batch_norm_momentum: 0.997
  l2_regularization: 0.0001
  
  # Activation
  activation: relu
  weight_init: he_normal

training:
  # Training parameters for RTX 3060 Ti + Ryzen 9
  batch_size: 256  # Conservative for larger chess network
  learning_rate: 0.02  # Higher initial LR for chess
  learning_rate_schedule: cosine
  lr_warmup_steps: 1000  # Warmup for stability
  lr_decay_steps: 100
  lr_decay_rate: 0.1
  min_learning_rate: 0.00001
  
  # Optimizer
  optimizer: adam
  adam_beta1: 0.9
  adam_beta2: 0.999
  weight_decay: 0.0001
  
  # Gradient handling
  gradient_accumulation_steps: 4  # More accumulation for smaller batch
  max_grad_norm: 5.0
  
  # Training loop
  num_epochs: 10
  
  # Self-play - Utilizing 12 cores
  num_games_per_iteration: 150  # Less games due to complexity
  num_workers: 12  # Full CPU utilization
  # games_per_worker: auto-calculated based on num_games / num_workers
  max_moves_per_game: 300  # Longer chess games
  resign_threshold: -0.90  # Less aggressive resignation
  resign_check_moves: 20
  resign_start_iteration: 15  # Chess needs more iterations to learn endgames
  
  # Data handling - Optimized for 64GB RAM
  window_size: 300000  # Smaller window for chess positions
  augment_data: false  # No augmentation for chess
  shuffle_buffer_size: 20000
  dataloader_workers: 8
  pin_memory: true
  persistent_workers: true
  
  # Mixed precision
  mixed_precision: true
  
  # Paths
  save_dir: checkpoints_chess
  tensorboard_dir: runs_chess
  data_dir: self_play_data_chess

arena:
  # Evaluation settings
  num_games: 100  # Fewer games due to complexity
  num_workers: 6  # Less parallel games for memory
  # games_per_worker: auto-calculated based on num_games / num_workers
  win_threshold: 0.55
  
  # Game settings
  temperature: 0.1
  mcts_simulations: 1200  # More simulations for evaluation
  c_puct: 1.5
  max_moves: 300
  randomize_start_player: true
  
  # ELO tracking
  elo_k_factor: 32.0
  elo_initial_rating: 0.0  # Standard ELO starting rating
  update_elo: true
  
  # Logging
  save_game_records: true  # Save PGN for chess
  save_arena_logs: true
  arena_log_dir: arena_logs_chess
  elo_save_path: elo_ratings_chess.json